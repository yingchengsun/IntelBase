[
{"url": "https://www.youtube.com/watch?v=QkAFTjBvQ-4", "link_title": "Saving Capitalism", "sentiment": 0.20696969696969694, "text": "The greatest income inequality in 80 years. A shrinking middle class. And what he sees as a new American oligarchy. The economic system that helped make America so strong is, says Robert Reich, now failing. The former American labour secretary and author of Saving Capitalism: For the Many Not the Few joins the program to outline what it will take to fix it."},
{"url": "http://www.weatherinfelsius.us", "link_title": "Implementation of xkcd 1923 \u2013 Felsius", "sentiment": 0.0, "text": "The temperature is currently"},
{"url": "http://www.dw.com/en/worlds-tallest-elevator-tower-rises-in-rottweil-germany/a-18527286", "link_title": "World\u2032s tallest elevator tower rises in Rottweil, Germany (2015)", "sentiment": 0.12459392818616119, "text": "The ThyssenKrupp elevator test tower in Rottweil, Germany, will be the tallest in the world - 246 meters (807 feet).\n\nIt will also boast Germany's highest observation deck.\n\nAnd when the last bucket of concrete is craned up top, the structure will weigh five times as much as the Eiffel Tower.\n\n\"What we really need the height for is the fast elevators,\" says project coordinator Peter Osterstock. These cars will travel at speeds in excess of 60 kilometers per hour. The tower's high-speed elevators can be slowed back down in time before they shoot up through the roof.\n\nAs an afterthought, he adds that they'll be testing the brakes by loading up an elevator with 40 tons of material and letting it freefall - \"but only from about 100 meters high.\"\n\nMore important, the company's needs this tower to test its MULTI elevator system, sometimes described as the Harry Potter elevator. The MULTI uses magnets instead of cables, allowing its cabins to go sideways as well as up and down. They also move in one continuous loop - a modern take on the\n\n\"They need three shafts that are directly next to one another,\" Osterstock explains.\n\nOur elevator up to the top isn't a MULTI, and it definitely isn't a speedy elevator. It's the slowest elevator I've ever been on - and Osterstock is quick to point out that it wasn't made by his company, and it wasn't made in Germany.\n\nAll I care about is that it gets us up there safely.\n\nAtop the ongoing project, there's a tall security fence, and that feels pretty safe.\n\nBut the wooden platform we're walking on hangs beyond the building's upper lip, meaning we're floating. The tower's interior contains 12 empty elevator shafts topped with moveable, wooden lids. There are steel reinforcement bars everywhere.\n\nSuddenly the whole platform rises a couple of centimeters.\n\nBut where some sense mortal danger, Osterstock sees progress.\n\nThe massive structure rising over Rottweil is growing at a rate of three meters per day and will finish first-phase construction in July.\n\nAfter a quick frown, the project coordinator adds, \"Or August.\"\n\nStill, it's absolutely amazing that this colossus is being built here.\n\nRottweil hasn't really made headlines since people discovered its dogs. It's the oldest city in the German state of Baden-W\u00fcrttemberg. It's perched defensively - medievally - atop a hill, where its 25,000 residents seem to be a bit on the elderly side, sipping beverages and keeping an eye on any suspicious non-Rottweilers. All in all, an unlikely choice for an engineering project of superlative dimensions.\n\nSo why not build the tower at ThyssenKrupp's nearby Neuhausen elevator research campus, where nobody would have noticed?\n\n\"Too close to the Stuttgart airport,\" Osterstock says. \"You can't build a building this high there.\" The company did survey other nearby locations, he adds, but, regionally speaking, Rottweil was the best.\n\nOK, but why not go underground? That's what the Finnish Kone company did with a pre-existing mine shaft, creating the longest elevator test chamber in the world (330 meters). Germany has plenty of mines.\n\n\"Those are not realistic conditions,\" he says.\n\nWhen the wind blows, the Rottweil elevator tower will bend with it - by half a meter. Skyscrapers do this, too - they bend. ThyssenKrupp wants to know how its elevators and shafts react in moving buildings. Among the potential problems they want to avoid: resonance.\n\nBeyond that, Ostersock says, the company couldn't have gone underground in Rottweil - too much bedrock. And at a certain point in negotiations with the city, the message was very clear: \"Wenn, denn,\" which roughly translates to \"Go big or go home.\"\n\nRottweil will soon boast Germany's highest observation deck, and that's not an accident. If the company was going to build a tower in Rottweil, then it was going to have an observation deck higher than the one in Berlin's Fernsehturm, thank you very much.\n\nBut not too much higher. Rottweil ranges from 600-650 meters above sea level, and the building was not allowed to exceed 850, Ostersock says. That's why they had to build the 246-meter-high structure in a place where Rottweil was only 600 meters above sea level.\n\nThis sounds very German. Why? What is this regulation for?\n\nOsterstock has no idea, and he doesn't care. \"It was high enough for our tower,\" he says.\n\nBut how do Rottweilers feel?\n\nWhen it's finished entirely in 2016, the Rottweil elevator tower will be wrapped in a textile dress. That'll make it far more attractive to look at. The material will also reduce the vortex effect of wind whipping around the cylinder. The building's architect was Alfons B\u00fcrk - a local.\n\nStill, reports in the German press suggested that not all the locals were happy about irrevocably altering their skyline with a private engineering project.\n\nThe city's deputy mayor, Werner Guhl, confirms that there were skeptics. He, himself, he says, was astonished when he first saw the plans - they sounded \"a little bit crazy.\" His citizens' concerns were aired during two city hall forums.\n\n\"But after just a few weeks it was clear that this historic, old city needed a signal for the future,\" he says.\n\nAnd since the city's only \"investment\" includes modernizing a few streets at the base of the tower and coming up with a marketing plan for it, the concerns of many locals ultimately amounted to details as trivial as opening hours. Beyond tourist revenues, the city also raised a little bit of cash by selling the property to ThyssenKrupp - \"at normal property prices,\" Guhl says.\n\nBut was it really this unanimous? Or is this a case of a city lining up with a business and pulling its citzenry along with it?\n\nIn town, I conduct an off-the-cuff unrepresentative survey of .1 percent of the population currently living there - meaning 25 people.\n\nAnd it turns out most of the Rottweilers either \"love\" the tower or just don't care.\n\n\"I think it is a good project,\" says an eighteen-year-old named Simon, who likes the idea of tourists spending money in his city.\n\nIsolde recalls the little balloon that was first used to show locals how high the tower would go. \"You had a tiny little spot in the sky, and you know, OK, I will see the tower from here. But you could not really imagine the dimensions,\" she says. \"So now, it's about half the height it will be, and it's not that dominant. It's almost elegant. I like it!\"\n\nI'm left with the sense that this is all just very German: A huge engineering project that's also somehow elegant, and at the base of a medieval city filled with pretty modern Germans."},
{"url": "http://research.microsoft.com/en-us/um/people/simonpj/Papers/excel/", "link_title": "Improving the world's most popular functional language: Excel (2003)", "sentiment": -0.006944444444444449, "text": "We describe extensions to the Excel spreadsheet that integrate user-defined functions into the spreadsheet grid, rather than treating them as a \u201cbolt-on\u201d. Our case study is unusual in that it highlights the way that programming language insights can be applied to a product not normally considered as a programming language.\n\nEven more unusual, our design is ruthlessly driven by principles of user-centred design developed by the HCI community, extending them to programming language design. Unlike other programming language research that focuses on usability, our project involves the evolution of the design of a well-established language, which raises compatibility with previous versions as a major issue, but also gives us access to a user base who are able to offer feedback in the user-centred design process.\n\nIn this paper we present our extensions and the HCI design principles that lead to our design choices.\n\nIf you are interested in this paper, you may also be interested in the European Spreadsheet Risk Interest Group (EuSpRIG)."},
{"url": "https://blog.cirro.com/2017/12/01/three-simple-steps-to-prevent-hacks-like-the-uber-hack/", "link_title": "Three 3 simple steps to prevents hacks like the Uber Hack", "sentiment": 0.05257936507936509, "text": "I use Uber and UberEats, so the recent news about a 2016 Uber data breach really hits close to home. Hackers stole the names, e-emails, and phone numbers of 57 million Uber riders and drivers along with driver license numbers of around 600,000 drivers. \u00a0What\u2019s really scary is that according to hackmageddon.com\u00a0the Uber attack was one of hundreds of attacks in 2016, with attacks in 2017 already doubling.\n\nIf you have data in databases that you want to secure, then you\u2019re going to love this blog post.\u00a0 I\u2019m going to show you three simple steps that any business, regardless of size or network complexity, can do to keep their data safe.\u00a0 \u00a0This would have definitely prevented the Uber hack.\n\nUp front, I want to clarify that I\u2019m not a security expert, I\u2019m a database and data infrastructure expert. Security experts focus on all the network layers, application secret management solution, people, and policy around things that access a database. While database experts consider all those layers compromised and secure the database regardless of the extra layers.\n\nAccording to news sources the following occurred:\n\nThe response to the attack from security experts was typical. They focused on GitHub security, developer practices for secrets management, and AWS AIM management. Unfortunately, none of them focused on the single most critical flaw; the fact that a random European IP address could access the database.\n\nJust implementing Cirro Secure Connect will\u00a0allow you to publicly publish your database credentials and database IP addresses and still be confident that hackers won\u2019t be able to steal your data.\n\nTo prove this works, I have a publicly exposed Postgres database server that I can connect to via my Cirro server from any external IP in the world.\n\nBelow are the details. I challenge anyone to hack it."},
{"url": "https://medium.com/@fermatslibrary/comments-on-arxiv-papers-20d2b048cf92#email?ref=producthunt", "link_title": "Should arXiv papers have comments?", "sentiment": 0.17837662337662338, "text": "A few months ago we read a user survey conducted by arXiv and were inspired to create Librarian. We decided to solve the two biggest pain points mentioned by arXiv users: getting quick access to references and being able to extract the Bibtex of the paper they were reading. Today we are happy to announce that we are launching a new feature that allows users to post comments on arXiv papers.\n\narXiv is the platform that researchers use to share their most recent work with the world. New findings are posted to arXiv on a daily basis before they are even reviewed or published in journals. It was on arXiv that Grigori Perelman published the papers that led to the proof of the Poincar\u00e9 Conjecture, one of the seven Millenium Prize Problems, for which he was awarded (and declined!) a million dollars and a Fields Medal. Perelman\u2019s first proof was far from being easy to understand and even had minor errors/gaps in the argument that needed to be fixed before he could claim with confidence that he had found a proof to the Poincar\u00e9 Conjecture. At that time, most of the discussions about Perelman\u2019s proof were kept in private silos inside Universities or in email threads. We believe that there should be a place online where these discussions live and where people can openly and publicly collaborate. There have been multiple demonstrations of how powerful open collaboration around papers can be: Terrence Tao\u2019s proof of the Erd\u0151s discrepancy (an 80-year-old number theory problem posed by the great Hungarian mathematician Paul Erd\u0151s) was deeply influenced by a comment on his blog. In addition, there are fields such as Machine Learning and Deep Learning where the rate at which new papers are published is so high that it\u2019s imperative that there exists a place where researchers can discuss and review the most recent advances in the field before they are published in journals.\n\nThat\u2019s why we decided to add the ability to comment papers to Librarian. The comments are added via a Chrome Extension directly on the paper, so that you don\u2019t need to leave arXiv and go to another website. We added support for markdown and Latex while also being able to add links to other content that can enrich the discussion (like images, videos, other PDFs, presentations, code etc). Finally, we made it easy to share comments with anyone that doesn\u2019t have the extension installed; you can just share a link and they will be able to have access to all the comments on the paper.\n\nThere\u2019s a lot of potential energy that can be unlocked if there are more open discussions about science and our ultimate vision for Librarian is that it becomes a platform where people can collaborate and share knowledge around arXiv papers.\n\nTo install Librarian click here. If you want to see a Live demo of the comments click here.\n\nWe would like to thank Ian Goodfellow and Jess Riedel for all the constructive feedback and valuable insights during the development of this feature."},
{"url": "https://www.nytimes.com/2017/11/30/technology/facebook-bored-panda.html?rref=collection%2Fsectioncollection%2Ftechnology&action=click&contentCollection=technology&region=rank&module=package&version=highlights&contentPlacement=1&pgtype=sectionfront&_r=0", "link_title": "How 41 People in Lithuania Took Over Your Facebook Feed", "sentiment": 0.012875862875862875, "text": "The company has done all this without raising outside funding, unlike digital powerhouses such as BuzzFeed and Vice, which have collected hundreds of millions of dollars. It also has only 41 employees, and the low operating costs, along with its enormous popularity, have made for good business. Tomas Banisauskas, Bored Panda\u2019s founder, told me he expects to be profitable this year with $20 million to $30 million in revenue, mostly from the advertisements that appear on its website. Roughly 90 percent of its web traffic comes from Facebook, making the social network by far the biggest factor in Bored Panda\u2019s success.\n\n\u201cThey\u2019re a really helpful company for us,\u201d Mr. Banisauskas, 31, said of Facebook.\n\nBored Panda began as a side project in 2009, while Mr. Banisauskas, then a freelance videographer, was studying business administration at Vilnius University. He was inspired by feats of internet creativity like the Million Dollar Homepage, in which an entrepreneur auctioned off a million pixels on a website for $1 each. And he came up with the idea for a website that would, as he put it, \u201cfight boredom with art and good news stories.\u201d\n\nOn the content side, Bored Panda\u2019s strategy followed a familiar playbook. It collected user-generated content from Reddit, Instagram, Twitter and other social platforms and repackaged it with tempting headlines. But by focusing on art, photography and other creative pursuits, and by studiously sticking to the kind of apolitical content that few people object to, Bored Panda has steadily built a feel-good, escapist empire.\n\nBored Panda has the advantage of getting most of its content free from up-and-coming artists and other creative types who want the kind of exposure a large Facebook page can bring. (And, yes, it does ask for permission. I contacted several artists whose work had been featured on Bored Panda, and all said they\u2019d given their blessing.) It has also adopted a quality-over-quantity strategy that appears to have served it well. It published only 519 articles in October, or roughly 16 posts a day, according to NewsWhip. Compare that with CNN, which published 5,595 articles during the month, and Fox News, which published 51,919 articles.\n\nIt hasn\u2019t been a straight line to success. In its early days, Bored Panda relied on StumbleUpon, a link aggregation site that was popular at the time, for much of its traffic. But in 2010, according to Mr. Banisauskas, StumbleUpon sharply reduced Bored Panda\u2019s prominence on the site and pressured him to buy ads instead.\n\nAs Mr. Banisauskas would later write in a post on Medium, the experience taught him that \u201cthe only way to survive in this industry is to build long-term value through loyal followers.\u201d\n\nThe next several years were a struggle, but in 2013, Bored Panda began to see a spike in viewers being sent from a new source: Facebook. Its positive, lighthearted content was a hit with the social network\u2019s users, and the site\u2019s traffic grew tenfold in a single year. Soon, despite Mr. Banisauskas\u2019s intentions, Bored Panda was far from self-sufficient \u2014 its prospects hinged almost entirely on Facebook.\n\nMore recently, while its competitors have hedged their risks by diversifying away from Facebook, Bored Panda has made a conscious effort to pull the platform even closer. It has started several offshoot Facebook brands, including pages for art and animal-themed stories, and a page called Crafty Panda that focuses on D.I.Y. projects. It has begun creating original content, too, and recently set up a video studio in its office, a hospital from the 19th century that was converted into a tech office complex.\n\n\u201cEveryone wants to be not so dependent on Facebook,\u201d Mr. Banisauskas told me. \u201cAt the same time, it\u2019s impossible \u2014 Facebook is the place where people share their ideas.\u201d\n\nBut dependence comes with real risk. Last month, for example, Facebook began testing a new design for its news feed. In this version, which is being tested in six countries, Facebook posts from pages (including businesses, public figures and publishers like Bored Panda) were removed from the regular news feed. They were placed in a separate section called \u201cExplore Feed,\u201d where they appeared less prominently.\n\nThis change caused tremors in the Facebook publishing world. Several publishers from countries included in the test complained that their Facebook traffic had plummeted overnight. A social media manager from a news site in Slovakia, one of the countries included in the test, called it the \u201cbiggest drop in Facebook organic reach we have ever seen.\u201d\n\nFacebook told me it planned to continue testing the Explore Feed changes for several more months. In a blog post, Adam Mosseri, Facebook\u2019s head of news feed, wrote that the test was meant to \u201cunderstand if people prefer to have separate places for personal and public content,\u201d but that the company had \u201cno plans to roll this test out further.\u201d\n\nRafat Ali, a digital publishing veteran and chief executive of the travel media company Skift, said that while these particular algorithmic changes might not come to pass, sites like Bored Panda could still be easily crushed by a future Facebook experiment.\n\n\u201cYou never know when the rug could be pulled from under them,\u201d Mr. Ali said. \u201cThey could be done in a year or two.\u201d\n\nMr. Banisauskas knows that Facebook can be a fickle landlord, and he worries that as a small foreign company that specializes in aggregated entertainment content, Bored Panda is in a more precarious position than most. Roughly half of Bored Panda\u2019s Facebook audience is American, and Mr. Banisauskas worries that the site could be punished inadvertently by efforts to combat fake news and Russian-style influence campaigns.\n\n\u201cWe\u2019re not part of the problem,\u201d he said, \u201cbut we could get the collateral damage.\u201d\n\nLast summer, Mr. Banisauskas traveled to New York to meet with a group of other Facebook-focused publishers. All these companies produce entertaining material that reaches millions of people every day. In another era, that alone might have been enough to guarantee them a stable future. Today, they exist at Facebook\u2019s mercy and might be wiped away at any moment.\n\nFor now, though, Bored Panda is charging ahead, and hoping to remain on Facebook\u2019s good side.\n\n\u201cEveryone should be worried,\u201d Mr. Banisauskas said, before he injected a note of Bored Panda-style positivity: \u201cBut I believe everything will work out well.\u201d"},
{"url": "http://www.psychiatrictimes.com/special-reports/borderline-personality-disorder-treatment-resistance-reconsidered", "link_title": "Borderline Personality Disorder: Treatment Resistance Reconsidered", "sentiment": 0.09202910564612692, "text": "The concept of treatment resistance deserves reconsideration. Originally formulated in psychoanalytic terms, resistance in treatment referred to the inevitable ways patients unconsciously express their psychology in terms of defense mechanisms and transference enactment. This form of resistance provides a window into the patient\u2019s problems; therefore, it is a major focus of the inquiry and intervention. Modern psychiatry defines treatment resistance as a lack of response to adequate treatment. Both conceptualizations locate treatment resistance within the patient, rather than as a product of limited, underdeveloped, and ineffective treatments. As a result, the term \u201ctreatment resistant\u201d can fuel views of patients as \u201coppositional\u201d and recalcitrant, instead of expectably symptomatic.\n\nTreatment resistance is highly prevalent across most psychiatric disorders\u2014even in common diagnoses generally associated with positive outcomes, such as depression. There are many more obstacles to effective treatment (Figure 1) than the patient\u2019s psychological resistance alone. Identification of specific factors that diminish treatment response may provide more useful points of intervention than the label of treatment resistance.\n\nComorbid disorders contribute to poor treatment response. Treatment guidelines are often based on a false assumption that patients present with single disorders that respond to specific evidence-based treatments. Regardless of increasing attention to problems of comorbidity, guidelines for combining and prioritizing the treatment of different diagnoses remain largely underdeveloped.\n\nComorbid personality disorders complicate treatment. Over 50% of patients in specialized psychiatric settings have personality disorders.1 These patients are more likely to face social adversity, suffer from complex comorbidities, and drop out of treatment or not adhere to medication regimens\u2014all of which contribute to an increased risk of a lack of response to treatment. The presence of a personality disorder, particularly borderline, predicts persistence of anxiety and substance use disorders as well as poorer outcomes in depressive disorders. Moreover, 13% of those who complete suicide have personality disorders.2\n\nClinicians often see patients with personality disorders as treatment resistant\u2014and, in some cases, untreatable.3 While it is true that patients with personality disorders may be challenging to treat, they are treatable. The self-defeating coping skills and difficulty with relationships that are central to personality disorders make a productive treatment alliance difficult to sustain. Clinicians prototypically react with feelings of frustration, disengagement, incompetence, confusion, helplessness, and even rage.4 The identification of these countertransference reactions can facilitate the diagnosis of personality disorders but can overwhelm and disturb clinicians, leading them to avoid diagnosis and personalize problems as a product of either the patient\u2019s immutable character or the clinician\u2019s limitations.\n\nOur progress in understanding and treating borderline personality disorder (BPD) illustrates the benefits of centralizing the personality disorder diagnosis in care management. For over half a century, patients with BPD were identified by their negative therapeutic reactions, that is, worsening with what was thought to be otherwise appropriate treatment. While pessimism and stigma about the disorder remain, our notion of BPD\u2019s prognosis has radically improved with research.\n\nA major longitudinal study of BPD and other personality disorders with 16 years of follow-up showed that virtually all subjects with BPD achieve sustained remission for at least 2 years, and 78% sustain remission for 8 years. Recovery, that is attending work or school and sustaining at least one meaningful relationship, occurred for 60% of patients for 2 years, and was maintained in 40% over 8 years.5 This evidence suggests that the majority of individuals with BPD (and other personality disorders) can achieve remission and most can recover some sustained functioning, which challenges the notion that patients themselves resist treatment."},
{"url": "http://www.businessinsider.com/a-startup-is-creating-communal-housing-for-middle-class-workers-2017-12?r=UK&IR=T/#residents-of-the-mission-community-also-maintain-a-communal-bar-cart-8", "link_title": "A startup is turning old hotels into housing for SF's middle class", "sentiment": 0.12142857142857141, "text": "The booming tech industry has caused an ongoing housing crisis in San Francisco, and longtime middle-income residents have been forced out by sky-high housing costs.\n\nA startup called Starcity is on a mission to alleviate the situation. Founded in 2016, the 18-person team is creating communal housing for middle-income people who don't qualify for government subsidies but still can't afford San Francisco's sky-high prices.\n\nStarcity buys up defunct hotels, retail buildings, and parking garages and turns them into dorm-like living spaces for the city's restaurant workers, teachers, and artists. According to the founder Jon Dishotsky, fewer then 20% of residents work in tech.\n\nRight now, Starcity runs two San Francisco locations \u2014 one in the Mission district and one in Soma. There's an 1,800-person waiting list for the two open locations, with nine more locations in the works. We visited the Mission location to see what it's like."},
{"url": "https://github.com/AlexanderBartash/hybris-integration-intellij-idea-plugin", "link_title": "IntelliJ Idea Hybris Plugin", "sentiment": 0.1260416666666667, "text": "This program is free software: you can redistribute it and/or modify it under the terms of the GNU Lesser General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.\n\nThis program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU Lesser General Public License for more details.\n\nYou should have received a copy of the GNU Lesser General Public License along with this program. If not, see http://www.gnu.org/licenses/.\n\nThis plugin provides hybris integration into Intellij IDEA and another IDE based on it. You can install this plugin to your IDE directly from the repository by clicking on the \"Browse Repositories\" button in Settings/Plugins dialog."},
{"url": "https://github.com/kigster/arli", "link_title": "Do you code complex Arduino projects? Use Arli to search/install libs", "sentiment": 0.10891450216450217, "text": "NOTE: This software is currently in BETA. Bugs are possible, and reporting them is encouraged.\n\nArli is an awesomely simple and very easy to use Arduino Library Installer. It allows your Arduino projects to be portable by including a small text file called that defines your project's Arduino library dependencies. Using either this file, or command line flags, Arli is able to search for libraries, install them locally to a custom location, and do it all consistently and reliably.\n\nThat way you can share projects with others and they will be able to automatically download and install the dependent libraries instead of having to do that manually. The project is inspired by Bundler.\n\nHere is a screenshot of running inside a project with the that defines all of the project's library dependencies. We install into a default libraries folder :\n\nIn a nutshell, Arli relies on the publicly available database of the vast majority of public Ardiuino libraries. This database is maintained by Arduino themselves, and is a giant gzipped JSON file. Arli automatically downloads and caches the index on a local file system, and then lets you search and install libraries using either a simple name search, or more sophisticated ruby-like syntax that supports searching for ANY attribute as an equal match, or a regular expressions, or even a Proc.\n\nSometimes, however, an Arduino library you use may not part of the main database. No problem! Just add the attribute together with the library name. The URL can either be a Github URL, or a URL to a downloadable ZIP file. Arli will figure out the rest.\n\nis a YAML-formatted file that looks like this below. We list all dependencies using the library names that are provided in the database (you can search for the libraries you need prior to populating this file):\n\nThe libraries may be specified with a name and url only, in which case no search is performed, and the provided URL is used to install the library. The library above is not in the main database, therefore we provide URL for Arli to use.\n\nIf the URL is not provided, you can specify one of several fields that are searched for a matching library. Remember, in this case Arli must find one and only one library to install, otherwise it will throw an error.\n\nYou can provide the following fields in the Arilfile if you want the library to be installed from the central database:\n\nIn all of the above cases, Arli will search the standard library database provided by the Arduino official library database JSON file.\n\nYou can also install just a single library by using the command, instead of the . Install accepts either a flag ( ), or a url , , for example:\n\nInstall the ruby gem as follows:\n\nUse this command to install Arduino libraries.\n\nYou can specify libraries in the by providing just the (and posibly ) \u2014 the name must match exactly a library in the Arduino standard database. Alternatively, your can pass fields , \u2014 which all uniquely identify a library in the database.\n\nIf a library you are using is not in the public database just provide its and the fields. The URL can either be a git URL, or a downloadable ZIP file. Arli will use the field if it's available without trying to search for the library elsewhere.\n\nArli understands that the folder where the library is installed must be named correctly: in other words, folder name must match the header file inside of the folder for the library to be found.\n\nWhen Arli downloads libraries in ZIP format, they are unpacked into folder that are named differently. Arli will then search that folder for the source and header files. The name of the directory is then compared to the files found, and in some cases Arli will automatically rename the library folder to match the main header file..\n\nHere is the command inside CMake-based project to build a Wall Clock using Arduino. This project has the following :\n\nYou can see that most libraries are specified by name, except one (SimpleTimer) is specified together with the URL, which will be used to the library.\n\nSo let's specify where our libraries live, and run inside that project. Below is a screenshot of running inside of the Wall Clock Arduino project:\n\nBelow is the complete help for the command for reference:\n\nUse this command to install a single library by either a name or URL:\n\nTo search Arduino library database, you can use the search command.\n\nYou can search in two ways:\n\ndoes a simple search by name, and would match any library with 'AudioZero' in the name, such as . This search returns three results sorted by the version number:\n\nThe search argument can also be a ruby-syntaxed expression, that (if you know ruby) is actually -ed into the method parameters. Here are a few examples:\n\nYou can also use regular expressions, and set maximum number of results printed by the flag.\n\nWith flag, we disabled the default search limit of 100, and got all of the libraries that have the word \"adafruit\" in their name. We could have used , or , or , or even and fields. For complete description of available library attributes, please see the official definition of the file.\n\nA detailed description of the complete search functionality is documented in the library that provides it \u2014 arduino-library. Arli uses gem behind the scenes to search, and lookup libraries.\n\nBelow is the help screen for the search command:\n\nAfter checking out the repo, run to install dependencies. Then, run to run the tests. You can also run for an interactive prompt that will allow you to experiment.\n\nTo install this gem onto your local machine, run . To release a new version, update the version number in , and then run , which will create a git tag for the version, push git commits and tags, and push the file to rubygems.org.\n\nBug reports and pull requests are welcome on GitHub at https://github.com/kigster/arli.\n\nThe gem is available as open source under the terms of the MIT License."},
{"url": "https://www.polygon.com/features/2017/12/1/16707720/the-500-best-games-of-all-time-100-1", "link_title": "The 500 best games of all time: 100-1 \u2013 Polygon", "sentiment": 0.11553639069264068, "text": "This week, we\u2019ve been running a big list of what we \u2014 and a group of trusted friends \u2014 recently voted as the 500 best video games of all time. For the backstory, criteria, explanation of why Breath of the Wild isn\u2019t on the list, etc., head to the beginning here: The 500 best games of all time.\n\nAnd now we\u2019re at the end of the countdown. For numbers 100-1, scroll down.\n\nWarlords pit four players against each other, all fighting to destroy the others' castles with projectiles while defending their own. When it released, the game was praised for its evolution of Pong's gameplay \u2014 due to its projectiles being similar to the Pong ball \u2014 within an addictive multiplayer game.\n\nOffering more than 10,000 playfields to solve puzzles in, The Sentinal featured a first-person view and visual depth that marked a big step forward for game visuals \u2014 and gave players the impression they were in a different world.\n\nSuikoden 2 made waves by being huge. On top of a near-uncountable number of secrets, minigames and side missions, players were able to recruit more than 100 characters to their party. The sheer size of Suikoden 2 is still unparalleled by most other games.\n\nManic Miner was the first title on the ZX Spectrum to have in-game music. Initially thought to be impossible on the machine, Manic Miner's inclusion of music marked an early example of how video game developers could learn to push hardware farther than its creators thought possible.\n\nHomeworld, in a lot of ways, was more of the same for the real-time strategy genre. But its visuals completely moved the bar forward. Unparalleled in detail at the time, Homeworld's recreation of space caught the eyes of critics and players, raising expectations for how games after it should look.\n\nGrand Theft Auto 4 pointed an angry finger right at the American dream. Telling a darker story than previous Grand Theft Auto games, Grand Theft Auto 4 was a bleak, violent look at what life could be like for an immigrant who came to the \"land of opportunity\" in search of just that, only to find the cards stacked against them.\n\nGuitar Hero 2 only improved what was necessary from the first Guitar Hero, adding more complex ways to play like three button notes. While not full of revolutionary upgrades, Guitar Hero 2 cemented the series as a cultural phenomenon, as well as sparking the release of numerous expansions and spin-offs.\n\nYoshi's Island's beautiful, hand-drawn art style made it one of the best-looking games of the 16-bit generation. With Yoshi as a playable character, the game introduced numerous mechanics players hadn't seen before, such as a flutter jump and the ability to transform.\n\nEvery time you enjoy a twin-stick shooter, remember to thank Robotron: 2084. Though its twin stick controls were never widely adopted by other arcade game developers, as time went on they became a natural fit for the dual-analog sticks present on most console pads.\n\nDragon Warrior was the template from which nearly every Japanese role-playing game drew inspiration. From the point of view, to the turn-based combat, to the story stretching over multiple games, Dragon Warrior did it first. Though the game itself never proved a hit in the west, Dragon Warrior's influence still stretches to games today.\n\nOne of the most complex games ever made, Eve is often described as a part-time job, one requiring constant work and attention to keep track of the politics and economy. But for many, the effort is worth the payoff \u2014 in one battle, more than 10,000 players fought together, amassing an estimated more than $30,000 in damages.\n\nMetroid, unlike other platformers, doesn't really reward players for rushing through it \u2014 though it has become a popular speedrunning game. Instead, its emphasis on exploration has been highly influential in games being worlds to explore, not just obstacles to overcome.\n\nAt the time of its release, Modern Warfare was unparalleled in its intense portrayal of war \u2014 something later entries would build upon. But it was the game's multiplayer that proved most impactful. Introducing killstreaks, a level-up system and many other new features, Modern Warfare's multiplayer changed the dynamics of multiplayer shooters forever.\n\nA clone of the game Rogue, the roguelike NetHack was a far richer experience, one players were invited to change as they saw fit. Using an open-source distribution model, NetHack became a \"metagame-within-a-game \u2026 [where] anything could and probably would happen,\" according to Engadget.\n\nLargely similar to the first Doom, Doom 2's biggest enhancements came in the way of graphical upgrades and larger maps. However, Doom 2, unlike Doom, was sold in retail stores, putting the first-person game in more hands than the original had been. Doom 2, though not id's most influential game, played a big role in the explosion of first-person shooters in the '90s.\n\nOne of the \"most unusual and original game[s] to hit PlayStation 2,\" according to Time, Katamari Damacy was developed around being easy to understand and fun to play. This low barrier to entry gained the game a cult-following and led to it being featured in the Museum of Modern Art.\n\nThe first Portal's uses of telekinesis and teleportation gave the puzzle genre an exciting twist. Portal 2's expanded mechanics felt like a fresh start. Adding ways to redirect lasers and options to accelerate player speed created countless approaches to objectives, further opening up the puzzles to dynamic solutions.\n\nSilent Hill 2 stood out as a game unafraid to examine sexuality in smart, nuanced ways \u2014 something hard to say about most games. A horror game on the surface \u2014 granted, an extremely scary one \u2014 Silent Hill's mature take on infidelity, lust, love and abuse showed the depth that game stories could achieve.\n\nA pioneer in many ways, Adventure is often remembered for its unique Easter egg, where players could find developer Warren Robinett's name hidden deep in the game.\n\nKnights of the Old Republic let players play on whatever side of the force they wanted, abandoning the staple light side of the movies. Taking place before the main trilogy of films, the game set the then-industry standard for how to handle a morality system in a game, balancing the experiences of both sides of the coin.\n\nGuild Wars 2 dared to be different. Implementing a mission system closer to that of a single-player game where player choice affected the game world, the MMORPG allowed players to see the world change based on how they approached different challenges.\n\nSpace Invaders is among the pantheon of great early arcade games that turned video games from toys into a full blown business. Space Invaders also helped move games away from realistic depictions and towards fantastical settings.\n\nSecret of Mana shook up the role-playing genre with its real-time combat, requiring players to time attacks just right. It also allowed three players to play together cooperatively, rare for the time, with secondary players jumping in and out at will.\n\nM.U.L.E. was all about the difficulties of supply and demand. Pitting four players against each other to see which would lead their colony to be the first to survive and accrue the most wealth, M.U.L.E got credit for being both fun and a learning experience about economics.\n\nHabitat was ostensibly the world's first MMO. Players had avatars \u2014 it's credited with coining the term \u2014 and they could interact with other players and objects in the world. The game was supposedly developed to facilitate up to 10,000 players, though it never reached that number. Released in 1986, the game had many features that became commonplace in MMOs decades later.\n\nPlaying Ultima Online was the closest a lot of people got to going to war. Built to facilitate thousands of players at once, the game became famous for its massive, months-long events where hundreds, sometimes thousands of players would band together to take on entire cities.\n\nAfter the success of Dota, which helped popularize the MOBA, there was nowhere else to go but up. Since its release in 2013, Dota 2 has remained one of Steam's most popular games, hitting one million concurrents at its peak. The game has also been one of the biggest success stories in the esports world, with some prize pools topping $20 million.\n\nWith The Elder Scrolls 5: Skyrim, the ends more than justified the means. Taking influence from decades of open-ended role-playing games, Skyrim set new standards with its sheer world size, quest depth and character options.\n\nBurnout 3: Takedown caught the eyes of racing fans when it put a focus not only on speed, but on obliterating opponents. The \"Takedown\" mechanic tasked players with ramming into other cars before ultimately causing an opponent to crash. The slow-motion footage of a successful Takedown remains one of the most satisfying sights in games.\n\nSuper Smash Bros. Melee is one of the longest-running competitive fighting games out there, even though it breaks some conventional rules. Proving a game doesn't have to be perfectly balanced to be great, Melee remains at the top of the pile 16 years later.\n\nOne of the biggest success stories of the PlayStation era, Final Fantasy 7 wasn't afraid to be weird, and its deeply emotional story remains a fan favorite still today. The game's success is, in part, credited with popularizing Japanese role-playing games around the globe.\n\nHarvest Moon is all about the tranquility of a simple life. Allowing players to decide how to tackle daily activities like raising livestock and farming, this early farm simulator turned the mundanity of farm life into a soothing, charming experience.\n\nWith more than 100 million people playing League of Legends every month, it's hard to think of game bigger than Riot's juggernaut. That success has also made League one of the most lucrative esports titles in the world, with top prize pools totalling more than $6 million.\n\nChaos Theory improved just about everything that had been in Splinter Cell up to that point, from the controls to the enemy AI to the gadgets. And it was super pretty, too.\n\nMadden is the king of the sports game world, and Madden NFL 2005 was one of the king's greatest achievements. It expertly rode the line between simulation and arcade game, making it possible for players of all skill levels to jump in, play and find something to love.\n\nESPN NFL 2K5 was the last hurrah of Sega's football series before Madden signed an exclusivity deal with the NFL. 2K5 was a remarkable celebration of the sport, one that experimented with how football games have to play and look.\n\nA simple game of tabletop ping pong, Pong revolutionized entertainment and set many of the first cornerstones of the video game industry. Requiring only one hand to operate and needing a second player to go against, Pong's popularity rose in part to its frequent placement in bars.\n\nSuper Mario Galaxy seamlessly blended old and new to acclaimed results. Taking the gameplay of 3D Mario games and giving it a gravity-bending twist, Galaxy played like a dream despite \u2014 and in part because of \u2014 the unusual Wii Nunchuk control setup.\n\nDeveloped by a supergroup of creative minds, Chrono Trigger innovated with role-playing features like multiple endings, side quests that tied into the main plot and non-random encounters. Chrono Trigger managed to walk a tightrope between being simple yet experimental, and many critics consider it the best role-playing game of all time.\n\nThe series' first reach beyond the confines of one city, Grand Theft Auto: San Andreas' fictional state of San Andreas featured numerous terrains and multiple cities \u2014 a move Rockstar would repeat a few games later. Telling a surprisingly emotional story about gang life and the difficulties of escaping it, San Andreas was a watershed moment in one of gaming's best series.\n\nGoldenEye revolutionized first-person shooters by taking them off the internet and putting them on consoles. The smooth gameplay \u2014 and great local multiplayer \u2014 established a new home for shooters.\n\nSuper Mario Galaxy 2 didn't change much from the original Galaxy; it just perfected everything that worked in its predecessor. The game continuing the series' tradition of pushing boundaries and expectations.\n\nNHL '94 was an early example of a game displaying a realistic recreation of the sports world. For hockey fans, it still stands out as one of the best representations of the sport in games \u2014 with a nice bonus of having accurate team-specific organ songs.\n\nIn Elite Beat Agents, you're out to help those in need \u2014 through the power of dance. One of Nintendo's bizarre rhythm games, Elite Beat Agents charming sense of humor, surprisingly awesome soundtrack and addictive gameplay made gave it a true sense of character.\n\nKeeping a lot of what made people fall in love with the series in the first place, while opening things up for those who'd never tried the game before, Civilization 5 dominated the real-time strategy genre.\n\nSimCity 2000 let players build better cities. It expanded on the city building genre by adding more meaningful institutions, like libraries, schools, museums and even prisons.\n\nMassive in every conceivable way \u2014 from the world to the script, lore, items, weapons and side quests \u2014 The Witcher 3: Wild Hunt distanced itself from other open-world games with its extreme attention to detail.\n\nDance Dance Revolution is a workout. Used in schools, for exercise and anywhere someone wants to make video game players look dumb, DDR's revolutionary active playstyle has helped the series stand the test of time.\n\nHalf-Life was a bleak story about science gone wrong. Unlike a lot of games at the time of its release, Half-Life told its story completely in-game, free of cutscenes. This, mixed with the great world design, and the fact Freeman was voiceless, allowed players to slip into Half-Life's world, personally engaging with the story more than in other games.\n\nFocusing less on the actual playing of the sport, Football Manager put players in charge of a soccer club, giving them control of all the crucial choices a team faces over a season. Football Manager innovated the amount of depth a game can have, allowing true soccer fans to experience what it's like to work behind the scenes for their favorite club.\n\nMass Effect 2 marked the pinnacle of the series' agency and consequences. Essentially putting you on a suicide mission, the series built upon its deep relationships by placing your favorite characters' lives in your hands. This gave decisions true weight.\n\nDota established the MOBA, with games like Paragon, Heroes of the Storm and Battleborn all cashing in on its success. Though not as popular as its sequel, the Valve-developed Dota 2, Dota quickly became a multimillion-dollar asset to the esports industry.\n\nShadow of the Colossus was more about the journey than the destination. Players spent a lot of time on horseback searching for 16 colossi \u2014 and sometimes even longer trying to defeat them. A game as much about subtlety as it was grand scale, Shadow of the Colossus is an example of games as high art.\n\nQuest for Glory: So You Want to Be a Hero asked that question literally. Striving for a level of realism still pretty rare in games, the game combined classic adventure mechanics with an approach that would later be known as a survival sim.\n\nMother 3 took a lot of what made its predecessors so special and threw it out the window. Emphasizing familial pressures, Mother 3 had a level of seriousness other games of its time didn't, quickly making it one of the most beloved games of all time, even though it was never released officially in North America.\n\nSuper Mario Kart is a great racing game. But it's a Nintendo racing game, and that distinction matters. A mix of Nintendo's trademark zaniness and a highly-competitive racer, Super Mario Kart became a staple of couch co-op games, proving who was the best behind the wheel with a well-placed banana peel.\n\nEvery wannabe rockstar finally had an audience in Guitar Hero. As one of the most popular rhythm games, Guitar Hero launched a renaissance of music-based games. Though the genre fell off over time, the first Guitar Hero was a phenomenon.\n\nThe Sims took decades of simulation game history and applied it to something everyone could understand: the human life. Free of all the complicated, obtuse angles of other simulators, The Sims' accessibility, diverse character creation and variety of daily activities made it one of the most successful games in the genre.\n\nHalo made Xbox. Without it, it's hard to say what Microsoft's game division would look like today. And that's thanks to the game's mix of scale, story and competition. The controls worked amazingly well on a console pad, too.\n\nWii Sports was the rare game that found its way in the hands players who normally wouldn't think of touching a game. Fusing easy-to-understand, easy-to-play sports minigames with Wii's accessible hardware and user interface, Wii Sports made many in the industry rethink what games needed to be.\n\nEvolving the design set forth by Demon's Souls, Dark Souls continued the series' legacy of sadistic gameplay and accomplishment of learning. Dark Souls was a game always pushing back. You played by its rules, yet those rules were always fair.\n\nOcarina of Time made the transition from 2D to 3D look like the easiest thing in the world. Everything you'd come to expect from a Zelda game was there, yet a host of new mechanics elevated the gameplay. Featuring the groundbreaking target-lock system and songs needing to be learned, Ocarina of Time stood out.\n\nDiablo 2 was one of the fastest-selling PC games \u2014 which makes sense. Following the immensely popular Diablo, this sequel didn't change too much. With more addictive hacking and slashing, and more loot and cows, Diablo 2 became one of Blizzard's highest achievements by being the only thing it needed to be: more.\n\nGrand Theft Auto 5 is the game that just keeps on giving. Providing players an entire state to play in, the game's open world was light years beyond anything seen before in terms of world detail, depth and sheer number of things to do.\n\nResident Evil 4 was a new perspective on an old genre. A change-up on the Resident Evil formula, RE4 introduced more action to the long-running survival horror series, and placed the camera over protagonist Leon Kennedy's shoulder \u2014 which fixed the series' legacy control issues.\n\nNintendo's first major success in North America and the first game designed by Shigeru Miyamoto, Donkey Kong broke ground as one of the earliest examples of what a platformer could be \u2014 and it introduced Mario.\n\nWorld let Mario find new items, it changed how he jumped and traversed levels and it introduced Yoshi. Utilizing the expanded size of the Super Nintendo, World was a much bigger game than earlier Marios, shipping with 96 total worlds.\n\nPersona 4's greatest achievement may just have been getting people to pay attention. When released, Persona 4 found large fanfare in the west \u2014 and its deep story, meaningful social links and addictive procedural dungeon crawling established the series as one of the best in games.\n\nOne of the first interactive fiction games, Zork changed gaming when the game actually spoke back to the player in an intelligent way. Utilising a \"text parser,\" Zork was able to understand complex commands, recognizing some conjunctions and prepositions, which added a layer of depth and complexity to the world.\n\nGone Home scoffed at what a game \"is.\" Free of conflict and combat, relying solely on environmental storytelling and exploration, necessitating players explore every inch of the game to piece together the entire picture, Gone Home told one of the more personal stories in games.\n\nSpelunky is a 2D platformer you'll probably never master \u2014 or even beat. Its procedural nature ensures no two playthroughs are the same, and it's so masterfully designed, so full of mysteries and so addicting, that many players find themselves constantly playing through each new iteration as if it was a new game.\n\nGiven a more realistic setting than most games in the genre, EarthBound was developed to be enjoyed by people who don't play JRPGs \u2014 or even games in general. Its goofy tone, cultural satire and genuine heart made it a standout.\n\nThe Elder Scrolls 3: Morrowind took the series' history of open-ended gameplay and expanded upon it greatly. Putting less emphasis on plot, Morrowind made its titular world the star. And Morrowind's world was a treat to get lost in \u2014 especially without waypoints constantly looming overhead.\n\nJourney was a game about companionship and the freedom of death. Players weren't told who they were playing with, and only had the option to help each other, forcing players to trust one another. This competition-free approach to multiplayer combined with the game's beautiful allegory for life made Journey an instant classic.\n\nNBA Jam made more than $1 billion in quarters. With its over-the-top sometimes-on-fire gameplay, it ushered in new wave of arcade sports games emphasizing craziness over realism. But Jam's precise gameplay made it a standout over imitators.\n\nMetal Gear Solid gets credit for popularizing the stealth genre. Bringing the Metal Gear series into 3D, the game let players sneak around real environments, hiding from guards and hiding bodies. Using elaborate cutscenes and voice acting, Metal Gear Solid's cinematic presentation made its deep story of top-secret infiltration rival Hollywood blockbusters.\n\nRevolving around the construction and management of a Dwarf colony, Dwarf Fortress is a game you can't win \u2014 you simply play until you're done or defeated. The open-ended gameplay and unique use of text-based visuals made the game an early example of an indie game becoming successful solely based on its unique gameplay and style.\n\nRogue created an entirely new genre. Elements of this 1980 dungeon-crawler, like randomly generated dungeons, permadeath and collectible weapons and items, gave birth to a wave of games called \"roguelikes.\" Despite the punishment of having to start over each time, Rogue's dynamic gameplay made for an addicting trip through ever-changing corridors that kept players trying over and over.\n\nFIFA 12 took the long-running sports series and turned it into something beautiful. The host of new features made it a faithful recreation of soccer, allowing players to not only play the sport, but manage their teams down to the sheer minutiae.\n\nTo this day, Super Mario Bros. still plays like a world-class 2D platformer. Its success isn't limited to just genre, though. The game also helped pull the video game industry out of the calamitous 1980s crash.\n\nA return to the series' original top-down perspective, A Link to the Past's Hyrule was massive \u2014 especially for the time \u2014 featuring numerous dungeons and two overworlds. It was \"the purest representation of the time-honored Zelda formula,\" according to GameSpot.\n\nGiving players control over nearly endless mechanics and outcomes, Civilization 2 played a part in making its games among some of the finest-crafted experiences the industry ever had the fortune to play.\n\nCastlevania: Symphony of the Night carried the legacy of 2D games like Super Metroid into the 32-bit era \u2014 when sprites had fallen out of fashion. And it also happened to have one of the most polished, explorable worlds ever seen in a game.\n\nWhat Portal lacked in length it more than made up for in unique, experimental gameplay based. Portal's puzzles allowed players to experiment with the best \u2014 and coolest \u2014 ways to progress with their Companion Cubes.\n\nReinventing how running, jumping and action worked in three dimensions, Mario 64 was one of the first games to explore how 3D spaces could replicate what players loved in 2D. It also experimented with freedom of movement and open levels that later became staples of the genre.\n\nInspired by creator Will Wright's interest in urban planning, SimCity established the city-building genre. Giving players the option to mark areas as commercial or residential, build transportation systems, adjust tax rates and more, SimCity revolutionized the simulation genre with its amount of content and depth.\n\nPraised for its revolutionary AI, gameplay and realistic physics, Half-Life 2 is the standard to which many first-person shooters are still compared \u2014 though few have managed to make the same impact.\n\nBlizzard's decision to add three races to StarCraft revolutionized strategy games, opening up new tactics and playstyles, and ultimately solving a problem many found with strategy games. StarCraft introduced the idea of diversity to strategy games, paving the way for others to experiment with different playstyles.\n\nGrand Theft Auto 3 changed the world. The dawn of the modern Grand Theft Auto game, it showed how open worlds could work, with sandbox gameplay allowing players to do nearly anything they wanted. Its violence, too, intrigued and scared the wider world, bringing levels of media attention unseen before in games.\n\nDarker than earlier Final Fantasy games, FF6 tackled tough issues like infidelity, suicide and genocide. Giving players, for the first time, access to 14 playable characters, each with their own levels of emotional attachment, Final Fantasy 6 was a bleak, memorable, standout in a series known for great experiences.\n\nArriving decades before the indie explosion, Super Metroid is still a common template for 2D and retro inspired indie releases housed under the \"Metroidvania\" subgenre. Its package included a beautiful game full of immense detail, massive open-ended levels and a meaningful arsenal of weapons and tools.\n\nWhen you get people to compete, you bring in a lot of quarters. The game that kicked off the fighting game boom, Street Fighter 2 was a massive success at getting people back into arcades. And it went on to define the SNES library as well.\n\nMinecraft never tells players \"no.\" Deceptively simple looking, Minecraft's building mechanics and open-ended gameplay created one of the biggest fandoms in gaming by simply allowing players to use their imaginations.\n\nWorld of Warcraft set one of the highest watermarks in games, and Blizzard has continued to support it for more than 10 years. The game recently crossed the 100 million lifetime accounts line, thanks to constant expansions, updates and iterations. Praised for its massive open world, passionate community and deep quests, World of Warcraft is a masterclass in attention to detail that has kept players coming back.\n\nPac-Man normalized video games. Its addictive-yet-rewarding gameplay loop of eating Pac-Dots and running from the ghosts created a bonafide phenomenon, enticing people of all ages to take a stab at the arcade machines.\n\nFew games changed the course of history the way Pokemon Red and Blue did. The first games in the Pokemon series, Red and Blue turned the franchise into a global phenomenon, even before it transitioned into a multimedia titan with television shows, movies and a massive collectible card game.\n\nDoom made rockstars out of nerds. Led by video game luminaries John Romero and John Carmack, id's landmark first-person shooter birthed the massive popularity of the genre, spawned countless imitators and made the two Johns millionaires.\n\nIntroducing players to a world and characters they would live with for years to come, The Legend of Zelda was an incredible action role-playing game with tight controls and a great sense of exploration. That it came out so close to the original Super Mario Bros. makes us wonder just what was in the water in Kyoto.\n\nIntroducing many features that went on to define the series, Super Mario Bros. 3 debuted flying, level-specific mechanics and different suits for Mario to wear. SMB3 also exhibited a generous respect for its players, rewarding them for taking the time to explore each level for secrets.\n\nRequiring a strong balance of strategy and reflexes, Tetris defined what it meant to be a puzzle game. Rarely has a game so thoroughly dominated its genre. It doesn't matter who you are; you've played Tetris \u2014 something not easily said about most games. Tetris was simple in its set up and masterful in its execution."},
{"url": "http://www.detroitnews.com/story/business/autos/foreign/2017/11/29/self-driving-race-heats-los-angeles-auto-show/108127776/", "link_title": "Self-driving race heats up at LA Auto Show", "sentiment": 0.1454417600373483, "text": "Los Angeles \u2014 The traffic on California freeways outside the Los Angeles Convention Center is relentless. So it\u2019s fitting that automakers are thinking big at the Los Angeles Auto Show about autonomous cars that relieve driving stress.\n\nBut while the industry agrees on an autonomous, self-driving future, the paths that automakers are taking to get there vary from Audi to Tesla to General Motors to Toyota.\n\nAudi made headlines this week with the U.S. introduction of its flagship A8 sedan with Traffic Jam Assist, the first so-called Level 3 autonomous system that lets the car take full control from the pilot. It will drive itself under 37 mph, allowing drivers to disengage from the car to check email, text and engage in other distractions.\n\nCadillac debuted its similar \u201cSuperCruise\u201d system this fall on the brand\u2019s flagship CT6 sedan. It will also be hands-free, but is considered a Level 2 system because its still requires driver attention on a defined network of divided, limited-access highways. GM\u2019s Chevy division is testing a fleet of autonomous Bolt EVs equipped with LIDAR sensors that allow fully-autonomous, Level 4 capability.\n\nTesla has been the most aggressive proponent of a self-driving cars. It\u2019s outfitted the Model S sedan with an array of camera, radar and sonar hardware augmented by regular, over-the-air software updates.\n\nAnd then there\u2019s Toyota. In contrast to America\u2019s colossus GM, the Japanese giant has kept a low profile. But with the LA show it\u2019s starting to show its hand.\n\nLexus, Toyota\u2019s premium brand, introduced the latest version of its Lexus Safety Sense system, LSS+A, on Tuesday to the media. Building on previous systems that automatically brake to mitigate impact with other vehicles or pedestrians, LSS+A takes a big step toward autonomy by steering and braking to a stop to avoid impact. The Level 4-like feature only works when the driver is disengaged.\n\nIt\u2019s Toyota\u2019s mantra that self-driving cars should be about safety first. But the modest LSS+A masks a larger, more aggressive autonomy program.\n\n\u201cThey are creating a path to much more advanced autonomous-driving technology,\u201d says Kelley Blue Book analyst Karl Brauer.\n\nHe\u2019s referring to the confluence of two Toyota autonomy streams by 2020: Toyota\u2019s \u201cMobility Teammate\u201d hands-free driving system for consumer cars and a fully autonomous ride-sharing service for the 2020 Tokyo Olympic Games for which Toyota is the exclusive transportation partner.\n\n\u201cIf Toyota had the ability to demonstrate at the Olympics to attendees \u2014 and to the watching world \u2014 how much easier they made it to get around the Olympic venue with autonomous technology, that\u2019s a huge opportunity,\u201d says Brauer.\n\nIf Toyota\u2019s product plans have been less ambitious than players like GM and Tesla, its two-track autonomy business model is one of the industry\u2019s clearest.\n\nSpeaking at the AutoMobility LA tech conference that coincided with the show, Gill Pratt, director of the U.S.-based Toyota Research Institute that\u2019s dedicated to autonomous driving, explained the two tracks referred to internally as \u201cChauffeur\u201d and \u201cGuardian.\u201d\n\nChauffeur-related technologies lead down the path to full, so-called Level 4 mobility that will be on display at the Tokyo Olympics. Driverless Olympic Village shuttles will use \u201cMobility Teammate\u201d \u2014 Toyota\u2019s trademark, urban autonomy system.\n\nThe system mirrors what GM, Chrysler, and Volvo are testing with ride-sharing services.\n\n\u201cIncrease productivity for mobility as a service is the major motivation for why so much money is being spent in this space right now,\u201d says Pratt who helped create TRI in late 2015.\n\nManned driving services today costs $1.50 a mile according to a Deutsche Bank analysis. Remove the driver and the cost plummets to 85 cents. That\u2019s a whopping 65 cents per mile of available profit to be made.\n\n\u201cIt\u2019s hard for anyone to make money right now (in the ride-share business),\u201d says Pratt. \u201cThe potential is, if you don\u2019t have drivers you become very profitable. The ride-share companies are in it for their life. They know that the first one that manages to eliminate the cost, they will make tremendous profits.\u201d\n\nAs will the manufacturer that can supply them hundreds of thousands of vehicles.\n\nBut Pratt says there is money to be made in the Guardian space, too \u2014 even though its motivation is more safety than bottom line. Guardian-type technology is what the Lexus LS500 uses to shadow drivers should they encounter trouble.\n\n\u201cGuardian is also driven by sales, particularly as society ages,\u201d explains Pratt. \u201cOlder people tend not to drive very much, and not to buy cars very much.\u201d\n\nHow do manufacturers like Toyota extend the auto-buying years? Sell seniors safer, semi-autonomous vehicles that keep them out of trouble. Pratt says Guardian-type systems will also drive more sales to young people.\n\n\u201cIf I want to buy a car for my 16-year-old, I want a car that won\u2019t crash. So that will boost sales,\u201d he says.\n\nThere are many obstacles to autonomy. Waymo CEO John Krafcik points to the challenge of cameras seeing through bad weather. \u201cThat\u2019s why we\u2019re testing in Phoenix, not Michigan,\u201d he says of Waymo\u2019s real-world autonomy program.\n\nBut Toyota\u2019s Pratt has no doubt that manufacturers will get there and soon. There is too much money at stake.\n\nHenry Payne is auto critic for The Detroit News. Find him at hpayne@detroitnews.com or Twitter @HenryEPayne."},
{"url": "https://threadreaderapp.com/thread/936615043126370306", "link_title": "Things Many People Find Too Obvious to Have Told You Already \u2013 Patio11", "sentiment": -0.3333333333333333, "text": "Your idea is not valuable, at all. All value is in the execution. You think you are an exception; you are not. You should not insist on an NDA to talk about it; nobody serious will engage in contract review over an idea, and this will mark you as clueless."},
{"url": "https://www.theatlantic.com/technology/archive/2017/12/old-man-yells-at-snapchat/547229/?single_page=true", "link_title": "Social Apps Are Now a Commodity", "sentiment": 0.11332435966810972, "text": "I am very old. As in, my age begins with a four, a profoundly uncool number for an age to start with. Which is to say, too old to use Snapchat, the image-messaging social-network app. Founded in 2011, it\u2019s most popular among young people, who spurned Facebook and even Instagram for it. Why? For one part, it\u2019s because we olds are on Facebook and even Instagram. But for another part, it\u2019s just because Snapchat is a thing that young people use, and so other young people use it. That\u2019s how the story goes, anyway. But maybe something simpler is happening. Perhaps there is no magic in any of these apps and services anymore. Facebook and Instagram, Snapchat and GroupMe and Messenger and WhatsApp and all the rest\u2014all are more or less the same. They are commodities for software communication, and choosing between them is more like choosing between brands of shampoo or mayonnaise than it is like choosing a set of features or even a lifestyle.\n\nIt\u2019s not just a myth that Snapchat is for young people. Sixty percent of its users are 25 years old or less, and 37 percent fall between 18 and 24, that revered demographic of marketers. Almost a quarter of the app\u2019s users are under 18. But that\u2019s also changing, as more millennials\u2014or should I say 30-somethings\u2014pick up the app too. One reason is that older folk have, for years, been using Instagram, which is owned by Facebook (which they\u2019ve also used since college or high school). Facebook has been systematically copying Snapchat\u2019s most popular features, including Stories, ephemeral 24-hour photo montages of a user\u2019s activity. It\u2019s no surprise: Facebook has enormous wealth and leverage, including 2 billion users of its core service and over a billion each for its messaging apps, Messenger and WhatsApp. Instagram boasted some 30 million users when Facebook acquired the company in 2012, and that figure has swelled to 800 million in the five years since. Snapchat is stuck around 170 million users. Snap, the company that makes Snapchat, has shed more than half its value since peaking just after going public in March of this year. Its current market cap, about $16 billion, is still more than the $3 billion Facebook offered to acquire the company. And Google had reportedly bid up to $30 billion for the company in advance of the IPO. Although Snap denied the rumor, if true it\u2019s a figure the company might regret having spurned to go it alone.\n\nSnap\u2019s attempts to shake its doldrums have been mixed. A year ago, the company introduced a $130 pair of glasses called Snap Spectacles, which took photos for its app. Initial demand was high, but it soon collapsed. Less than half of buyers were still using the gadget a month after purchase. Snap wrote down almost $40 million dollars in excess inventory. It also paid around $100 million to acquire a Canadian company called Bitstrips, integrating its Bitmoji product, a stylized avatar, into the Snapchat service (it can also be used as a stand-alone stickers in other messaging and social-media apps). Bitmoji gave every Snapchat user a similar but strikingly accurate cartoon image of themselves. And it offered a new platform for advertising, via sponsored avatars\u2014an approach that the company had previously explored with ad-supported photo filters and lenses. Bitmoji also gave Snapchat a way to represent its users in a standard, physical way. It released Snap Map in June, which allows friends to see one another\u2019s activity on a map. None of these innovations really helped turn around Snap\u2019s decline. Though still popular among its core audience, its stock dropped 20 percent in November, after the company missed revenue, profit, and user-growth expectations. Its user base had grown by only 3 percent since the previous quarter. This week, Snap CEO Evan Spiegel announced a redesign of Snapchat. The app is notoriously unintuitive for the unfamiliar, and the redesign, which Spiegel promised in the wake of dismal Q3 results, hopes to make it easier for new users, boosting adoption.\n\nThe announcement came in the form of a short video of Spiegel explaining the \u201cnew and improved\u201d Snapchat. The video is disorienting\u2014a video of a video shoot, really, a jaunty yellow backdrop displayed as a prop instead, the camera cutting between views of Spiegel and those of a film crew filming Spiegel. \u201cLook at us working hard,\u201d the video\u2019s subtext telegraphs. Its text is more mysterious. As a nonuser of Snapchat, Spiegel\u2019s promises struck me as so vague and woolly that they might apply to anything whatsoever. He vows to make Snapchat \u201cmore personal.\u201d Your friends \u201caren\u2019t content; they\u2019re relationships,\u201d he opines, rationalizing the redesign\u2019s shift of sponsored posts into their own view, separated from friends. This move, which gets its own post-production textual overlay on either side of Spiegel\u2019s gaunt body, amounts to \u201cseparating the social from the media.\u201d All of it makes perfect sense so long as you don\u2019t think about it even for a second. The changes themselves are straightforward. Snapchat\u2019s default view is the camera. To the left are chats and stories from friends, and to the right those from publishers and sponsors. For the first time, the friends view works as an algorithmic feed rather than a chronological list\u2014like Facebook, Instagram, and Twitter. When it rolls out over the coming weeks, the new Snapchat will privilege close friends over acquaintances\u2014if indeed your close friends are the ones you send snaps to more often. In that respect, the app will work a lot more like messaging apps like GroupMe, WhatsApp, and Messenger than social-media apps like Instagram or Twitter. In Spiegel\u2019s dressed-up script, that amounts to \u201corganizing Snapchat around your relationships to make it more personal.\u201d\n\nEvery other social app intersperses sponsored posts with organic content for visibility, so it\u2019s hard to imagine why anyone would ever choose to look at Snapchat\u2019s sponsored view, where that material is safely sequestered from view. But perhaps the company hopes to take a hit on ad and sponsor-post performance, if not revenue, to demonstrate user growth to the street. Most notable to me, watching the video, was the incessant refrain that the redesign would inspire its audience to \u201cExpress yourself with your friends.\u201d At its start, Spiegel deadpans, Snapchat \u201cmade it easier to express yourself by talking with pictures.\u201d The redesign, he promises, will make it easier to find the people you want to express yourself with. The result? \u201cThe friends you want to talk to will be there when you want to talk to them.\u201d As a Snapchat nonuser, it\u2019s easier for me to hold these claims at a distance. But not because they are incredible or stupid or even bad. Rather, because they are so ordinary and humdrum that it seems ridiculous to suggest that they are remarkable. In essence, Snapchat hopes to compete by taking a weird, unique, unseemly product that lures a specific audience partly on account of those reasons, and transforming it into yet another chat app\u2014even if a photo-centric one\u2014that works more or less like any other. It makes me wonder, what makes someone choose one app over another? Why use Twitter over Facebook, or Instagram over Snapchat, or GroupMe over Messenger? Knowing how bitterly old I am, I ask my kids, teenagers who use Snapchat like most teens do.\n\n\u201cSnapchat still has more features, even given the stuff that Instagram stole from them,\u201d my daughter explains. Her scorn for Instagram, which she also uses, is palpable. Among those features are best friends, which is just what it sounds like, and streaks, a kind of high score for daily posts back and forth with specific Snapchat friends. She has never had a Facebook account and thus doesn\u2019t use Messenger, although she does use GroupMe (which is owned by Microsoft) for group chats. My son, who is a couple years older, did get Facebook immediately upon eligibility at age 13, although he never uses it anymore. He tells me that most of his friends use Snapchat or GroupMe for ordinary, day-to-day conversation\u2014not just for social preening, as many old people imagine they do. I feel even longer in the tooth when he explains that Messages\u2014the blue-bubble iPhone replacement for texting\u2014is something he hardly ever uses. Except to talk to old people, like his parents. Texts, once the bastion of screen-shocked youth, have already gone the way of email, that dour and grizzled technology of geriatrics. People do the things they do. They start because they are convenient, or ready-to-hand, or shared by peers, or momentarily novel. The college students who started using Facebook in the mid-2000s did so because it was new, accessible at universities, and spreading quickly. The parents and friends and grandparents who did so in the years following picked it up because others were doing so. WhatsApp gained popularity in nations where SMS remained expensive, but contacts were still identifiable by telephone number.\n\nThere are functional differences between the services. Instagram is made of pictures, but more oriented toward photographic aesthetics than Snapchat, which uses pictures as messages. That\u2019s what Spiegel means by \u201ctalking with pictures\u201d; it\u2019s phatic visual communication, as my colleague Rob Meyer puts it. Likewise, Twitter\u2019s constraint, at 140 or 280 characters, makes it different from Facebook. GroupMe\u2019s ease of adding multiple people to a chat separates it from Messenger, or Apple\u2019s Messages. But even though those differences make a difference, they are also remarkably small differences. And increasingly smaller, as the various services borrow and steal from one another, as Instagram and Snapchat and others have done. Instead of distinctive services with clear value propositions, these apps are becoming commodities. All commodities have real product differentiators\u2014Coke tastes different (ahem, better) than Pepsi; Secret shills deodorants specially formulated for women, while Old Spice dudes them up for men, and so on. But at bottom, the rapport people have for a particular product or service comes down to a hazy affinity developed from discovery, branding, peer adoption, and other accidents of timing and circumstance. Repeated use, not to mention product marketing, reinforces that choice over time. Snapchat doesn\u2019t make me feel old because it\u2019s so much cooler than Twitter or Messenger, nor because I\u2019m so uncool that I couldn\u2019t possibly grasp it (even if both claims might also be true). Rather, it\u2019s just that Snapchat is the communication service that young people have picked up of late. Telecommunication apps are universal and numerous enough that they support shifting trends and fashions. It\u2019s no different than drinking Jolt Cola or listening to Fugazi or wearing Z Cavariccis or subscribing to call waiting or keeping the line busy while dialing up to Prodigy\u2014all things that were also cool, at one time. The difference is: Nobody thought of soft drinks or music or apparel\u2014or even telephony and computer services, really\u2014as problems to be atomized into individual companies, let alone public ones, meant to corner the market. They were just commodities differentiated through unique, but temporary, variations in form, function, and packaging. Indeed, the whole reason commodities are commodities is because they are so cheap and easy to produce that competition encourages that differentiation. It would be a relief if this might yet become the future of computing. No more innovation and disruption and other chest-thumping boasts. No more world-changing deliverance from the stodgy, legacy paradigms of yore. Just communication offerings in the form of software, offered in various forms with nuanced distinction, each doing their part in letting people interact, so that they can get on with life beyond their rectangles."},
{"url": "https://gizmodo.com/what-the-hell-is-a-quantum-computer-and-how-excited-sho-1819296509", "link_title": "What the Hell Is a Quantum Computer and How Excited Should I Be?", "sentiment": 0.0982582609036098, "text": "They will never sit on your desk, and they will most certainly never fit in your pocket. Today, they\u2019re fragile, and need to be kept at temperatures close to absolute zero. Quantum computers aren\u2019t much like the desktop PCs we\u2019re all so familiar with\u2014they\u2019re a whole new kind of machine, capable of calculations so complex, it\u2019s like upgrading from black-and-white to a full color spectrum.\n\nLately, you\u2019ve been hearing a lot about quantum computing. There are news stories about how it \u201ccould change the world\u201d and \u201copen new dimensions.\u201d Universities are hyping up their quantum microchip prototypes, demonstrations of quantum mechanical ideas in silicon, and other devices and theories. But come on, how does it work? What does it do? Who\u2019s doing it? And, most importantly, why should you care?\n\n\n\nDespite what you\u2019ve heard, right now, quantum computing is more or less in the era that classical computing was in the \u201850s, when room-sized hulks ran on vacuum tubes. But it could revolutionize computing. Potentially. Maybe.\n\nBefore you learn what a quantum computer is and why it matters, let\u2019s break down the mathematical theory of quantum mechanics. It may sound esoteric, but the rules of quantum mechanics govern the very nature of the particles that make up our universe, including those of your electronics and gadgets.\n\n\n\nIn our universe, we are used to a thing being one thing. A coin, for example, can be heads, or it can be tails. But if the coin followed the rules of quantum mechanics, the coin would be flipping midair. So until it lands and we look at it, we don\u2019t know if it\u2019s heads or tails. Effectively, it\u2019s both heads and tails at the same time. \n\n\n\nWe do know one thing about this coin. There is a probability for the flipping coin to be either heads or tails. So the coin isn\u2019t heads, it\u2019s not tails, it\u2019s\u2014for example\u2014the probability of 20% heads and 80% tails. Scientifically speaking, how can a physical thing be like this? How do we even begin describe it?\n\nThe most mind-boggling part of quantum mechanics is that for some reason, particles like electrons seem to act like waves, and light waves like particles. Particles have a wavelength. The most basic experiment demonstrating this fact is the double slit experiment:\n\n\n\nIf you put a pair of parallel slits in a partition\u00a0between a beam of particles and a wall, and put a detector on the wall to see what happens, a strange pattern of stripes appear. It\u2019s called an interference pattern.\n\n\n\nLike waves, the\u00a0particles-waves that travel through one slit interfere with those that travel through the other slit. If the peak of the wave aligns with a trough, the particles cancel out and nothing shows up. If the peak aligns with another peak, the signal in the detector would be even brighter. (This interference pattern still exists even if you only send one electron at a time.)\n\nIf we were to describe one of these wave-like particles (before they hit the wall) as a mathematical equation, it would look like the mathematical equation describing our coin (before it hits the ground and lands on heads or tails).\n\nThese equations can look kind of scary, like this:\n\nBut all you need to know is that this equation lists the particle\u2019s definite properties but doesn\u2019t say which one you\u2019ll get. (We don\u2019t know that yet.) You can use this equation to find the probabilities of some of the particle\u2019s properties.\n\nAnd because this math involves complex numbers\u2014those containing the square root of -1, or i\u2014it doesn\u2019t just describe the probability of a coin being heads or tails, it describes an advanced probability, which could include the way the face of the coin will be rotated.\n\nFrom all this crazy math, we get a couple of crazy things. There\u2019s superposition\u2014the midair coin being heads and tails at the same time. There\u2019s interference\u2014probability waves overlapping and cancelling each other out. And there\u2019s entanglement, which is like if we tied a bunch of coins together, changing the probability of certain outcomes because they\u2019re, well, entangled now. These three crazy things are exploited by quantum computers to make whole new kinds of algorithms.\n\n\u201cIn some sense we\u2019ve been doing the same thing for 60 years. The rules we use to compute have not changed\u2014we\u2019re stuck with bits and bytes and logic operations,\u201d Martin Laforest, Senior Manager of Scientific Outreach at the Institute for Quantum Computing at the University of Waterloo in Canada, tells Gizmodo. But that is all about to change. \u201cQuantum computers turn the rules of computers on their heads.\u201d\n\nTraditional computers do their computation using bits, which can be stored as electrical charges in processors or even tiny pits drilled into CDs. A bit only has two choices, which we represent as one and zero. Anything with two choices you can pick from is a bit. All computing is done via setting and relating bits, with operations like \u201cif this bit is a zero and this bit is a one, make this third bit a one, otherwise make it a zero,\u201d and so on and so forth.\n\nThe qubit, short for quantum bit, is like a regular bit, but it\u2019s both a zero and a one at the same time (before you look at it). It\u2019s that coin flipping in midair. A quantum computer is like flipping multiple coins at the same time\u2014except while these coins are flipping, they obey the wacky rules of superposition, interference and entanglement.\n\nThe quantum computer first bestows the qubits with this quantum mechanical version of probability of what will happen once you actually peep the qubit. (Once you peep the mysterious qubit though, it stops being mysterious and becomes a defined bit.) Quantum mechanical computations are made by preparing the qubits (or adding weights to a coin before you flip it to manipulate the probability of the outcome), then interacting them together (or flipping a bunch of entangled coins at once) and then measuring them (which causes the coins to stop flipping and produces the final value). If done properly, all of this mid-air interaction should result in a best answer (the value) to whatever question you\u2019ve asked the computer.\n\nQuantum computing is special. As we said before, because its math uses complex numbers, it computes a special version of probabilities\u2014not just heads vs. tails but also the orientation of the coin. So as you throw these coins up in the air, they bump into each other with their different sides and orientations, and some of this bumping changes the probability of the side revealed by the outcome. Sometimes they bump into each other and cancel each other out, making certain outcomes less likely. Sometimes they push each other along, making certain outcomes more likely. All this is interference behavior.\n\n\u201cThe idea with a quantum computer is that you take this phenomenon and exploit it on a massive scale,\u201d said Scott Aaronson, theoretical computer scientist at the University of Texas, Austin. \u201cThe idea is to choreograph a pattern of interference\u201d so that everything cancels out except for the answer you were looking for.\u00a0You want the coins to interfere in the air.\n\n\n\nTo the observer, the answer just looks like the output of regular bits. The quantum mechanics happens in the background.\n\n\n\nIt was famous physicist Richard Feynman who\u2019s credited as dreaming up the first quantum computer in a 1982 paper\u2014a computer that could use quantum mechanics to solve certain problems. But it was like first coming up with a new way of notating music, but no instrument to play it on and no compositions written. It wasn\u2019t until mathematicians began devising algorithms for this computer to use that it became a more reasonable dream to pursue. Theorists wrote the compositions (the algorithms), while physicists worked on building the instruments (the physical quantum computers).\n\nBut okay, now you just have these weird quantum bits whose output you can\u2019t guess beforehand. Now you have to figure out how you can use them. Today, there are several places where researchers think using a quantum computer could solve certain problems better than a classical computer.\n\nMost obviously, you can use these quantum bits to create simulations of other things that follow the crazy rules of quantum mechanics: namely, atoms and molecules. Scientists can use qubits to model entire molecules and their interactions. This could help drug companies devise new medicines, or create new materials with desired properties, before ever setting a foot into a lab.\n\nScientists have already been able to model these molecules using classical computing, but quantum mechanics offers a huge speedup. Fully representing the behavior of the caffeine molecule, including the relevant quantum mechanical rules of its individual particles, might take 160 qubits, explained Robert Sutor, vice president of Cognitive, Blockchain, and Quantum Solutions at IBM. Doing so with a classical computer to that level of detail would require around the same number of bits (10^48) as there are atoms on planet Earth (between 10^49 and 10^50).\n\n\n\nIBM has already modeled the far lighter beryllium hydride molecule using a six qubit quantum computer. Researchers at Lawrence Berkeley National Laboratory determined all of the energy state of a hydrogen molecule with their own two qubit quantum computer.\n\nThere are other algorithms that researchers think might provide some sort of speedup over classical computers. Grover\u2019s algorithm, for example, can help optimize searching. Some are working on using quantum computing in artificial intelligence, or in optimization problems such as \u201cfind the biggest mountain in this mountain range\u201d and \u201cfind the fastest route between these two points separated by several rivers crossed by several bridges.\u201d\n\nBut perhaps the most talked-about quantum computer algorithm is something called Shor\u2019s algorithm, which could change the way almost all our data in encrypted.\n\nDevised by Peter Shor in 1994, its purpose is to factor numbers into primes. I literally mean the factoring you learned in elementary school, the way that you can break 15 into its factors, 3 and 5. Multiplying numbers together is a simple computational task, but breaking big numbers into their factors takes a far longer time. Modern cryptography is based on this knowledge, so lots of your data is, in its most simplified form, encrypted \u201csecurely\u201d by converting things into numbers, multiplying them together\u00a0and associating them with a \u201ckey\u201d\u2014instructions on how to factor them. RSA encryption is used almost everywhere, from passwords to banking to your social media. But if a quantum computer can come along that can run Shor\u2019s algorithm and break the encryption, then that old encryption method is no longer secure.\n\nAccording to everyone I spoke with, breaking RSA encryption is decades away, but scientists are well on their way looking for post-quantum cryptography, new math that can be used for encoding data. The idea is that encryption based on these new ideas would be based on mathematics not easier to run with a quantum computer. Meanwhile, other researchers are scrambling to break the popular RSA encryption system with quantum computers before a hacker does.\n\n\u201cI suppose on that level, it\u2019s like the Cold War,\u201d said Stephan Haas, University of Southern California theoretical physicist. \u201cYou\u2019re getting nuclear weapons because the other guy is getting nuclear weapons.\u201d\n\nScientists needed transistors, teeny electrical switches, to store bits and make regular computers. Similarly, they need hardware that can store a quantum bit. The key to producing a quantum computer is finding a way to model a quantum system that folks can actually control\u2014actually set the probabilities and orientations of those flipping coins. This can be done with atoms trapped by lasers, photons, and other systems. But at this point, most everyone in the industry who\u2019s presented a quantum computer has done so with superconductors\u2014ultra-cold pieces of specially-fabricated electronics.\n\nThey look like teeny microchips. Except these microchips get placed into room-sized refrigerators cooled to temperatures just above absolute zero.\n\nThese superconducting qubits stay quantum for a long time while performing quantum computing operations, explained Irfan Sidiqqi from the University of California, Berkeley. He said that other types of systems can stay quantum for longer, but are slower. \n\n\n\nThere are three kinds of qubits made from these electronics. They\u2019re called flux, charge, and phase qubits, differing by the specifics of their constructions and their physical properties. All of them rely on something called a Josephson junction in order to work.\n\n\n\nA Josephson junction is a tiny piece of non-superconducting insulator placed between the superconducting wires, places where electrons travel without any resistance and begin to show off obvious quantum effects in larger systems. Manipulating the current through the wires allows physicists to set up qubits in these systems. As of today, these systems are very fragile. They fall apart into classical bits through any sorts of noise. And every additional qubit adds more complexity. The biggest quantum computers today have less than 20 qubits, with an exception, the D-Wave computer, whose 2,000 qubits operate on a separate, more specific principle that we\u2019ll dig into later.\n\nActually performing calculations with these qubits can be a challenge. Regular computers have error correction, or built-in redundancies, places where multiple bits perform the same function in case one of them fail. For quantum computers to do this, they need to have extra qubits built into their system specifically to check errors. But the nature of quantum mechanics makes actually doing this error correction more difficult than it does in classical computers. It could take around two thousand physical qubits working in tandem, in fact, to create one reliable \u201cerror-corrected\u201d qubit resistant to messing up. But we\u2019re getting closer. \u201cThere\u2019s a lot of healthy progress that wouldn\u2019t have been imaginable two years ago,\u201d said Debbie Leung on the faculty at the Institute for Quantum Computing at the University of Waterloo.\n\n\u201cA quantum computer will always have errors,\u201d said Laforest. Thankfully, modeling molecules doesn\u2019t need quite the same level of accuracy, said Siddiqi, which is why researchers have plowed forward with these types of simulations in few-qubit systems.\n\nBetter qubits and further research continue to bring us closer to the threshold where we can construct few-qubit processors. \u201cNow we\u2019re at the junction where the theoretical demand versus the reality of experiments are converging together,\u201d said Laforest.\n\n\n\nUniversities, national labs, and companies like IBM, Google, Microsoft and Intel are pursuing qubits set-ups in logic circuits similar to regular bits, all with less than 20 qubits so far. Companies are simultaneously simulating quantum computers with classical computers, but around 50 qubits is seen as the limit\u2014IBM recently simulated 56 qubits, which took 4.5 terabytes of memory in a classical computer.\n\nEach company we spoke to has a slightly different approach to developing their superconducting machines. Sutor from IBM told Gizmodo the company is taking a long-term approach, hoping to one day release a general-purpose quantum computer that classical computers rely on, when needed, through the cloud. Intel has just entered the race with their 17-qubit processor released in October. Microsoft showed off their consumer-facing software suite to Gizmodo, and described a similar long-term goal for quantum computing involving scalable hardware.\n\nRumors are swelling that before the end of this year, Google will unleash a quantum computer that will achieve \u201cquantum supremacy\u201d\u00a0with 49 or 50 qubits. Quantum supremacy simply means finding one single algorithm for which a quantum computer always win, and for which a classical workaround can\u2019t be found to solve the same problem. This is just one milestone, though.\n\n\u201cIt will probably be a contrived task, something not classically important,\u201d said Aaronson. Still, he said, \u201cI think at that point it raises the stakes for the skeptics, for the people who have said and continue to say that it\u2019s a pipe dream.\u201d The other companies seemed to agree and stressed their long-term goals for quantum computing. Google did not respond to a request for comment.\n\nWhile 2017 seems to be a year amidst a sort-of quantum boom, everyone I spoke to was realistic about just how far from a consumer-facing product quantum computing is. \u201cLooking at 2020, 2021 we\u2019ll start seeing the advantage for real users, corporations, and scientific research,\u201d Sutor said.\n\nBut one controversial company, D-wave, is instead doing a different kind of quantum computing called adiabatic quantum computing. Rather than just a dozen to a few dozen qubits, they\u2019ve announced a computer with 2,000. And rather than rely on quantum logic circuits like the rest of the pack, their computer solves one type of problem\u2014optimization problems, like finding the best solution from a range of okay solutions, or finding the best taxi route from point A to point B staying as far as possible from other taxis. These kind of problems are potentially useful in finance.\n\n\n\nUnlike the competitors, D-wave doesn\u2019t need its qubits to be error-corrected. Instead, it overcomes the error correction by running the algorithm many times per second. \u201cIs it a general purpose machine that could run any problem? No,\u201d Bo Ewald, D-Wave\u2019s president, told Gizmodo. \u201cBut there aren\u2019t any computers that can run these problems anyway.\u201d\n\nAt this point, people agree that D-Wave\u2019s computer is a quantum computer, but are unsure if it\u2019s better than a classical computer for the same problem yet (some of its users report beating classical algorithms, said Ewald). But Ewald just wanted to get quantum computers in front of people now. \u201cIf you want to get started with real-world quantum computing today, this is how you do it. NASA, Google, and Los Alamos National Labs have all purchased models or computing space,\u201d said Ewald.\n\nEveryone, even Ewald at D-Wave, agrees that we\u2019re far from seeing quantum computers used in everyday life\u2014there\u2019s a lot of excitement but we\u2019re still in the early days. There are hordes of challenges, like error correction. Then comes the related problem of transmitting quantum information between distant computers or storing quantum information long term in memory.\n\nI asked Aaronson\u00a0whether he thought some startup or some secret effort might come along from out of nowhere and present a super advanced model\u2014he said probably not. \u201cWe know who the best scientists are and we\u2019d expect them to be vacuumed up the way physicists were in the Manhattan project,\u201d he said. \u201cI think it remains a very healthy field, but at the same time it\u2019s true that actually building a useful quantum computer is a massive technological undertaking.\u201d You can\u2019t just build one in your garage.\n\nSo no, you cannot own a quantum computer now, nor is it likely that you will ever own a quantum computer. It\u2019s more likely that when your classical computer needs quantum help, you won\u2019t notice it working. You may hear about some benefits of quantum computing in the next few years, like biochemical advances, but other advantages could be 20 years down the line. And overall, there\u2019s no proof a quantum computer is any better than a classical computer. Yet."},
{"url": "http://www.pylancing.email/", "link_title": "Show HN: PyLancing \u2013 newsletter with freelance leads for Python Devs", "sentiment": 0.125, "text": "First, create an account with Gumroad\n\nIs this your street address? Yes, it is\n\nMacedonia, the former Yugoslav Republic of"},
{"url": "https://geekflare.com/http2-implementation-apache-nginx/", "link_title": "Why it is important to enable HTTP/2 to your website", "sentiment": 0.07083333333333333, "text": "HTTP/2 is second major version HTTP protocol released in 2015.\n\nSince launch, around 11% of website support HTTP/2.\n\nIt got many features like:\n\nDemo by AKAMAI shows HTTP/2 is approximately two\u00a0times faster than HTTP/1.1\n\nDid you know LiteSpeed was one of the first web servers to support HTTP/2?\n\nIf you are using CDN like Cloudflare, Incapsula, MaxCDN then you may not need to enable HTTP/2 in your web servers as you can do it from CDN network edge.\n\nHowever, if you need to implement HTTP/2 in your web servers like Apache, Nginx, IIS then here is how you can do that.\n\nNote: currently all browser support HTTP/2 protocol over HTTPS only. Your web server must be configured with SSL certificate to support HTTP/2.\n\nBut don\u2019t worry if you are doing some experiment, you can get the SSL certificate in FREE.\n\nHTTP/2 can be deployed in Apache HTTP 2.4.17 or later version with the help of mod_http2 module. So if you have 2.2 or lower version then first you got to upgrade to the compatible version.\n\nThis concludes Apache HTTP is installed with HTTP/2 module and it\u2019s time to do the necessary configuration.\n\nIf you are enabling HTTP/2 for an individual virtual host, then you need to add Protocols under respective VIrtualHost.\n\nNote: there are three parameters in above Protocols directive\n\nNow, Apache HTTP instance is enabled to support HTTP/2 protocol.\n\nNginx 1.9.5 or higher version support HTTP/2 so first you got to ensure you have the compatible version installed.\n\nEnabling HTTP/2 in Nginx is just matter of adding http2 parameter in listen directive.\n\nAs I mentioned above, HTTP/2 is supported only over HTTPS, so you got to add under server block which has SSL configuration.\n\nIf your SSL configuration is in another file than nginx.conf, then you got to update there.\n\nOnce done, restart the Nginx for configuration to be active.\n\nThere are multiple ways to check if website support HTTP/2 or not.\n\nManually \u2013 open IE/Chrome/Firefox and press F12 >> go to network tab and you should see protocol as HTTP/2\n\nOnline \u2013 you can use HTTP/2 Test tool\n\nThat\u2019s all for today. I hope above helps you to enable HTTP/2 protocol in Apache and Nginx web server for fast loading web pages."},
{"url": "https://www.iafrikan.com/2017/12/01/hmd-global-celebrates-one-year-as-the-new-home-of-nokia-phones-2/", "link_title": "The rebirth of Nokia", "sentiment": 0.23075163398692813, "text": "HMD Global, the company from Finland behind the relaunch of Nokia phones, is celebrating a year in business. During their first year they have introduced 11 new devices including the much hyped return of the Nokia 3310.\n\nHMD Global has already released its new portfolio of six Nokia smartphones and five feature phones in over 80 markets with activations in 170 countries, delivering websites in 48 languages and setting up solid foundations for future growth.\n\n\n\n Pekka Rantala, Global Executive Vice President and Chief Marketing Officer at HMD Global on their 1 year journey so far and what the future holds.\n\n\u201cThe design and craft of our entire product portfolio are shaped and informed by what our fans want, so it's hugely gratifying to see them respond so positively. The feedback and engagement we\u2019ve enjoyed in the last 12 months have very much inspired us for what's to come. All in all, it's been an exhilarating first year, and we're already looking ahead to what the next 12 months have in-store for us. We're confident they will be our best yet,\u201d said Pekka Rantala, Executive Vice President and Chief Marketing Officer at HMD Global.\n\nEarlier in 2017 when HMD Global announced the return of Nokia mobile phones, it proved how much brand power they still had given how the first Nokia 3310,announcement was received. arrived on the scene to incredible The Nokia 3310 was announced at Mobile World Congress 2017. Nokia mobile phones are on sale across more than 80 countries on 45 local websites across 48 languages. According to HMD Global, devices have already been activated in more than 170 countries.\n\nJuho Sarvikas, Chief Product Officer of HMD Global, explained that their journey started with huge expectations from fans and huge responsibility to deliver on the legacy of Nokia phones.\n\n\"True to our Scandinavian roots, we designed beautiful devices adhering to the build-quality you expect from the heritage of Nokia phones. We took no shortcuts in integrating the latest technology to enhance your real-life experiences. At the same time, we delivered innovative propositions such as the Dual-Sight experience on Nokia 8 and the extraordinary 2-day battery life on Nokia 2.\"\n\n\u201cOur first smartphone, the Nokia 6, sold out in China in just 23 seconds. More recently, the Nokia 8 and Nokia 2 were both recognised as delivering genuine flagship quality at a price that doesn't break the bank. The reviews and awards have really spoken for themselves and we are extremely grateful for our fans\u2019 enthusiastic support,\u201d concluded Sarvikas."},
{"url": "http://www.pewinternet.org/2017/11/29/public-comments-to-the-federal-communications-commission-about-net-neutrality-contain-many-inaccuracies-and-duplicates/", "link_title": "Pew Report: Public Comments to the FCC Contain Many Inaccuracies and Duplicates", "sentiment": 0.09320798319327729, "text": "Fully 57% of comments used temporary or duplicate email addresses, and seven popular comments accounted for 38% of all submissions\n\nCorrection: This report initially noted that 450,000 comments were submitted to the FCC during its previous open comment period on net neutrality. That data point was based only on the initial comment period, spanning Feb. 9-July 18, 2014. The FCC subsequently reopened the comment period through Sept. 15, 2014, and the report now reflects the total number of comments received during the entirety of the 2014 public comment period. In addition, a reference to John Oliver in a sentence referring to the most popular pro-net-neutrality comment has been removed. Pew Research Center has issued a statement regarding concerns raised about this analysis.\n\nFor the second time in less than four years, the U.S. Federal Communications Commission (FCC) is considering regulations regarding net neutrality \u2013 the principle that internet service providers must treat all data the same, regardless of the origin or purpose of that data. Opponents of net neutrality regulations argue that ISPs should have the right to prioritize traffic and charge for their services as they wish. Meanwhile, supporters of net neutrality suggest that so-called fast lanes are anti-competitive and would prevent start-ups and smaller companies from competing with more well-established companies that can afford to pay for prioritized web traffic.\n\nFrom April 27 to Aug. 30, 2017, the FCC allowed members of the public to formally submit comments on the subject. In total, 21.7 million comments were submitted electronically and posted online for review. This figure dwarfs the number received during the initial comment period when the FCC last accepted comments on this topic in 2014, as well as the nearly four million total submissions received during the entirety of the comment process that year. \u00a0Net neutrality regulations underpin the digital lives of many Americans, yet it is challenging to survey the public on such an inherently complex and technical subject. For this reason, Pew Research Center set out to analyze the opinions of those who had taken the time to submit their thoughts to the FCC.\n\nHowever, the Center\u2019s analysis of these submissions finds that the comments present challenges to anyone hoping to understand the attitudes of the concerned public regarding net neutrality. It also highlights the ways in which individuals and groups are using modern digital tools to engage in the long-standing practice of speaking out in order to influence government policy decisions. Among the most notable findings:\n\nThe Center conducted its analysis by downloading all the comments from the FCC\u2019s publicly available API. All data and comments used in this report are stored on the FCC\u2019s site and are freely available to the public. Researchers then used various data analysis techniques to summarize the comments and to look for duplicates or invalid information. Most notably, the Center utilized a measure of textual similarity to determine the share of highly similar comments that were submitted multiple times. \u00a0Full details of the contents of this dataset and the techniques used in this analysis can be found in the methodology\u00a0at the end of this report.\n\nCollecting large-scale data from the public is always challenging. It is difficult to ensure that a person online is indeed who they claim to be, and falsification of someone\u2019s personal information can be accomplished with relatively minimal effort. The Center\u2019s analysis finds evidence that many people did not reveal their true identities when submitting comments to the FCC. Some of these instances may have been accidental, but in many cases patterns in the comments indicate those submitting the comments intentionally entered false or misleading personal information.\n\nThe most common \u201cname\u201d included as an author was not, in fact, a name. In nearly 17,000 instances, the name of the commenter filing their views on the FCC site was written as \u201cNet Neutrality\u201d (this term also appeared as the author of more than 5,000 comments in lower-case form). \u201cThe Internet\u201d also appeared as the name in almost 7,500 submissions. Of the top 15 names that appeared in the FCC submissions, eight included the common last names of \u201cSmith\u201d or \u201cJohnson,\u201d and four were not names at all.\n\nIn theory, the process for submitting a comment to the FCC included a validation technique to ensure the email address submitted with each comment came from a legitimate account. The submission form clearly states that all information submitted, including names and addresses, would be publicly available via the FCC site.\n\nHowever, the Center\u2019s analysis shows that the FCC site does not appear to have utilized this email verification process on a consistent basis. According to this analysis of the data from the FCC, only 3% of the comments definitively went through this validation process. In the vast majority of cases, it is unclear whether any attempt was made to validate the email address provided.\n\nAs a result, in many cases commenters were able to use generic or bogus email addresses and still have their comments accepted by the FCC and posted online. For instance, the email address example@example.com appeared in 7,513 comments, making it the most common email address to appear. The email address john_oliver@yahoo.com (television host John Oliver advocated on his show for net neutrality earlier this year) was also used in 1,002 comments. All told, the Center\u2019s analysis identified 1.4 million email addresses that appeared multiple times in the comments.\n\nAdditionally, in 9,190 cases the email address supplied did not contain the \u201c@\u201d character necessary to serve as a functioning email account. Moreover, 10% of the comments submitted did not include an email address at all.\n\nAlong with using duplicate or potentially fraudulent addresses, the Center\u2019s analysis finds more than 8 million submissions included email addresses from temporary email accounts designed to disappear within hours and leave no trace of email exchanges behind. Taken together, some 57% of the comments submitted to the FCC either utilized a temporary email address or an email address that was also included with at least one other comment.\n\nThe Center\u2019s analysis of these data suggests the net neutrality comment period was marked by several organized efforts aimed at conveying the public\u2019s feelings on this subject.\n\nThis analysis finds that 6% of the 21.7 million comments were submitted a single time. The remaining 94% were each submitted multiple times, in some cases numbering in the thousands. In fact, five comments were submitted more than 800,000 times each. Taken together, these seven comments alone account for more than 8 million submissions, representing 38% of the total over the entirety of the comment period.\n\nThe single comment submitted more times than any other was a pro-net-neutrality statement that appeared 2.8 million times, accounting for 13% of all submissions. At the same time, seven of the top 10 comments argued against net neutrality and encouraged the FCC to roll back Title II regulations. \u00a0The seven most-popular anti-net-neutrality posts made up 27% of all the comments submitted, while the three most-popular comments in favor of net neutrality made up 17% of the total submitted.\n\nWhether they argued for or against net neutrality, the text of many of the top comments can be traced back to a small number of organizations. For example, the single most-popular comment was a pro-net-neutrality statement that appeared as a submission form on the website battleforthenet.com. Similarly, the wording for three popular comments opposing net neutrality (representing the second-, sixth- and ninth-most submitted overall) appeared on the website for an organization known as the Taxpayers Protection Alliance. Combined, the text from these three suggested comments appeared in almost 2.4 million submissions, making up 11% of the total.\n\nOther research has suggested that some share of the FCC comments may have been submitted in bulk using automated processes, such as organized bot campaigns. The Center\u2019s analysis finds support for this argument, based on the fact that many comments were submitted at precisely the same instant. The FCC assigned a precise timestamp to each comment as it was submitted, and an analysis of those timestamps shows that on numerous occasions, thousands of posts were submitted at exactly the same time \u2013 a sign that these submissions were likely automated.\n\nOn more than 100 different occasions, 25,000 or more comments were submitted to the FCC at the same precise second. And on nine different occasions, 75,000 messages or more were posted simultaneously. The three most numerous of these nine moments featured variations of the most popular pro-net-neutrality message. The remaining six included several different anti-net-neutrality statements.\n\nIn the most prolific example, 475,482 comments were submitted on July 19 at precisely 2:57:15 p.m. EDT. Almost all of those comments were pro-net neutrality and offered variations of text that appeared on the site battleforthenet.com. In some cases, the only difference was the name of the submitter: the same text was \u201csigned\u201d 286 times by \u201cAndrew,\u201d 265 times by \u201cMichael\u201d and 235 times by \u201cRyan,\u201d among other names.\n\nA deeper analysis of these simultaneous comments highlights several variations in how they were submitted. In some cases, the comments were highly similar but with minor variations. The 86,237 comments submitted at precisely 7:18:04 p.m. on May 24 offer an example of this approach. No two were exactly the same, but all featured consistent patterns. Most began with variations of a similar theme, such as: \u201cDear [FCC Chairman] Mr. Pai, I am a voter worried about regulations on the Internet,\u201d \u201cDear Chairman Pai, I am a voter worried about Title 2 and net neutrality,\u201d or \u201cDear Commissioners: I\u2019m concerned about Internet regulation and net neutrality.\u201d\n\nThe body of these comments also featured similar phrases. One post charged, \u201cObama\u2019s policy to take over the web is a betrayal of net neutrality. It reversed a free-market policy that functioned supremely well for decades with both parties\u2019 backing.\u201d While another stated, \u201cThe previous administration\u2019s policy to control the Internet is a betrayal of the open Internet. It disrupted a free-market system that functioned fabulously smoothly for decades with bipartisan approval.\u201d\n\nIn other cases, the content of these simultaneous submissions was entirely identical. On May 28 at exactly 8:23:51 p.m. EDT, the FCC received 90,458 comments with this exact message: \u201cTitle II is a Depression-era regulatory framework designed for a telephone monopoly that no longer exists. It was wrong to apply it to the Internet and the FCC should repeal it and go back to the free-market approach that worked so well.\u201d Indeed, this example was not an isolated incident. The Center identified at least five separate occasions when the exact same text was submitted more than 24,000 times at precisely the same moment.\n\nOf course, the fact that many comments were submitted at precisely the same time does not mean the organization or webpage where the text first appeared was responsible for automating or standardizing those submissions. It is possible a third party used the text and submitted these comments on its own. Nor is there anything inherently wrong or sinister about bulk filing of comments. This analysis simply highlights the scale at which digital tools are being brought to bear in the long-standing practice of commenting on proposed government rules.\n\nDuring the four-month period in which the FCC accepted comments on net neutrality, an average of 172,246 posts were submitted per day. But the comment period featured several long stretches with few submissions, punctuated by bursts of intense activity.\n\nThe comment period officially opened on April 27, and only 453 comments were submitted on that day. On Sunday, May 7, two major events occurred that coincided with a significant increase in submissions. That evening, comedian John Oliver broadcasted a nearly 20-minute segment on his HBO show Last Week Tonight defending net neutrality and encouraging his viewers to submit comments supporting his position. The last time the FCC considered net neutrality in 2014, a Pew Research Center analysis showed that John Oliver\u2019s program also led to a spike in the number of comments submitted.\n\nAlso on May 7, the FCC issued a news release stating that a distributed denial of service attack (DDoS) occurred against the electronic filing system. Some critics have questioned whether an actual DDoS attack occurred, noting that the FCC did not provide documentation regarding the attack following a Freedom of Information Act request by the website Gizmodo. And two Democratic members of the House Energy and Commerce Committee have since requested an investigation into the matter.\n\nMore than 2.1 million comments were submitted in the five days following those two events (May 8-12). Those comments made up 10% of all the comments submitted during the entire submission period.\n\nIn response to this surge of submissions, the FCC released a public notice on May 11 that announced a \u201csunshine period\u201d for the week spanning May 12-18 in which the FCC would temporarily stop taking public comments due to the large number of submissions. According to the FCC\u2019s statement:\n\n\u201cThis means that during this brief period of time, members of the public cannot make presentations to FCC employees who are working on the matter, and are likely to be involved in making a decision on it, if the underlying content of the communication concerns the outcome of the proceeding \u2026 The Commission adopted these rules to provide FCC decision-makers with a period of repose during which they can reflect on the upcoming items.\u201d\n\nAlthough the FCC claimed it would not accept comments during this period, the Center\u2019s analysis finds that more than 93,000 posts submitted on those days were included among the final database made available for public review.\n\nThe rate of comments slowed significantly over the next few weeks. From May 30 to July 8, the number of comments declined to an average of only 5,832 posts per day. In mid-July, activity increased dramatically and remained relatively high until the original date the comment period ended.\n\nThe single day with the most submissions occurred on July 12. Online activists dubbed the day \u201cNet Neutrality Day of Action\u201d or \u201cDay of Action to Save Net Neutrality\u201d and numerous sites altered their websites to include statements favoring net neutrality. On that day alone, 1.4 million comments were submitted electronically to the FCC."},
{"url": "https://copywrite.io/", "link_title": "Learn how to manage your marketing content easily", "sentiment": 0.3, "text": "Read our most recent articles, and see how you can improve your writing. Keep up with the most recent techniques and see how you can find more title ideas."},
{"url": "https://www.theatlantic.com/technology/archive/2017/12/how-the-index-card-catalogued-the-world/547271/?utm_source=feed&amp;single_page=true", "link_title": "How the Index Card Catalogued the World", "sentiment": 0.10231169973817032, "text": "Like every graduate student, I once holed up in the library cramming for my doctoral oral exams. This ritual hazing starts with a long reading list. Come exam day, the scholar must prove mastery of a field, whether it\u2019s Islamic art or German history. The student sits before a panel of professors, answering questions drawn from the book list. More From Our Partners How Racial Data Gets 'Cleaned' in the U.S. Census To prepare for this initiation, I bought a lifetime supply of index cards. On each four-by-six rectangle, I distilled the major points of a book. My index cards\u2014portable, visual, tactile, easily rearranged and reshuffled\u2014got me through the exam. Yet it never occurred to me, as I rehearsed my talking points more than a decade ago, that my index cards belonged to the very European history I was studying. The index card was a product of the Enlightenment, conceived by one of its towering figures: Carl Linnaeus, the Swedish botanist, physician, and the father of modern taxonomy. But like all information systems, the index card had unexpected political implications, too: It helped set the stage for categorizing people, and for the prejudice and violence that comes along with such classification.\n\nIn 1767, near the end of his career, Linnaeus began to use \u201clittle paper slips of a standard size\u201d to record information about plants and animals. According to the historians Isabelle Charmantier and Staffan M\u00fcller-Wille, these paper slips offered \u201can expedient solution to an information-overload crisis\u201d for the Swedish scientist. More than 1,000 of them, measuring five by three inches, are housed at London\u2019s Linnean Society. Each contains notes about plants and material culled from books and other publications. While flimsier than heavy stock and cut by hand, they\u2019re virtually indistinguishable from modern index cards. The Swedish scientist is more often credited with another invention: binomial nomenclature, the latinized two-part name assigned to every species. Before Linnaeus, rambling descriptions were used to identify plants and animals. A tomato, for example, was a mouthful: Solanum caule inermi herbaceo foliis pinnatis incisis. After Linnaeus, the round fruit became Solanum lycopersicum. Thanks to his landmark study, Systema Naturae, naturalists had a universal language, which organized the natural world into the nested hierarchies still used today\u2014species, genus, family, order, class, phylum, and kingdom. In 18th-century Europe, Linnaeus became a household name. \u201cTell him I know no greater man on earth,\u201d said Jean-Jacques Rousseau of his Swedish idol. Like other savants of his day, Rousseau saw the study of plants as a moral pursuit, a virtuous escape into nature. Germany\u2019s man of letters, Johann Wolfgang von Goethe, confessed that after Shakespeare and Spinoza, no one had influenced him more than Linnaeus. \u201cGod created\u2014Linnaeus arranged,\u201d went the adage.\n\nBut despite his meteoric success, Linnaeus had a problem. The man who made order from nature\u2019s chaos did not have a good management system for his own work. His methods for sorting and storing information about the natural world couldn\u2019t keep up with the flood of it he was producing. Linnaeus\u2019s appearance only added to an aura of disorder. Stunned visitors described the prince of botany as a \u201cmarkedly unshaven\u201d man in \u201cdusty shoes and stockings.\u201d Writing about himself, Linnaeus was even less charitable: \u201cBrow furrowed. A low wart on the right cheek and another on the right side of the nose. Teeth bad, worm-eaten.\u201d Worms aside, the real issue vexing Sweden\u2019s top scientist was how to manage a data deluge. He had started out collecting plants in the woods of his native southern Sweden. But as his profile grew, so did his research and writing, and the number of students under his wing. Achieving scientific renown of their own, Linnaeus\u2019s students sent him specimens from their travels in Europe, Russia, the Middle East, West Africa, and China. According to Charmantier and M\u00fcller-Wille, most botanists of the era employed a team to manage their affairs that would keep track of correspondence and categorize specimens. But not Linnaeus, \u201cwho preferred to work alone.\u201d Starting in the 1750s, he complained in letters to friends of feeling overworked and overwhelmed. Burnout, it turns out, isn\u2019t a modern condition.\n\nLinnaeus\u2019s predicament wasn\u2019t new, either. In her book Too Much to Know: Managing Scholarly Information before the Modern Age, the historian Ann Blair explains that since the Renaissance, \u201cthe discovery of new worlds, the recovery of ancient texts, and the proliferation of printed books\u201d unleashed an avalanche of information. The rise of far-flung networks of correspondents only added to this circulation of knowledge. Summarizing, sorting, and searching new material wasn\u2019t easy, especially given the available tools and technologies. Printed books needed buyers. And while notebooks kept information in one place, finding a detail buried inside one was another story. Finishing an academic dissertation wasn\u2019t just a test of erudition or persistence; dealing with the material itself\u2014recording, searching, retrieving it\u2014was a logistical nightmare. Many scholars, like the 17th-century chemist Robert Boyle, preferred to work on loose sheets of paper that could be collated, rearranged, and reshuffled, says Blair. But others came up with novel solutions. Thomas Harrison, a 17th-century English inventor, devised the \u201cark of studies,\u201d a small cabinet that allowed scholars to excerpt books and file their notes in a specific order. Readers would attach pieces of paper to metal hooks labeled by subject heading. Gottfried Wilhelm Leibniz, the German polymath and coinventor of calculus (with Isaac Newton), relied on Harrison\u2019s cumbersome contraption in at least some of his research.\n\nLinnaeus experimented with a few filing systems. In 1752, while cataloging Queen Ludovica Ulrica\u2019s collection of butterflies with his disciple Daniel Solander, he prepared small, uniform sheets of paper for the first time. \u201cThat cataloguing experience was possibly where the idea for using slips came from,\u201d Charmantier explained to me. Solander took this method with him to England, where he catalogued the Sloane Collection of the British Museum and then Joseph Banks\u2019s collections, using similar slips, Charmantier said. This became the cataloguing system of a national collection. Linnaeus may have drawn inspiration from playing cards. Until the mid-19th century, the backs of playing cards were left blank by manufacturers, offering \u201ca practical writing surface,\u201d where scholars scribbled notes, says Blair. Playing cards \u201cwere frequently used as lottery tickets, marriage and death announcements, notepads, or business cards,\u201d explains Markus Krajewski, the author of Paper Machines: About Cards and Catalogs. In 1791, France\u2019s revolutionary government issued the world\u2019s first national cataloging code, calling for playing cards to be used for bibliographical records. And according to Charmantier and M\u00fcller-Wille, playing cards were found under the floorboards of the Uppsala home Linnaeus shared with his wife Sara Lisa. \u00a0 In 1780, two years after Linnaeus\u2019s death, Vienna\u2019s Court Library introduced a card catalog, the first of its kind. Describing all the books on the library\u2019s shelves in one ordered system, it relied on a simple, flexible tool: paper slips. Around the same time that the library catalog appeared, says Krajewski, Europeans adopted banknotes as a universal medium of exchange. He believes this wasn\u2019t a historical coincidence. Banknotes, like bibliographical slips of paper and the books they referred to, were material, representational, and mobile. Perhaps Linnaeus took the same mental leap from \u201cfree-floating banknotes\u201d to \u201clittle paper slips\u201d (or vice versa). Sweden\u2019s great botanist was also a participant in an emerging capitalist economy.\n\nLinnaeus never grasped the full potential of his paper technology. Born of necessity, his paper slips were \u201cidiosyncratic,\u201d say Charmantier and M\u00fcller-Wille. \u201cThere is no sign he ever tried to rationalize or advertise the new practice.\u201d Like his taxonomical system, paper slips were both an idea and a method, designed to bring order to the chaos of the world. The passion for classification, a hallmark of the Enlightenment, also had a dark side. From nature\u2019s variety came an abiding preoccupation with the differences between people. As soon as anthropologists applied Linnaeus\u2019s taxonomical system to humans, the category of race, together with the ideology of racism, was born. It\u2019s fitting, then, that the index card would have a checkered history. To take one example, the FBI\u2019s J. Edgar Hoover used skills he burnished as a cataloger at the Library of Congress to assemble his notorious \u201cEditorial Card Index.\u201d By 1920, he had catalogued 200,000 subversive individuals and organizations in detailed, cross-referenced entries. Nazi ideologues compiled a deadlier index-card database to classify 500,000 Jewish Germans according to racial and genetic background. Other regimes have employed similar methods, relying on the index card\u2019s simplicity and versatility to catalog enemies real and imagined. The act of organizing information\u2014even notes about plants\u2014is never neutral or objective. Anyone who has used index cards to plan a project, plot a story, or study for an exam knows that hierarchies are inevitable. Forty years ago, Michel Foucault observed in a footnote that, curiously, historians had neglected the invention of the index card. The book was Discipline and Punish, which explores the relationship between knowledge and power. The index card was a turning point, Foucault believed, in the relationship between power and technology. Like the categories they cataloged, Linnaeus\u2019s paper slips belong to the history of politics as much as the history of science."},
{"url": "https://www.akalin.com/intro-erasure-codes", "link_title": "A Gentle Introduction to Erasure Codes", "sentiment": 0.03345848063332073, "text": "This article explains Reed-Solomon erasure codes and the problems they solve in gory detail, with the aim of providing enough background to understand how the PAR1 and PAR2 file formats work, the details of which will be covered in future articles. I\u2019m assuming that the reader is familiar with programming, but has not had much exposure to coding theory or linear algebra. Thus, I\u2019ll review the basics and treat the results we need as a \u201cblack box\u201d, stating them and moving on. However, I\u2019ll give self-contained proofs of those results in a companion article. So let\u2019s start with the problem we\u2019re trying to solve! Let\u2019s say you have \\(n\\) files of roughly the same size, and you want to guard against \\(m\\) of them being lost or corrupted. To do so, you generate \\(m\\) parity files ahead of time, and if in the future you lose up to \\(m\\) of the data files, you can use an equal number of parity files to recover the lost data files. \u2002 Using parity codes to protect against the loss or corruption of up to two images (out of three) of cashcats. \u2002 With a corrupted and a missing file, recovering the original cashcat images using the parity files from Figure\u00a01. Note that this works even if you lose some of the parity files also; as long as you have \\(n\\) files, whether they be data or parity files, you\u2019ll be able to recover the original \\(n\\) data files. Compare making \\(n\\) parity files with simply making a copy of the \\(n\\) data files (for \\(n > 1\\)). In the latter case, if you lose both a data file and its copy, that data file becomes unrecoverable! So parity files take the same amount of space but provide superior recovery capabilities. Now we can reduce the problem above to a byte-level problem as follows. Have pad all the data files so they\u2019re the same size, and then for each byte position call a function on the th byte of each data file, and store the results into the th byte of each parity file. Also take a checksum or hash of each data file and store those (along with the original data file sizes) with the parity files. Then, can detect corrupted files using the checksums/hashes and treat them as missing, and then for each byte position it can call a function on the th byte of each good data and parity file to recover the th byte of the corrupted/missing data files. A byte error where we know the position of the dropped/corrupted byte is called an erasure. Then, the pair of functions and which behave as described above implements what is called an optimal erasure code; it\u2019s an erasure code because it guards only against byte erasures, and not more general errors where we don\u2019t know which data bytes have been corrupted, and it\u2019s optimal because in general you need at least \\(n\\) known bytes to recover the \\(n\\) data bytes, and that bound is achieved. that computes \\(m\\) parity bytes given \\(n\\) data bytes, and a function that takes in a partial list of data and parity bytes from an earlier call to , and returns the full list of data bytes if there are at least \\(n\\) known data or parity bytes (i.e., there are no more than \\(m\\) omitted data or parity bytes), and an error otherwise. In detail, an optimal erasure code is composed of some set of possible \\((n, m)\\) pairs, and for each possible pair, a functionthat computes \\(m\\) parity bytes given \\(n\\) data bytes, and a functionthat takes in a partial list of data and parity bytes from an earlier call to, and returns the full list of data bytes if there are at least \\(n\\) known data or parity bytes (i.e., there are no more than \\(m\\) omitted data or parity bytes), and an error otherwise. By the end of this article, we\u2019ll find out exactly how the following example works: Let be the input data bytes and let be the desired parity byte count. Then the output parity bytes are \n\n Let be the input partial data bytes and be the input partial parity bytes. Then the output data bytes are\n\nNow coming up with an erasure code for \\(m = 2\\) is more involved, but we can get an inkling of how it could work by letting \\(n = 3\\) for simplicity, and also letting the output of be non-negative integers, instead of just bytes (i.e., less than \\(256\\)). In that case, we can consider parity numbers that are weighted sums of the data bytes. For example, like in the \\(m = 1\\) case, we can have the first parity number be \\[ p_0 = d_0 + d_1 + d_2\\text{,} \\] (using \\(d_i\\) for data bytes and \\(p_i\\) for parity numbers) but for the second parity number, we can pick different weights, say \\[ p_1 = 1 \\cdot d_0 + 2 \\cdot d_1 + 3 \\cdot d_2\\text{.} \\] We want to make sure that the weights for the second parity number are \u201csufficiently different\u201d from that of the first parity number, which we\u2019ll clarify later, but for example note that setting \\[ p_1 = 2 \\cdot d_0 + 2 \\cdot d_1 + 2 \\cdot d_2 \\] can\u2019t add any new information, since then \\(p_1\\) will always be equal to \\(2 \\cdot p_0\\). function looks like So then ourfunction looks like , if we have two missing data bytes, say \\(d_i\\) and \\(d_j\\) for \\(i < j\\), and \\(p_0\\) and \\(p_1\\), we can rearrange the equations \\[ \\begin{aligned} p_0 &= d_0 + d_1 + d_2 \\\\ p_1 &= 1 \\cdot d_0 + 2 \\cdot d_1 + 3 \\cdot d_2 \\end{aligned} \\] to get all the unknowns on the left side, letting \\(d_k\\) be the known data byte: \\[ \\begin{aligned} d_i + d_j &= X = p_0 - d_k \\\\ (i+1) \\cdot d_i + (j+1) \\cdot d_j &= Y = p_1 - (k + 1) \\cdot d_k\\text{.} \\end{aligned} \\] We can then multiply the first equation by \\(i + 1\\) and subtract it from the second to cancel the \\(d_i\\) term and get \\[ d_j = (Y - (i + 1) \\cdot X) / (j - i)\\text{,} \\] and then we can use the first equation to solve for \\(d_i\\): \\[ d_i = X - d_j = ((j + 1) \\cdot X - Y) / (j - i)\\text{.} \\] Thus with these equations, we can implement : ReconstructDataWeighted(partialData: (byte?)[3], partialParity: (int?)[2]) { Handle all cases except when there are exactly two entries set to none in partialData. [i, j] := indices of the unknown data bytes k := index of the known data byte X := partialParity[0] - partialData[k] Y := partialParity[1] - (k + 1) * partialData[k]; d_i := ((j + 1) * X - Y) / (j - i) d_j := (Y - (i + 1) * X) / (j - i) return an array with d_i, d_j, and d[k] in the right order } (Generalizing this to larger values of \\(n\\) is straightforward; \\(p_0\\) will still have a weight of \\(1\\) for each data byte, and \\(p_1\\) will have a weight of \\(i + 1\\) for \\(d_i\\). \\(X\\) and \\(Y\\) will then have terms for all known bytes, and everything else proceeds the same after that.) As for, if we have two missing data bytes, say \\(d_i\\) and \\(d_j\\) for \\(i < j\\), and \\(p_0\\) and \\(p_1\\), we can rearrange the equations \\[ \\begin{aligned} p_0 &= d_0 + d_1 + d_2 \\\\ p_1 &= 1 \\cdot d_0 + 2 \\cdot d_1 + 3 \\cdot d_2 \\end{aligned} \\] to get all the unknowns on the left side, letting \\(d_k\\) be the known data byte: \\[ \\begin{aligned} d_i + d_j &= X = p_0 - d_k \\\\ (i+1) \\cdot d_i + (j+1) \\cdot d_j &= Y = p_1 - (k + 1) \\cdot d_k\\text{.} \\end{aligned} \\] We can then multiply the first equation by \\(i + 1\\) and subtract it from the second to cancel the \\(d_i\\) term and get \\[ d_j = (Y - (i + 1) \\cdot X) / (j - i)\\text{,} \\] and then we can use the first equation to solve for \\(d_i\\): \\[ d_i = X - d_j = ((j + 1) \\cdot X - Y) / (j - i)\\text{.} \\] Thus with these equations, we can implement(Generalizing this to larger values of \\(n\\) is straightforward; \\(p_0\\) will still have a weight of \\(1\\) for each data byte, and \\(p_1\\) will have a weight of \\(i + 1\\) for \\(d_i\\). \\(X\\) and \\(Y\\) will then have terms for all known bytes, and everything else proceeds the same after that.) Now what goes wrong if we just try to do everything modulo \\(256\\)? The most obvious difference from the \\(m = 1\\) case is that solving for \\(d_i\\) or \\(d_j\\) involves division, which works fine for non-negative integers as long as there\u2019s no remainder, but it is not immediately clear how division can make sense modulo \\(256\\). One possible way to define division modulo \\(256\\) would be to first define the multiplicative inverse modulo \\(256\\) of an integer \\(0 \\le x \\lt 256\\) as the integer \\(0 \\le y \\lt 256\\) such that \\((x \\cdot y) \\bmod 256 = 1\\), if it exists, and then define division by \\(x\\) modulo \\(256\\) to be multiplication by \\(y\\) modulo \\(256\\). But this immediately runs into problems; \\(2\\) has no multiplicative inverse modulo \\(256\\), and the same holds for any even number, so reconstruction will fail if, for example, we have the first and third data bytes missing, since then we\u2019d be trying to divide by \\(j - i = 2\\). But for now, let\u2019s leave aside the problem of generating parity bytes instead of parity numbers, and instead focus on how we can generalize the above for larger values of \\(m\\). To do so, we need to first review some linear algebra.\n\n4. Just enough linear algebra to get by[1] In our \\(n = 3, m = 2\\) example in the previous section, the equations for the parity numbers have the form \\[ p = a_0 \\cdot d_0 + a_1 \\cdot d_1 + a_2 \\cdot d_2 \\] for constants \\(a_0\\), \\(a_1\\), and \\(a_2\\). We call such a weighted sum of the \\(d_i\\)s a linear combination of the \\(d_i\\)s, and we write this in a tabular form \\[ p = \\begin{pmatrix} a_0 & a_1 & a_2 \\end{pmatrix} \\cdot \\begin{bmatrix} d_0 \\\\ d_1 \\\\ d_2 \\end{bmatrix}\\text{,} \\] where we define the multiplication of a row vector and a column vector by the equation above, generalized in the straightforward manner for any \\(n\\). Then since we have two parity numbers \\(p_0\\) and \\(p_1\\), each a linear combination of the \\(d_i\\)s, i.e. \\[ \\begin{aligned} p_0 &= a_{00} \\cdot d_0 + a_{01} \\cdot d_1 + a_{02} \\cdot d_2 \\\\ p_1 &= a_{10} \\cdot d_0 + a_{11} \\cdot d_1 + a_{12} \\cdot d_2\\text{,} \\end{aligned} \\] we can write this in a single tabular form as \\[ \\begin{bmatrix} p_0 \\\\ p_1 \\end{bmatrix} = \\begin{pmatrix} a_{00} & a_{01} & a_{02} \\\\ a_{10} & a_{11} & a_{12} \\end{pmatrix} \\cdot \\begin{bmatrix} d_0 \\\\ d_1 \\\\ d_2 \\end{bmatrix}\\text{,} \\] where we define the multiplication of a matrix and a column vector by the equations above. Now if we restrict parity numbers to be linear combinations of the data bytes, then we can identify a function using some set of weights with the matrix formed from that set of weights as above. This holds in general: if a function is defined as a list of linear combinations of its inputs, then it can be represented using a matrix as above, and we call it a linear function. Then we have a correspondence between linear functions that take \\(n\\) numbers to \\(m\\) numbers and matrices with \\(m\\) rows and \\(n\\) columns, which are denoted as \\(m \\times n\\) matrices. As the first example of this correspondence, note that we denote the elements of the matrix above as \\(a_{ij}\\), where the first index is the row index and the second index is the column index. Looking back to the parity equations, we also see that the first index corresponds to the output arguments of , and the second index corresponds to the input arguments.[2] The usefulness of the correspondence between linear functions and matrices is that we can store and manipulate a linear function by storing and manipulating its corresponding matrix of weights, which you wouldn\u2019t be able to easily do for functions in general. For example, as we\u2019ll see below, we\u2019ll be able to compute the inverse of a linear function by matrix operations, which will be useful for . Deleting a row of a matrix corresponds to deleting an output of a linear function. Swapping two rows of a matrix corresponds to swapping two outputs of a linear function. Appending a row to a matrix corresponds to adding an output to a linear function. In general, matrix row operations correspond to manipulations of a linear function\u2019s outputs. First, let\u2019s examine some simple matrix operations and their effects on the corresponding linear function:In general, matrix row operations correspond to manipulations of a linear function\u2019s outputs. matrixMultiply(f: Matrix, g: Matrix) { if (f.columns != g.rows) { return Error } h := new Matrix(f.rows, g.columns) for i := 0 to f.rows - 1 { for j := 0 to g.columns - 1 { t := 0 for k := 0 to f.columns - 1 { t += f[i, k] * g[k, j] } h[i, j] = t } } return h } which you can convince yourself is correct by trying to compose some small linear functions by hand. An important operation on functions is composition: if \\(f\\) takes \\(k\\) inputs to \\(m\\) outputs, and \\(g\\) takes \\(m\\) inputs to \\(n\\) outputs, then we can define \\((g \\circ f)(x_0, \\ldots, x_k) = g(f(x_0, \\ldots, x_k))\\) which takes \\(k\\) inputs to \\(n\\) outputs. It turns out that the composition of two linear functions is again a linear function, and so there must be an operation which takes the corresponding \\(m \\times k\\) matrix \\(F\\) and the \\(n \\times m\\) matrix \\(G\\) and yields a \\(n \\times k\\) matrix. The important operation, the bane of high-schoolers everywhere, is called matrix multiplication , denoted by \\(F \\cdot G\\). If \\(H = F \\cdot G\\), then the explicit formula for its elements is \\[ h_{ij} = \\sum_{k=0}^{m-1} f_{ik} \\cdot g_{kj}\\text{,} \\] which corresponds to the following code:which you can convince yourself is correct by trying to compose some small linear functions by hand. A useful property of matrix multiplication is that it\u2019s a generalization of the product of a row vector and a column vector, and the product of a matrix and a column vector as we defined above. I would be remiss if I didn\u2019t talk about the consequences of defining matrix multiplication as the matrix of the composition of the corresponding linear functions. First, this immediately implies that you can only multiply matrices if the left matrix has the same number of rows as the number of columns of the right matrix, which corresponds to the fact that you can only compose functions if the left function takes the same number of inputs as the number of outputs of the right function. Furthermore, even if you have two \\(n \\times n\\) matrices \\(F\\) and \\(G\\), unlike numbers, it is not true that \\(F \\cdot G = G \\cdot F\\), which corresponds to the fact that in general, for two functions that take \\(n\\) inputs to \\(n\\) outputs, it is not true that \\(f \\circ g = g \\circ f\\). If you learned matrix multiplication just from the formula above, then these facts are much less obvious! Finally, an important function is the identity function \\(\\mathrm{Id}_n\\), which return its \\(n\\) inputs as its outputs. It corresponds to the identity matrix \\[ I_n = \\begin{pmatrix} 1 & 0 & \\cdots & 0 & 0 \\\\ 0 & 1 & \\cdots & 0 & 0 \\\\ \\vdots & \\vdots & \\ddots & \\vdots & \\vdots \\\\ 0 & 0 & \\cdots & 1 & 0 \\\\ 0 & 0 & \\cdots & 0 & 1 \\end{pmatrix}\\text{.} \\] For a linear function \\(f\\) that takes \\(n\\) inputs to \\(n\\) outputs, if there is a function \\(g\\) such that \\(f \\circ g = \\mathrm{Id}_n\\), then we call \\(g\\) the inverse of \\(f\\), and denote it as \\(f^{-1}\\). (It is also true that \\(f^{-1} \\circ f = \\mathrm{Id}_n\\), i.e. \\((f^{-1})^{-1} = f\\).) Not all linear functions taking \\(n\\) inputs to \\(n\\) outputs have inverses, but if the inverse exists, it is also linear (and unique, which is why we call it the inverse). Therefore, we can define the inverse of an \\(n \\times n\\) (or square) matrix \\(M\\) as the unique matrix \\(M^{-1}\\) such that \\(M \\cdot M^{-1} = M^{-1} \\cdot M = I_n\\), if it exists; also, if \\(M\\) has an inverse, we say that \\(M\\) is invertible. where is an arbitrary-precision rational number type. Let \\[ M = \\begin{pmatrix} 1 & 2 \\\\ 3 & 4\\end{pmatrix}\\text{.} \\] This corresponds to the linear functionwhereis an arbitrary-precision rational number type. so is the inverse function of . Indeed, is and is . \\(M\\) is invertible with inverse \\[ M^{-1} = \\begin{pmatrix} -2 & 1 \\\\ 3/2 & -1/2\\end{pmatrix}\\text{.} \\] This corresponds to the linear functionsois the inverse function of. Indeed,isandis So now we\u2019ve reduced the problem of finding the inverse of a linear function taking \\(n\\) inputs to \\(n\\) outputs to finding the inverse of an \\(n \\times n\\) matrix. Before we tackle the question of computing those inverses, let\u2019s first recast our problem in the language of linear algebra and see why we need to find the inverse of a linear function.\n\nwhich therefore corresponds to the parity matrix \\[ P = \\begin{pmatrix} 1 & 1 & 1 \\\\ 1 & 2 & 3 \\end{pmatrix}\\text{.} \\] So in mathematical notation, looks like: \\[ \\begin{bmatrix} p_0 \\\\ p_1 \\end{bmatrix} = \\mathtt{ComputeParityWeighted}(d_0, d_1, d_2) = \\begin{pmatrix} 1 & 1 & 1 \\\\ 1 & 2 & 3 \\end{pmatrix} \\cdot \\begin{bmatrix} d_0 \\\\ d_1 \\\\ d_2 \\end{bmatrix}\\text{.} \\] So, revisiting our \\(n = 3, m = 2\\) erasure code from above, we have the linear functionwhich therefore corresponds to the parity matrix \\[ P = \\begin{pmatrix} 1 & 1 & 1 \\\\ 1 & 2 & 3 \\end{pmatrix}\\text{.} \\] So in mathematical notation,looks like: \\[ \\begin{bmatrix} p_0 \\\\ p_1 \\end{bmatrix} = \\mathtt{ComputeParityWeighted}(d_0, d_1, d_2) = \\begin{pmatrix} 1 & 1 & 1 \\\\ 1 & 2 & 3 \\end{pmatrix} \\cdot \\begin{bmatrix} d_0 \\\\ d_1 \\\\ d_2 \\end{bmatrix}\\text{.} \\] So let\u2019s now reimplement using linear algebra. First, append the rows of \\(P\\) to the identity matrix \\(I_3\\) to get the matrix equation \\[ \\begin{bmatrix} d_0 \\\\ d_1 \\\\ d_2 \\\\ p_0 \\\\ p_1 \\end{bmatrix} = \\begin{pmatrix} 1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1 \\\\ 1 & 1 & 1 \\\\ 1 & 2 & 3 \\end{pmatrix} \\cdot \\begin{bmatrix} d_0 \\\\ d_1 \\\\ d_2 \\end{bmatrix}\\text{,} \\] which corresponds to a linear function that returns the input data bytes in addition to computing the parity numbers. Now let\u2019s say we lose the data bytes \\(d_0\\) and \\(d_2\\). Then let\u2019s remove the rows corresponding to those bytes: \\[ \\begin{bmatrix} \\xcancel{d_0} \\\\ d_1 \\\\ \\xcancel{d_2} \\\\ p_0 \\\\ p_1 \\end{bmatrix} = \\begin{pmatrix} \\xcancel{1} & \\xcancel{0} & \\xcancel{0} \\\\ 0 & 1 & 0 \\\\ \\xcancel{0} & \\xcancel{0} & \\xcancel{1} \\\\ 1 & 1 & 1 \\\\ 1 & 2 & 3 \\end{pmatrix} \\cdot \\begin{bmatrix} d_0 \\\\ d_1 \\\\ d_2 \\end{bmatrix}\\text{,} \\] which turns into \\[ \\begin{bmatrix} d_1 \\\\ p_0 \\\\ p_1 \\end{bmatrix} = \\begin{pmatrix} 0 & 1 & 0 \\\\ 1 & 1 & 1 \\\\ 1 & 2 & 3 \\end{pmatrix} \\cdot \\begin{bmatrix} d_0 \\\\ d_1 \\\\ d_2 \\end{bmatrix}\\text{,} \\] which corresponds to a linear function that maps the input data bytes to the non-lost data bytes and the parity bytes. This is the inverse of the function we want, so we want to invert the \\(3 \\times 3\\) matrix above, which we\u2019ll call \\(M\\). That inverse is \\[ M^{-1} = \\begin{pmatrix} -1/2 & 3/2 & -1/2 \\\\ 1 & 0 & 0 \\\\ -1/2 & -1/2 & 1/2 \\end{pmatrix}\\text{.} \\] Multiplying both sides above by \\(M^{-1}\\), we get \\[ \\begin{bmatrix} d_0 \\\\ d_1 \\\\ d_2 \\end{bmatrix} = \\begin{pmatrix} -1/2 & 3/2 & -1/2 \\\\ 1 & 0 & 0 \\\\ -1/2 & -1/2 & 1/2 \\end{pmatrix} \\cdot \\begin{bmatrix} d_1 \\\\ p_0 \\\\ p_1 \\end{bmatrix}\\text{,} \\] which is exactly what we want: the original data bytes in terms of the known data bytes and the parity numbers![3] Comparing this equation to the one we manually computed previously, they don\u2019t look immediately similar, but some rearrangement will reveal that they indeed compute the same thing. As a sanity check, notice that the second row of \\(M^{-1}\\) means that the first input argument is mapped unchanged to the second output argument, which is exactly what we want for the known byte \\(d_1\\). Now what does this look like in general, i.e. for arbitrary \\(n\\) and \\(m\\)? First, we have to generate an \\(m \\times n\\) parity matrix \\(P\\) whose rows have to be \u201csufficiently different\u201d from each other, which we still have to clarify. Then just multiplies \\(P\\) by \\([d]\\), the column matrix of input bytes, like so: \\[ \\begin{bmatrix} p_0 \\\\ \\vdots \\\\ p_{m-1} \\end{bmatrix} = \\mathtt{ComputeParity}(d_0, \\ldots, d_{n-1}) = \\begin{pmatrix} p_0 \\\\ \\vdots \\\\ p_{m-1} \\end{pmatrix} \\cdot \\begin{bmatrix} d_0 \\\\ \\vdots \\\\ d_{n-1} \\end{bmatrix}\\text{,} \\] where the \\(p_i\\) are the rows of \\(P\\). As for , we first append the rows of \\(P\\) to \\(I_n\\), whose rows we\u2019ll denote as \\(e_i\\): \\[ \\begin{bmatrix} d_0 \\\\ \\vdots \\\\ d_{n-1} \\\\ p_0 \\\\ \\vdots \\\\ p_{m-1} \\end{bmatrix} = \\begin{pmatrix} e_0 \\\\ \\vdots \\\\ e_{n-1} \\\\ p_0 \\\\ \\vdots \\\\ p_{m-1} \\end{pmatrix} \\cdot \\begin{bmatrix} d_0 \\\\ \\vdots \\\\ d_{n-1} \\end{bmatrix}\\text{.} \\] Now assume that the indices of the missing \\(k \\le m\\) data bytes are \\(i_0, \\ldots, i_{k-1}\\). Then we remove the rows corresponding to the missing data bytes, and keep some \\(k\\) parity rows, e.g. \\(p_0\\) to \\(p_{k-1}\\). This yields the equation \\[ \\begin{bmatrix} d_{j_0} \\\\ \\vdots \\\\ d_{j_{n-k-1}} \\\\ p_0 \\\\ \\vdots \\\\ p_{k-1} \\end{bmatrix} = \\begin{pmatrix} e_{j_0} \\\\ \\vdots \\\\ e_{j_{n-k-1}} \\\\ p_0 \\\\ \\vdots \\\\ p_{k-1} \\end{pmatrix} \\cdot \\begin{bmatrix} d_0 \\\\ \\vdots \\\\ d_{n-1} \\end{bmatrix}\\text{,} \\] where \\(j_0, \\ldots, j_{m-k-1}\\) are the indices of the present \\(n - k\\) data bytes. Call that \\(n \\times n\\) matrix \\(M\\), and compute its inverse \\(M^{-1}\\). If \\(P\\) was chosen correctly, \\(M^{-1}\\) should always exist, so if the inverse computation fails, raise an error. Therefore, just multiplies \\(M^{-1}\\) by the column matrix of present data bytes and chosen parity numbers: \\[ \\begin{bmatrix} d_0 \\\\ \\vdots \\\\ d_{n-1} \\end{bmatrix} = \\mathtt{ReconstructData}(d_{j_0}, \\ldots, d_{j_{n-k-1}}, p_0, \\ldots, p_{k-1}) = M^{-1} \\cdot \\begin{bmatrix} d_{j_0} \\\\ \\vdots \\\\ d_{j_{n-k-1}} \\\\ p_0 \\\\ \\vdots \\\\ p_{k-1} \\end{bmatrix}\\text{.} \\] As an optimization, some rows of \\(M^{-1}\\) correspond to just shuffling around the known data bytes \\(d_{j_*}\\), so we can just remove those rows, compute the missing data bytes, and do the shuffling ourselves. and , but we still have missing pieces. In particular, How do we compute matrix inverses? How do we generate \u201coptimal\u201d parity matrices so that \\(M^{-1}\\) always exists? How do we compute parity bytes instead of parity numbers? So we now have outlines of implementations of bothand, but we still have missing pieces. In particular, So first, let\u2019s see how to compute matrix inverses using row reduction.\n\nWe developed the theory of matrices by identifying them with linear functions of numbers. To show how to find matrix inverses, we have to look at them in a slightly different way by identifying matrix equations with systems of linear equations of numbers. For example, consider the matrix equation \\[ M \\cdot x = y\\text{,} \\] where \\[ M = \\begin{pmatrix} 1 & 2 \\\\ 3 & 4 \\end{pmatrix}\\text{,} \\quad x = \\begin{bmatrix} x_1 \\\\ x_2 \\end{bmatrix} \\text{,} \\quad \\text{and } y = \\begin{bmatrix} y_1 \\\\ y_2 \\end{bmatrix}\\text{.} \\] This expands to \\[ \\begin{pmatrix} 1 & 2 \\\\ 3 & 4 \\end{pmatrix} \\cdot \\begin{bmatrix} x_1 \\\\ x_2 \\end{bmatrix} = \\begin{bmatrix} y_1 \\\\ y_2 \\end{bmatrix}\\text{,} \\] or \\[ \\begin{aligned} y_1 &= 1 \\cdot x_1 + 2 \\cdot x_2 \\\\ y_2 &= 3 \\cdot x_1 + 4 \\cdot x_2\\text{,} \\end{aligned} \\] which is a linear system of equations of numbers. Letting \\(M\\) be any matrix, and \\(x\\) and \\(y\\) be appropriately-sized column matrices of variables, we can see that the matrix equation \\(M \\cdot x = y\\) is shorthand for a system of linear equations of numbers. If we could find \\(M^{-1}\\), we could solve the matrix equation easily by multiplying both sides by it: \\[ \\begin{aligned} M^{-1} \\cdot (M \\cdot x) &= M^{-1} \\cdot y \\\\ x &= M^{-1} \\cdot y\\text{,} \\end{aligned} \\] and therefore solve the linear system for \\(x\\) in terms of \\(y\\). Conversely, if we were able to solve the linear system for \\(x\\), we\u2019d then be able to read off \\(M^{-1}\\) from the new linear system. adding one equation to another, possibly multiplying the equation by a number before adding. But how do we solve a linear system? From the theory of linear systems of equations, we have a few tools at our disposal: All of these are valid transformations because they don\u2019t change the solution set of the linear system. For example, in the equation above, the first step would be to subtract \\(3\\) times the first equation from the second equation to yield \\[ \\begin{aligned} y_1 &= x_1 + 2 \\cdot x_2 \\\\ y_2 - 3 \\cdot y_1 &= -2 \\cdot x_2\\text{.} \\end{aligned} \\] Then, add the second equation back to the first equation: \\[ \\begin{aligned} y_2 - 2 \\cdot y_1 &= x_1 \\\\ y_2 - 3 \\cdot y_1 &= -2 \\cdot x_2\\text{.} \\end{aligned} \\] Finally, divide the second equation by \\(-2\\): \\[ \\begin{aligned} y_2 - 2 \\cdot y_1 &= x_1 \\\\ (3/2) \\cdot y_1 - (1/2) \\cdot y_2 &= x_2\\text{.} \\end{aligned} \\] This is equivalent to the matrix equation \\[ \\begin{pmatrix} -2 & 1 \\\\ 3/2 & -1/2 \\end{pmatrix} \\cdot \\begin{bmatrix} y_1 \\\\ y_2 \\end{bmatrix} = \\begin{bmatrix} x_1 \\\\ x_2 \\end{bmatrix}\\text{,} \\] so \\[ M^{-1} = \\begin{pmatrix} -2 & 1 \\\\ 3/2 & -1/2 \\end{pmatrix}\\text{.} \\] So how do we translate the above process to an algorithm operating on matrices? First, express our matrix equation in a slightly different form: \\[ M \\cdot x = I \\cdot y\\text{.} \\] Using the example above, this is \\[ \\begin{pmatrix} 1 & 2 \\\\ 3 & 4 \\end{pmatrix} \\cdot \\begin{bmatrix} x_1 \\\\ x_2 \\end{bmatrix} = \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix} \\cdot \\begin{bmatrix} y_1 \\\\ y_2 \\end{bmatrix}\\text{.} \\] Then, you can see that the first step above corresponds to subtracting \\(-3\\) times the first row from the second row to yield: \\[ \\begin{pmatrix} 1 & 2 \\\\ 0 & -2 \\end{pmatrix} \\cdot \\begin{bmatrix} x_1 \\\\ x_2 \\end{bmatrix} = \\begin{pmatrix} 1 & 0 \\\\ -3 & 1 \\end{pmatrix} \\cdot \\begin{bmatrix} y_1 \\\\ y_2 \\end{bmatrix}\\text{.} \\] We don\u2019t even need to keep writing the \\(x\\) and \\(y\\) column matrices; we can just write the \u201caugmented\u201d matrix. \\[ A = \\begin{pmatrix} 1 & 2 & | & 1 & 0 \\\\ 0 & -2 & | & -3 & 1 \\end{pmatrix} \\] and operate on it. swapping two equations corresponds to swapping two rows; multiplying an equation by a number corresponds to multiplying a row by a number; and adding an equation to another, possibly multiplying the equation by a number before adding, corresponds to adding a row to another row, possibly multiplying the row by a number before adding. Then, the goal is to use these row operations to transform the initial augmented matrix, where the right side looks like the identity matrix, into one where the left side looks like the identity matrix. Then, translating the augmented matrix back into a matrix equation, that would give \\(M^{-1}\\) on the right side.[4] Thus, the operations listed above on linear systems have corresponding operations on augmented matrices:Then, the goal is to use these row operations to transform the initial augmented matrix, where the right side looks like the identity matrix, into one where the left side looks like the identity matrix. Then, translating the augmented matrix back into a matrix equation, that would give \\(M^{-1}\\) on the right side. Turn the left side of \\(A\\) into a unit upper triangular matrix, which means that all the elements on the main diagonal are \\(1\\), and all elements below the main diagonal are \\(0\\), i.e. that \\(a_{ii} = 1\\) for all \\(i\\), and \\(a_{ij} = 0\\) for all \\(j > i\\). Then turn the left side of \\(A\\) into the identity matrix. This algorithm is called For each column \\(i\\) of the left side in ascending order: If \\(a_{ii}\\) is zero, look at the rows below the \\(i\\)th row for a row \\(j > i\\) such that \\(a_{ji} \n\ne 0\\), and swap rows \\(i\\) and \\(j\\). If no such row exists, return an error, as that means that \\(A\\) is non-invertible. Divide the \\(i\\)th row by \\(a_{ii}\\), so that \\(a_{ii} = 1\\). For each row \\(j > i\\), subtract \\(a_{ji}\\) times the \\(i\\)th row from it, which will set \\(a_{ji}\\) to \\(0\\). The second step can be similarly broken down: For each column \\(i\\) of the left side, in order: For each row \\(j < i\\), subtract \\(a_{ji}\\) times the \\(i\\)th row from it, which will set \\(a_{ji}\\) to \\(0\\). When doing this by hand, one usually works with the linear system itself, trying to see which variables can be easily eliminated so as to minimize arithmetic. However, to translate this to an algorithm, we\u2019re more interested in a systematic way of doing this. Fortunately, there\u2019s an easy two-step process:This algorithm is called row reduction . The first step can be further broken down:The second step can be similarly broken down: Note that we\u2019re assuming that all arithmetic is exact, i.e. we use a arbitrary-precision rational number type. If we use floating point numbers, we\u2019d have to worry a lot more about the order in which we do operations and numerical stability. Let The initial augmented matrix is We need to be non-zero, so swap rows and : We need to be 1, so divide row by 3: We need to be 0, so subtract row scaled by 6 from row : We need to be 1, so divide row by 2: We need to be 0, so subtract row scaled by \u22122 from row : We need to be 1, so divide row by \u22121, which makes the left side of a unit upper triangular matrix: We need to be 0, so subtract row from row : We need to be 0, so subtract row scaled by 5/3 from row : We need to be 0, so subtract row scaled by 4/3 from row , which makes the left side of the identity matrix: Since the left side of is the identity matrix, the right side of is -1. Therefore, LetThe initial augmented matrixisWe needto be non-zero, so swap rowsandWe needto be 1, so divide rowby 3:We needto be 0, so subtract rowscaled by 6 from rowWe needto be 1, so divide rowby 2:We needto be 0, so subtract rowscaled by \u22122 from rowWe needto be 1, so divide rowby \u22121, which makes the left side ofa unit upper triangular matrix:We needto be 0, so subtract rowfrom rowWe needto be 0, so subtract rowscaled by 5/3 from rowWe needto be 0, so subtract rowscaled by 4/3 from row, which makes the left side ofthe identity matrix:Since the left side ofis the identity matrix, the right side ofis. Therefore, Now notice one thing: if \\(M\\) has a row that is proportional to another row, then row reduction would eventually zero out one of the rows, causing the algorithm to fail, and signaling that \\(M\\) is non-invertible. In fact, a stronger statement is true: \\(M\\) has a row that can be expressed as a linear combination of other rows of \\(M\\) exactly when \\(M\\) is non-invertible. Informally, this means that the linear function corresponding to \\(M\\) has one of its outputs redundant with the other outputs, so it is essentially a a linear function taking \\(n\\) inputs to fewer than \\(n\\) outputs, and such functions aren\u2019t invertible. This gets us a partial explanation for what \u201csufficiently different\u201d means for our parity functions. If one parity function is a linear combination of other parity functions, then it is redundant, and therefore not \u201csufficiently different\u201d. Therefore, we want our parity matrix \\(P\\) to be such that no row can be expressed as a linear combination of other rows. However, this criterion for \\(P\\) isn\u2019t quite enough to guarantee that all possible matrices \\(M\\) computed as part of are invertible. For example, this criterion holds for the identity matrix \\(I_n\\), but if \\(n > 1\\) and you pick \\(I_n\\) as the parity matrix for \\(n = m\\), you can certainly end up with a constructed matrix \\(M\\) with repeated rows, since you\u2019re starting by appending another copy of \\(I_n\\) on top of \\(P = I_n\\)! This explains in a different way why simply making a copy of the original data files makes for a poor erasure code, unless of course you only have one data file. We\u2019re led to our next topic: what makes a parity matrix \u201coptimal\u201d?\n\nRecall from above that we form the square matrix \\[ M = \\begin{pmatrix} e_{j_0} \\\\ \\vdots \\\\ e_{j_{n-k-1}} \\\\ p_0 \\\\ \\vdots \\\\ p_{k-1} \\end{pmatrix} \\] by prepending some rows of the identity matrix to the first \\(k\\) rows of the parity matrix. We can generalize this a bit more, since we don\u2019t have to take the first \\(k\\) rows, but instead can take any \\(k\\) rows of the parity matrix, whose indices we denote here as \\(l_0, \\ldots, l_{k-1}\\): \\[ M = \\begin{pmatrix} e_{j_0} \\\\ \\vdots \\\\ e_{j_{n-k-1}} \\\\ p_{l_0} \\\\ \\vdots \\\\ p_{l_{k-1}} \\end{pmatrix}\\text{.} \\] So we want to construct \\(P\\) so that any such square matrix \\(M\\) formed from the rows of \\(P\\) is invertible. Therefore, we call a parity matrix \\(P\\) optimal if it satisfies this criterion. .) A parity matrix \\(P\\) is optimal exactly when any non-empty square submatrix of \\(P\\) is invertible.[5] .) A parity matrix \\(P\\) is optimal exactly when any non-empty square submatrix of \\(P\\) is invertible. Note that this criterion is stronger than the one in the previous section, where we want a parity matrix \\(P\\) to have no row that can be expressed as a linear combination of other rows. That is, if any non-empty square submatrix of \\(P\\) is invertible, that means that no row can be expressed as a linear combination of other rows.[6] However, it is possible to have a matrix \\(P\\) where no row can be expressed as a linear combination of other rows, but which is not optimal. We\u2019ve already seen an example above: \\(I_n\\) for \\(n \\gt 1\\), and indeed, \\[ I_2 = \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix}\\text{,} \\] has the \\(1 \\times 1\\) non-invertible submatrix \\(\\begin{pmatrix} 0 \\end{pmatrix}\\). Fortunately, there is a simpler criterion for optimal parity matrices. First, define a submatrix of a matrix \\(P\\) to be a matrix that you get by deleting any number of rows or columns, and call a matrix non-empty if it has at least one row and one column. Then:Note that this criterion is stronger than the one in the previous section, where we want a parity matrix \\(P\\) to have no row that can be expressed as a linear combination of other rows. That is, if any non-empty square submatrix of \\(P\\) is invertible, that means that no row can be expressed as a linear combination of other rows.However, it is possible to have a matrix \\(P\\) where no row can be expressed as a linear combination of other rows, but which is not optimal. We\u2019ve already seen an example above: \\(I_n\\) for \\(n \\gt 1\\), and indeed, \\[ I_2 = \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix}\\text{,} \\] has the \\(1 \\times 1\\) non-invertible submatrix \\(\\begin{pmatrix} 0 \\end{pmatrix}\\). Recall the parity matrix \\[ P = \\begin{pmatrix} 1 & 1 & 1 \\\\ 1 & 2 & 3 \\end{pmatrix} \\] that we were using for our \\(n = 3, m = 2\\) example. For any \\(n\\), this matrix looks like \\[ P = \\begin{pmatrix} 1 & 1 & \\ldots & 1 \\\\ 1 & 2 & \\ldots & n-1 \\end{pmatrix}\\text{.} \\] A \\(1 \\times 1\\) matrix is invertible exactly when its single element is non-zero, so any \\(1 \\times 1\\) submatrix of \\(P\\) is invertible. Any \\(2 \\times 2\\) submatrix of \\(P\\) looks like \\[ A = \\begin{pmatrix} 1 & 1 \\\\ a & b \\end{pmatrix} \\] for \\(a \n\ne b\\), which, using the formula for inverses of \\(2 \\times 2\\) matrices, has inverse \\[ A^{-1} = \\begin{pmatrix} b/(b-a) & -1/(b-a) \\\\ -a/(b-a) & 1/(b-a) \\end{pmatrix}\\text{.} \\] These are all the possible square submatrices of \\(P\\), so therefore this \\(P\\) is a optimal parity matrix for \\(m = 2\\). Then, finally, we now have a complete definition of what makes a list of parity functions \u201csufficiently different\u201d; it is exactly when the corresponding parity matrix is optimal as we\u2019ve defined it above. Now this leads us to the question: how do we find such optimal matrices? Fortunately, there\u2019s a whole class of matrices that are optimal: the Cauchy matrices. Let \\(a_0, \\ldots, a_{m+n-1}\\) be a sequence of distinct integers, meaning that no two \\(a_i\\) are equal, and let \\(x_0, \\ldots, x_{m-1}\\) be the first \\(m\\) integers of \\(a_i\\) with \\(y_0, \\ldots, y_{n-1}\\) the remaining integers. Then form the \\(m \\times n\\) matrix \\(A\\) by setting its elements according to: \\[ a_{ij} = \\frac{1}{x_i - y_j}\\text{,} \\] which is always defined since the denominator is never zero, by the distinctness of the \\(a_i\\). Then \\(A\\) is a Cauchy matrix. Combining this with the simple fact that any submatrix of a Cauchy matrix is also a Cauchy matrix, we get: ( .) Any non-empty square submatrix of a Cauchy matrix is invertible, and thus any Cauchy parity matrix is optimal. What makes Cauchy matrices useful is the following theorem:Combining this with the simple fact that any submatrix of a Cauchy matrix is also a Cauchy matrix, we get: Let and Then, the Cauchy matrix constructed from and is which has inverse Therefore, to generate a optimal parity matrix for any \\((n, m)\\), all we need to do is to generate an \\(m \\times n\\) Cauchy matrix. We can pick any sequence of distinct \\(m + n\\) integers, so for simplicity let\u2019s just use \\[ x_i = n + i \\quad \\text{and} \\quad y_i = i\\text{.} \\] For \\(n = 3, m = 2\\), we have the sequences \\[ x_0 = 3, x_1 = 4 \\quad \\text{and} \\quad y_0 = 0, y_1 = 1, y_2 = 2\\text{,} \\] so the corresponding Cauchy parity matrix is \\[ P = \\begin{pmatrix} 1/3 & 1/2 & 1 \\\\ 1/4 & 1/3 & 1/2 \\end{pmatrix}\\text{.} \\] Similarly, for any \\(n\\), \\[ P = \\begin{pmatrix} 1/n & \\cdots & 1/2 & 1 \\\\ 1/{n + 1} & \\cdots & 1/3 & 1/2 \\end{pmatrix}\\text{.} \\] All entries of \\(P\\) are non-zero, so any \\(1 \\times 1\\) submatrix of \\(P\\) is invertible. Any \\(2 \\times 2\\) submatrix of \\(P\\) looks like \\[ A = \\begin{pmatrix} 1/a & 1/b \\\\ 1/(a+1) & 1/(b+1) \\end{pmatrix} \\] for \\(a \n\ne b\\), which, using the formula for inverses of \\(2 \\times 2\\) matrices, has inverse \\[ A^{-1} = \\begin{pmatrix} \\frac{ab(a+1)}{b-a} & -\\frac{a(a+1)(b+1)}{b-a} \\\\ -\\frac{ab(b+1)}{b-a} & \\frac{b(a+1)(b+1)}{b-a} \\end{pmatrix}\\text{.} \\] These are all the possible square submatrices of \\(P\\), so therefore this \\(P\\) is a optimal parity matrix for \\(m = 2\\). Note that our first parity matrix for \\(n = 3, m = 2\\) isn\u2019t a Cauchy matrix, since no Cauchy matrix can have repeating elements in a single row. That means that there are other possible optimal parity matrices that aren\u2019t Cauchy matrices.[7] Also, our previous parity matrices had integers, and Cauchy matrices have rational numbers (i.e., fractions). This means that our parity numbers are now fractions. This isn\u2019t a serious difference, though, since we\u2019d have to deal with fractions when computing matrix inverses anyway. You could also change a parity matrix with fractions into one without by simply multiplying the entire matrix by some non-zero number that gets rid of all the fractions, which doesn\u2019t change the optimality of the matrix. For example, we can multiply \\[ \\begin{pmatrix} 1/3 & 1/2 & 1 \\\\ 1/4 & 1/3 & 1/2 \\end{pmatrix} \\] by \\(12\\) to get the equivalent parity matrix \\[ \\begin{pmatrix} 4 & 6 & 12 \\\\ 3 & 4 & 6 \\end{pmatrix}\\text{.} \\] Now our only remaining missing piece is this: how do we compute parity bytes instead of parity numbers? Answering this would render the above discussion moot. However, to do so, we first have to take another look at how we\u2019re doing linear algebra.\n\nWe ultimately want our parity numbers to be parity bytes, which means that we want to work with matrices of bytes instead of matrices of rational numbers. In order to do that, we need to define an interface for matrix elements that preserves the operations and properties we care about, and then we have to figure out how to implement that interface using bytes. Looking at the rule for matrix multiplication, we need to be able to add and multiply matrix elements. Looking at how we do matrix inversion, we also need to be able to subtract and divide matrix elements. Finally, there are certain properties that hold for rational numbers that we implicitly assume when doing matrix operations, but that we have to make explicit for matrix elements. This leads us to the concept of a field, which essentially defines the interface that matrix elements should implement. Here it is: We need to be able to add and multiply field elements, which we\u2019ll denote generically by \\(\\oplus\\) and \\(\\otimes\\). We also need to be able to take the negation (additive inverse) of an element \\(x\\), which we\u2019ll denote by \\(-x\\), and the reciprocal (multiplicative inverse) of a non-zero element \\(x\\), which we\u2019ll denote by \\(x^{-1}\\). Then we can define subtraction of field elements to be \\[ a \\ominus b = a \\oplus -b \\] and division of field elements to be \\[ a \\cldiv b = a \\otimes b^{-1}\\text{,} \\] when \\(b \n\ne 0\\). must satisfy further properties, which are copied from the number laws you learn in school: Associativity: \\((a \\oplus b) \\oplus c = a \\oplus (b \\oplus c)\\), and \\((a \\otimes b) \\otimes c = a \\otimes (b \\otimes c)\\). Of the above, guaranteeing the existence of reciprocals of non-zero elements is usually the non-trivial part. Now the rational numbers satisfy all of the above, since \\[ (p/q)^{-1} = q/p\\text{,} \\] so we say that they form a field. However, the integers do not form a field, since for example \\(2\\) has no integer reciprocal; only \\(1\\) and \\(-1\\) have integer reciprocals. Furthermore, as we saw above, the integers modulo \\(256\\), i.e. the numbers from \\(0\\) to \\(255\\) with standard arithmetic operations modulo \\(256\\), do not form a field, as we saw earlier, since \\((2 \\cdot b) \\bmod 256 \n\ne 1\\) for any \\(b\\). Also, an implementation ofmust satisfy further properties, which are copied from the number laws you learn in school:Of the above, guaranteeing the existence of reciprocals of non-zero elements is usually the non-trivial part. Now the rational numbers satisfy all of the above, since \\[ (p/q)^{-1} = q/p\\text{,} \\] so we say that they form a field. However, the integers do not form a field, since for example \\(2\\) has no integer reciprocal; only \\(1\\) and \\(-1\\) have integer reciprocals. Furthermore, as we saw above, the integers modulo \\(256\\), i.e. the numbers from \\(0\\) to \\(255\\) with standard arithmetic operations modulo \\(256\\), do not form a field, as we saw earlier, since \\((2 \\cdot b) \\bmod 256 \n\ne 1\\) for any \\(b\\). ( .) Given a prime number \\(p\\), for every integer \\(0 \\lt a \\lt p\\), there is exactly one \\(0 \\lt b \\lt p\\) such that \\((a \\cdot b) \\bmod p = 1\\). There are clever ways to find multiplcative inverses mod \\(p\\), but since \\(257\\) is so small, we can just brute-force it. So an implementation would look like: class Field257Element : implements Field<Field257Element> { plus(b) { return (this + b) % 257 } negate() { return (257 - this) } times(b) { return (this * b) % 257 } reciprocate() { if (this == 0) { return Error } for i := 0 to 256 { if (this.times(b) == 1) { return i; } } return Error } ... } However, we can construct a field with \\(257\\) elements, using the fact that \\(257\\) is a prime number, and the following theorem:There are clever ways to find multiplcative inverses mod \\(p\\), but since \\(257\\) is so small, we can just brute-force it. So an implementation would look like: Denote operations on the field with 257 elements by a subscript, and let and Then Denote operations on the field with 257 elements by asubscript, and letandThen instead of a rational number type when implementing and , and if we\u2019ve abstracted our type correctly, almost everything should just work. However, there is one thing we need to check: Are Cauchy parity matrices still optimal if we use fields other than the rational numbers? Fortunately, the answer is yes: ( .) A parity matrix \\(P\\) over any field is optimal exactly when any non-empty square submatrix of \\(P\\) is invertible. ( .) Any non-empty square Cauchy matrix over any field is invertible. ( .) Any square submatrix of a Cauchy matrix over any field is invertible, and thus any Cauchy parity matrix over any field is optimal. However, note that to construct an \\(m \\times n\\) Cauchy matrix, we need \\(m + n\\) distinct elements. So if we\u2019re working with a field with \\(257\\) elements, then this imposes the condition that \\(m + n \\le 257\\), i.e. using a finite field limits the number of data bytes and parity numbers you can have. So this gets us closer, since we can useinstead of a rational number type when implementingand, and if we\u2019ve abstracted ourtype correctly, almost everything should just work. However, there is one thing we need to check: Are Cauchy parity matrices still optimal if we use fields other than the rational numbers? Fortunately, the answer is yes:However, note that to construct an \\(m \\times n\\) Cauchy matrix, we need \\(m + n\\) distinct elements. So if we\u2019re working with a field with \\(257\\) elements, then this imposes the condition that \\(m + n \\le 257\\), i.e. using a finite field limits the number of data bytes and parity numbers you can have. Now the question remains: can we construct a field with \\(256\\) elements? As we saw above, we can\u2019t do so the same way as we constructed the field with \\(257\\) elements. In fact, we need to start with defining different arithmetic operations on the integers. This brings us to the topic of binary carry-less arithmetic.\n\nThe basic idea with binary carry-less (which I\u2019ll henceforth shorten to \u201ccarry-less\u201d) arithmetic is to express all integers in binary, then perform all arithmetic operations using binary arithmetic, except ignoring all the carries.[8] How does this work with addition? Let\u2019s denote binary carry-less add as \\(\\clplus\\),[9] and let\u2019s see how it behaves on single binary digits: \\[ \\begin{aligned} 0 \\clplus 0 &= 0 \\\\ 0 \\clplus 1 &= 1 \\\\ 1 \\clplus 0 &= 1 \\\\ 1 \\clplus 1 &= 0\\text{.} \\end{aligned} \\] This is just the exclusive or operation on bits, so if we do carry-less addition on any two integers, it turns out to be nothing but xor! Since xor can also be denoted by \\(\\clplus\\), we can conveniently think of \\(\\clplus\\) as meaning both carry-less addition and xor. Let and Then, with carry-less arithmetic, so What about subtraction? Recall that \\((a \\clplus b) \\clplus b = a\\) for any \\(a\\) and \\(b\\). Therefore, every element \\(b\\) is its own (carry-less binary) additive inverse, which means that \\(a \\clminus b = a \\clplus b\\), i.e. carry-less subtraction is also just xor. Carry-less multiplication isn\u2019t as simple, but recall that binary multiplication is just adding shifted copies of \\(a\\) based on which bits are set in \\(b\\) (or vice versa). To do carry-less multiplication, just ignore carries when adding the shifted copies again, i.e. xor shifted copies instead of adding them. Let and Then, with carry-less arithmetic, so Finally, we can define carry-less division with remainder. Binary division with remainder is subtracting shifted copies of \\(b\\) from \\(a\\) until you get a remainder less than the divisor; then carry-less binary division with remainder is xor-ing shifted copies of \\(b\\) with \\(a\\) until you get a remainder. However, there\u2019s a subtlety; with carry-less arithmetic, it\u2019s not enough to stop when the remainder (for that step) is less than the divisor, because if the highest set bit of the remainder is the same as the highest set bit of the divisor, you can still xor with the divisor one more time to yield a smaller number (which then becomes the final remainder). Consider the example below, where we\u2019re dividing \\(55\\) by \\(19\\). The first remainder is \\(17\\), which is less than \\(19\\), but still shares the same highest set bit, so we can xor one more time with \\(19\\) to get the remainder \\(2\\). Let and Then, with carry-less arithmetic, so with remainder This leads to an interesting difference between the carry-less modulo operation and the standard modulo operation. If you mod by a number \\(n\\), you get \\(n\\) possible remainders, from \\(0\\) to \\(n - 1\\). However, if you clmod (carry-less mod) by a number \\(2^k \\le n \\lt 2^{k+1}\\), you get \\(2^k\\) possible remainders, from \\(0\\) to \\(2^k-1\\), since those are the numbers whose highest set bit is lower than the highest set bit of \\(n\\). In particular, if you clmod by a number \\(256 \\le n < 512\\), you always get \\(256\\) possible remainders. This is very close to what we want\u2014now the hope is to find some \\(256 \\le n < 512\\) so that doing binary carry-less arithmetic clmod \\(n\\) yields a field, which will then be a field with \\(256\\) elements!\n\nNow we have all the pieces we need to construct erasure codes for any \\((n, m)\\) such that \\(m + n \\le 256\\). First, we can compute an \\(m \\times n\\) Cauchy parity matrix over the field with \\(256\\) elements. (Recall that this needs \\(m + n\\) distinct field elements, which is what imposes the condition \\(m + n \\le 256\\).) Working over the field with 256 elements, let and Then, the Cauchy matrix constructed from and is which has inverse Working over the field with 256 elements, letandThen, the Cauchy matrix constructed fromandiswhich has inverse Then we can implement matrix multiplication over arbitrary fields, and thus we can implement . Let be the input data bytes and let be the desired parity byte count. Then, with the input byte count the Cauchy parity matrix computed using and is Therefore, the parity bytes are computed as and thus the output parity bytes are Letbe the input data bytes and letbe the desired parity byte count. Then, with the input byte counttheCauchy parity matrix computed usingandisTherefore, the parity bytes are computed asand thus the output parity bytes are Then we can implement matrix inversion using row reduction over arbitrary fields. Example 14: Matrix inversion via row reduction in general Working over the field with 256 elements, let The initial augmented matrix is We need to be non-zero, so swap rows and : We need to be 1, so divide row by 3: We need to be 0, so subtract row scaled by 6 from row : We need to be 1, so divide row by 2: We need to be 0, so subtract row scaled by 14 from row : We need to be 1, so divide row by 3, which makes the left side of a unit upper triangular matrix: We need to be 0, so subtract row from row : We need to be 0, so subtract row scaled by 3 from row : We need to be 0, so subtract row scaled by 245 from row , which makes the left side of the identity matrix: Since the left side of is the identity matrix, the right side of is -1. Therefore, Working over the field with 256 elements, letThe initial augmented matrixisWe needto be non-zero, so swap rowsandWe needto be 1, so divide rowby 3:We needto be 0, so subtract rowscaled by 6 from rowWe needto be 1, so divide rowby 2:We needto be 0, so subtract rowscaled by 14 from rowWe needto be 1, so divide rowby 3, which makes the left side ofa unit upper triangular matrix:We needto be 0, so subtract rowfrom rowWe needto be 0, so subtract rowscaled by 3 from rowWe needto be 0, so subtract rowscaled by 245 from row, which makes the left side ofthe identity matrix:Since the left side ofis the identity matrix, the right side ofis. Therefore, Finally, we can use that to implement . Let be the input partial data bytes and be the input partial parity bytes. Then, with the data byte count and the parity byte count and appending the rows of the Cauchy parity matrix to the identity matrix, we get where the rows corresponding to the unknown data and parity bytes are crossed out. Taking the first rows that aren\u2019t crossed out, we get the square matrix which has inverse Therefore, the data bytes are reconstructed from the first known data and parity bytes as and thus the output data bytes are Letbe the input partial data bytes andbe the input partial parity bytes. Then, with the data byte countand the parity byte countand appending the rows of theCauchy parity matrix to theidentity matrix, we getwhere the rows corresponding to the unknown data and parity bytes are crossed out. Taking the firstrows that aren\u2019t crossed out, we get the square matrixwhich has inverseTherefore, the data bytes are reconstructed from the firstknown data and parity bytes asand thus the output data bytes are\n\nThanks to Ying-zong Huang, Ryan Hitchman, Charles Ellis, and Josh Gao for comments/corrections/discussion.\n\nLike this post? Subscribe to my feed or follow me on Twitter ."},
{"url": "http://www.businesswire.com/news/home/20171130006234/en/Blue-Apron-Appoints-Brad-Dickerson-Chief-Executive", "link_title": "Blue Apron Appoints Brad Dickerson as CEO", "sentiment": 0.11118914298262127, "text": "NEW YORK--(BUSINESS WIRE)--Blue Apron Holdings, Inc. (NYSE:APRN) today announced that the Company\u2019s Board of Directors has appointed Brad Dickerson as President and Chief Executive Officer. He will assume day-to-day leadership of the Company and will also join Blue Apron\u2019s Board of Directors. Dickerson, a consumer and capital markets veteran, has served as Blue Apron\u2019s Chief Financial Officer since he joined the Company in February 2016. Matt Salzberg, Blue Apron\u2019s co-founder, has stepped down from his role as President and Chief Executive Officer and has been named Executive Chairman. Salzberg will also continue to serve as Chairman of the Board of Directors. The Company has commenced a search for a new Chief Financial Officer.\n\n\u201c It has been a tremendous honor to serve as the CEO of Blue Apron since founding the company and I am incredibly proud of everything our team has accomplished together in just five years,\u201d said Salzberg. \u201c We\u2019ve made meaningful progress toward our top company priorities. Since we completed the transition of volume to our fulfillment center in Linden, New Jersey less than two months ago, our most recent On-Time-In-Full rates have improved to be in line with our other fulfillment centers. Additionally, as expected, our margins since the end of the third quarter have significantly improved.\u201d\n\n\u201c The Board and I are confident that Brad is the right person to build on this momentum,\u201d Salzberg continued. \u201c He is a seasoned leader with significant experience working with the public markets, operating efficiently at scale, and delivering value to shareholders. We are lucky to have him as our next CEO.\u201d\n\nBefore joining Blue Apron, Dickerson, 52, spent eleven years at Under Armour in senior leadership roles including as Chief Financial Officer and Chief Operating Officer. As one of Under Armour\u2019s most tenured executives, Dickerson helped advance the company\u2019s growth strategy, leading strong teams around him that took Under Armour from $200 million to $4 billion in net revenue. As Under Armour\u2019s Chief Operating Officer, he was also instrumental in driving operational efficiencies across the company\u2019s global supply chain that included multiple distribution channels.\n\n\u201c I know that I speak for everyone at Blue Apron in thanking Matt for his leadership and tireless dedication to the company,\u201d said Dickerson. \u201c I am incredibly excited to assume this new role and for the future of the company. We have an exceptionally talented team at Blue Apron that is focused on taking decisive actions to transform the business, continuing to innovate our product in new and diverse ways, and unlocking future growth opportunities. We remain confident in our previously stated financial guidance for the second half of 2017, and I believe we are taking the right steps to move the business forward.\u201d\n\nDickerson will participate in the Raymond James Technology Investors Conference in New York on Monday, December 4, 2017 at 1:15 p.m. Eastern Time. He will also speak at the KeyBanc Capital Markets Consumer Conference featuring Convergence on Wednesday, December 6, 2017 and the Company will meet with investors throughout the day.\n\nA live webcast and replay of the Raymond James session will be available on Blue Apron\u2019s Investor Relations website at investors.blueapron.com.\n\nBlue Apron\u2019s mission is to make incredible home cooking accessible to everyone. Launched in 2012, Blue Apron is reimagining the way that food is produced, distributed, and consumed, and as a result, building a better food system that benefits consumers, food producers, and the planet. The Company has developed an integrated ecosystem that enables the Company to work in a direct, coordinated manner with farmers and artisans to deliver high-quality products to customers nationwide at compelling values.\n\nThis press release includes statements concerning Blue Apron Holdings, Inc. and its future expectations, plans and prospects that constitute \u201cforward-looking statements\u201d within the meaning of the Private Securities Litigation Reform Act of 1995. For this purpose, any statements contained herein that are not statements of historical fact may be deemed to be forward-looking statements. In some cases, you can identify forward-looking statements by terms such as \u201cmay,\u201d \u201cshould,\u201d \u201cexpects,\u201d \u201cplans,\u201d \u201canticipates,\u201d \u201ccould,\u201d \u201cintends,\u201d \u201ctarget,\u201d \u201cprojects,\u201d \u201ccontemplates,\u201d \u201cbelieves,\u201d \u201cestimates,\u201d \u201cpredicts,\u201d \u201cpotential,\u201d or \u201ccontinue,\u201d or the negative of these terms or other similar expressions. Blue Apron has based these forward-looking statements largely on its current expectations and projections about future events and trends that it believes may affect its business, financial condition and results of operations. These forward-looking statements speak only as of the date of this press release and are subject to a number of risks, uncertainties and assumptions including, without limitation, risks related to its announced management and organizational changes, the continued service and availability of key personnel, its ability to expand its product assortments by offering additional products for additional consumer segments, the Company\u2019s anticipated growth strategies, anticipated trends and challenges in its business, and its expectations regarding, and the stability of, its supply chain, and the risks more fully described in the Company\u2019s Quarterly Report on Form 10-Q for the quarter ended September 30, 2017 filed with the U.S. Securities and Exchange Commission (the \u201cSEC\u201d) on November 3, 2017 and other filings that Blue Apron may make with the SEC in the future. Blue Apron assumes no obligation to update any forward-looking statements contained in this press release as a result of new information, future events or otherwise."},
{"url": "https://sleepmode.hetnieuweinstituut.nl/en/calum-robinson", "link_title": "Sleep Mode \u2013 The Art of the Screensaver", "sentiment": 0.039285714285714306, "text": "Although it looked very similar, at the start of development the movement in Flurry was much more frenzied. It looked interesting, but a screensaver should be relaxing in my opinion. I also played around with making it a single colour but settled on the rainbow effect as it provides more interest for the eye.\n\nI had released a few bits of software before and got maybe a few hundred downloads, so I was surprised when I got a few thousand in the first few weeks. When the product manager at Apple emailed me to ask if they could include it in Mac OS X I was completely shocked. At first I thought it would be an extra option for users and after a year or so it would be replaced. But Apple made it the default for over ten years. I always get a kick out of seeing it pop up in unexpected places, like TV shows and movies."},
{"url": "https://www.bloomberg.com/news/articles/2017-12-01/will-uber-ever-stop-the-bleeding", "link_title": "Will Uber Ever Stop the Bleeding?", "sentiment": 0.08275462962962961, "text": "With so many scandals, it's easy to lose track of one of the biggest problems over at Uber's\u00a0San Francisco\u00a0offices: figuring out how to make money, or at least lose less of it.\n\nI got my hands on some never-before-published financials and talked to Uber insiders about what to make of them. The blood-letting is jarring. Over just three months this year, the ride-sharing company\u00a0lost $1.5 billion.\n\nWe're getting this information now because SoftBank and Dragoneer finally launched their bid to buy Uber shares at an implied $48 billion valuation. I'm getting messages from former employees who are trying to figure out the deal. One wrote, \u201cUber. Where longterm former employees ask reporters for information about their tenders.\u201d\n\nInterested Uber shareholders got an overwhelming packet of information on the deal from NASDAQ Private Market, including Uber's financials. A few noble employees read me the numbers over the phone.\n\nHere are the numbers you should pay attention to mixed in with some useful financial information that Uber has\u00a0provided me in the past.\n\nIt's worth noting that in 2015 and 2016, Uber's net revenue included the total fare for the carpooling service UberPool, inflating the amount of revenue. Uber has since changed its accounting practice based on revised GAAP rules, and only includes\u00a0its share of the revenue from UberPool.\n\nOK. What to make of all this? Let's look at the bull case first. Here's how Uber has pitched investors over the years: Focus on gross bookings. That's the figure that reflects the total value of fares paid to drivers. It is a massive number and it keeps doubling.\n\nGross bookings have grown exponentially for years, from $685 million in 2013 to $2.9 billion in 2014 to $8.9 billion in 2015 to $20 billion last year, according to a chart Uber provided in April. Last year, Uber more than doubled at massive scale.\n\nNow look at 2017, Uber has said that its first quarter gross bookings were $7.5 billion. Add that to the gross bookings numbers disclosed to investors and we get to $26 billion over nine months this year. Uber's fourth quarter is traditionally Uber's best quarter thanks to holiday travel. If Uber's fourth quarter grew by half as much as it did last year, it would reach $11 billion. That would translate to $37 billion in gross bookings for the year. Uber would come just short of doubling its gross bookings compared to the previous year.\n\nThe bull case is also buoyed by signs that Uber can increase\u00a0its share of gross bookings, what the company calls its take rate. In the second quarter of this year, Uber's share of gross bookings came in at 19 percent. In the next quarter, Uber took nearly 21 percent. That increase is good news for Uber's shareholders and bad news for drivers. Uber has told investors in the past that it thinks that it can sustainably reach a take rate of from\u00a022 percent to 26 percent of gross bookings.\n\nHOWEVER, unless you're Amazon, eventually you have to make a profit. Enter the bear case.\n\nUber had previously disclosed to investors and the press a number it refers to as \"pro forma adjusted EBIT.\" That is, its loss\u00a0excluding one-time expenses like legal penalties and write-downs. It also excludes interest, taxes and stock-based compensation. According to that way of doing the math, Uber's loss\u00a0was\u00a0only $743 million in the third\u00a0quarter of this year.\n\nI can see why the company likes that number. The question is whether fines, lawsuit settlements and write-downs are unusual or a perpetual feature of Uber's business model. I'd recommend re-reading my story on Uber's legal problems.\n\nUber's true net loss, which the company is disclosing for the first time to investors, is\u00a0jarring. Uber lost $1.46 billion in the third quarter. Uber's loss from continuing operations is on track to significantly surpass the $3.2 billion\u00a0achieved in 2016. (One note: Uber's 2016 loss looks so small because the company\u00a0took credit for the sale of its China business to Didi. Look at operating loss if you want to understand the outflows that year.)\n\nAs worrying as the depths of Uber's loss, is its\u00a0trajectory. Even when you look at the numbers\u00a0as Uber likes to count them,\u00a0the company's loss grew by 15 percent in the third quarter from the previous three months. At the end of the first half of this year, Uber had $6.6 billion cash on hand so it won't run out anytime soon.\n\nAs gross bookings continue to soar, the question remains whether\u00a0Uber will ever be able to make a profit.\n\nThis story also ran on Bloomberg\u2019s technology newsletter Fully Charged.\u00a0Sign up here."},
{"url": "https://hackernoon.com/media-tried-to-trample-us-but-only-helped-us-reach-out-to-1-000-000-users-and-make-money-fb39a90fd0fa", "link_title": "MakeApp. Media tried to trample us but helped reach out to 1M users", "sentiment": 0.18820459054834057, "text": "\u201cWhite supremacist\u201d, \u201cmisogynist\u201d, and \u201cPutin\u2019s spy\u201d are just a few of the names I was called in the US during a week of hype surrounding our MakeApp project. Was I surprised? Yes, I was. Here\u2019s why.\n\nWe are a team of just 10 developers and graphic designers. Our flagship product is the AI-based augmented reality app called Magic. It uses emotion recognition for games and 3D masks.\n\nIt grabbed Apple\u2019s attention and was featured on the App Store time and again.\n\nWith Magic, we were developing a photo-realistic digital makeup technology.\n\nWhile experimenting with it, we found out that neural nets can both apply and remove makeup.\n\n\u201cHmm, that might be interesting,\u201d I thought and suggested that we tap the market using this feature.\n\nAll our Russian team members voted in favor of launching this experiment. Only one team member, Pir, my close friend and a US citizen, was against it.\n\nHe argued that the US media would dismiss this feature and accuse us of sexism. Having lived my whole life in Russia, I could hardly understand what he was talking about. I could not realize what was wrong with this makeup removal function. I listened to all the arguments and decided to keep this feature and release the app.\n\nThe first MakeApp version appeared in the App Store six months ago. We posted it on Product Hunt and caught the eye of Ryan Hoover, its founder.\n\n\u201cOh, that\u2019s great,\u201d we thought and went to bed.\n\nWhen I woke up the next morning to check my email, I could hardly believe my eyes. My inbox was bombarded with dozens of emails from journalists from Japan, South Korea, and China. They all asked me for an interview and comments about MakeApp.\n\nI went to the kitchen and made myself some coffee. I understood what was going on after I looked at the stats. We blew up the Asian market, went viral and topped the App Store ratings.\n\nMakeApp became Asia\u2019s top story. Look, Japan\u2019s TV presenters are loving it!\n\nAsian media were positive about our project, and Twitter users were really excited too. My American friend\u2019s concerns have proved unfounded. \u201cAsia loves us!\u201d\u200a\u2014\u200ahe messaged me.\n\nMedia in China, Japan, South Korea, and Thailand were teeming with very favorable headlines. MakeApp became a bestseller in just one day.\n\nThe project was so celebrated in Asia that China\u2019s Tencent announced that they would develop a competing product.\n\n\u201cCool! Media and users love us! We are on the right track,\u201d our team cheered and continued to pursue this technology.\n\nHalf a year later, we added video processing to MakeApp. I thought it would be great to post the news on BoredPanda. I decided to take celebrities\u2019 videos and pictures as sample images. Their looks are well-known and users can easily recognize them without makeup to see how the technology works.\n\nI prepared photos and GIFs, published them, and shared the links in relevant subreddits.\n\nBoredPanda editors saw the material and shared it on their Facebook pages. We were amazed to see Europe explode this time. MakeApp took the UK by storm, followed by Germany, Sweden, Italy, and others. The Daily Mail repeated my experiment and tested out the app on stars. MakeApp hit the news headlines.\n\nOur happiness knew no bounds! Everyone was thrilled! Everything went great.\n\nWell, it was\u200a\u2014\u200auntil the US media took notice.\n\n\u201cA male Russian propagandist is behind an unflattering AI app that shows how women look without makeup\u201d was the Business Insider headline that marked the start of our story in the USA.\n\nI was disappointed to find out how unprofessional journalists are in these and some other \u201cquality\u201d US media outlets.\n\nMy correspondence with Shona Ghosh showed that her primary interest was to hype the clickbait story rather than to investigate the app and technology. \u201cRussian-Kremlin-spy-sexist-racist\u201d\u200a\u2014\u200aheck, this guy is a dream come true for the yellow press!\n\nFrom our correspondence, I became aware that her agenda was to make me into a wicked monster and the app into a spawn of hell. Which I mentioned to her."},
{"url": "https://www.blog.google/topics/google-cloud/please-welcome-diane-bryant-google-cloud/", "link_title": "Diane Bryant Is Joining Google Cloud as Chief Operating Officer", "sentiment": 0.26300000000000007, "text": "I am happy and excited to announce that Diane Bryant, former Group President at Intel, will be joining Google Cloud as our Chief Operating Officer. I can\u2019t think of a person with more relevant experience and talents. She is an engineer with tremendous business focus and an outstanding thirty-year career in technology.\n\nMost recently, Diane was head of Intel\u2019s Data Center Group, which generated $17 billion in revenue in 2016. Over her five years as Group President, Diane expanded the business to additionally focus on pervasive cloud computing, network virtualization and the adoption of artificial intelligence solutions. Previously, Bryant was Intel\u2019s Corporate Vice President and Chief Information Officer, where she was responsible for corporate-wide information technology solutions and services.\n\nDiane serves on the board of United Technologies. Throughout her career, Diane has worked to mentor and sponsor women in technology.\n\nGoogle Cloud is the most technologically advanced, most highly available, and most open cloud in the world. We are growing at an extraordinary rate as we enable businesses to become smarter with data, increase their agility, collaborate and secure their information. Diane\u2019s strategic acumen, technical knowledge and client focus will prove invaluable as we accelerate the scale and reach of Google Cloud.\n\nI am personally looking forward to working closely with Diane Bryant as we enter what promises to be a great 2018 for Google Cloud."},
{"url": "http://www.linuxjournal.com/content/linux-journal-ceases-publication", "link_title": "Linux Journal Ceases Publication", "sentiment": 0.0, "text": ""},
{"url": "https://www.axios.com/500-startups-still-owes-money-to-its-latest-group-of-startups-2511194808.html", "link_title": "500 Startups still owes money to its latest group of startups", "sentiment": 0.0, "text": "See also: The romanticization of Pablo Escobar and El Chapo..."},
{"url": "https://medium.com/s/just-world-order/how-the-united-states-is-helping-saudi-arabia-destabilize-the-middle-east-b408863289b3", "link_title": "How the United States Is Helping Saudi Arabia Destabilize the Middle East", "sentiment": 0.04878963378963382, "text": "At around two in the morning on August 25, 2017, a five-year-old girl named Buthaina lost her entire family. Saudi Arabia had dropped a bomb on her home and several others in Sana\u2019a, the capital of Yemen, as part of its ongoing campaign against Houthi rebels. The attack killed 16 people, including Buthaina\u2019s parents and four siblings, and injured 17 others.\n\nNow under the care of her aunt and uncle, Buthaina herself was one of the injured. Images of Buthaina trying to open her bruised eyes went viral after the attack.\n\nWhere does Saudi Arabia get the bombs it uses to kill all these people?\n\nFor the most part, they come from the United States, with the United Kingdom and France also supplying substantial amounts. According to the Stockholm International Peace Research Institute, from 1950 to 2016, the United States provided Saudi Arabia with more than $34 billion worth of arms, while the United Kingdom provided more than $10 billion, and France provided more than $7 billion.\n\nThe United States is the world\u2019s leading arms exporter, and Saudi Arabia is its top client.\n\nThe bomb that injured Buthaina and killed her family originated in the United States, as an Amnesty International investigation found.\n\nButhaina and her family are just a few of the victims of the long-standing U.S.-Saudi alliance\u2014an alliance that has allowed Saudi Arabia to remain one of the worst human rights abusers in the world, export its odious Wahhabi interpretation of Islam, and inspire jihadist movements throughout the world, at the cost of thousands of lives.\n\nThe basis for the U.S.-Saudi alliance is the fact that Saudi Arabia sits on top of a lot of oil, as well as its opposition to actors and movements in the region that run counter to U.S. hegemonic ambitions.\n\nNowadays, the United States gets most of its oil through domestic production or from Canada. (The United States is now the world\u2019s leading oil producer, with Saudi Arabia a close second.) Just 11 percent of the oil that the United States imports comes from Saudi Arabia.\n\nDespite this, the United States\u200a\u2014\u200aunder both Republican and Democratic administrations\u200a\u2014\u200ahas backed Saudi Arabia and will likely continue to do so in the future.\n\nAlthough the United States is currently enjoying its own oil boom, it\u2019s likely to be short-lived. Domestic oil production will probably begin to decline around 2020, as the United States has proven reserves of just 10 billion barrels. The Saudis and their OPEC partners, Kuwait and the United Arab Emirates, on the other hand, have proven reserves of 460 billion barrels.\n\nIn 1945, the State Department identified Saudi Arabia\u2019s oil resources as \u201ca stupendous source of strategic power, and one of the greatest material prizes in world history.\u201d That hasn\u2019t changed\u200a\u2014\u200aand there\u2019s no reason Washington won\u2019t want Saudi Arabia to remain firmly inside its camp.\n\nIn addition, if all those massive arms deals between Washington and Riyadh were suddenly to stop, defense contractors like Lockheed Martin, Raytheon, and General Dynamics would stand to lose lots of money.\n\nFurthermore, Saudi Arabia\u2019s extremist variant of Islam has been very useful for the United States. Despite the rhetoric about a \u201cclash of civilizations\u201d supposedly happening between the West and Islam, the United States has, for the most part, traditionally sided with extremist sects of Islam against their more secular enemies for the simple reason that those secular enemies would rather remain independent of U.S. domination.\n\nThe U.S.-Saudi relationship began in the 1930s but strengthened after Gamal Abdel Nasser became president of Egypt in 1956. Nasser, a neutralist and secularist during the Cold War, nationalized many of Egypt\u2019s industries and instituted social welfare measures. For these crimes, he was considered \u201can extremely dangerous fanatic\u201d with a \u201cHitler-ite personality\u201d by Secretary of State John Foster Dulles.\n\nSince Nasser had widespread prestige throughout the Arab world for his anti-imperialism and independence, the United States needed a counterweight in the region. \u201cThe people are on Nasser\u2019s side,\u201d as Eisenhower complained. That counterweight was Saudi Arabia, an absolute monarchy and the only country in the world named after a ruling family (the Al Saud family).\n\nThe U.S.-Saudi relationship took on new urgency in 1979, when Iran overthrew its U.S.-installed dictator. The United States and United Kingdom had overthrown Iran\u2019s democratically elected government in 1953, because its secular leader, Mohammed Mossadegh, had nationalized Iran\u2019s oil industry.\n\nWith the loss of its ally in Iran, U.S. support for Saudi Arabia would now be based not only on the kingdom\u2019s opposition to secular nationalist movements and governments, but also against the Shia theocracy in Iran.\n\nU.S. opposition to Iran has nothing to do with Iran\u2019s human rights record or its authoritarian government. If it were, the United States would not be supporting Saudi Arabia, which has a much worse human rights record and a more authoritarian government. Unlike Saudi Arabia, Iran has actual elections, women have some kind of rights, and there is a liberal opposition.\n\nNor is U.S. opposition to Iran based on Iran\u2019s support for \u201cextremist\u201d groups abroad\u200a\u2014\u200abecause, again, Saudi Arabia supports and inspires much worse extremist groups abroad.\n\nWatch this dumbfounded State Department official trying to explain the contradiction between U.S. support for Saudi Arabia while opposing Iran:\n\nThe truth is, Iran just isn\u2019t a threat to the United States. Its military budget is $13 billion, equivalent to about 2 percent of the U.S. military budget of $611 billion, the highest in the world. (Saudi Arabia\u2019s military budget is $64 billion, the fourth highest in the world.) Iran does not have nuclear weapons, nor does it have a nuclear weapons program. As the Defense Department has pointed out, \u201cIran\u2019s military doctrine is primarily defensive.\u201d\n\nWhy, then, does the United States take such an antagonistic attitude toward Iran?\n\nThe answer is simple: Iran refuses to subordinate itself to U.S. hegemony. Anybody who doesn\u2019t follow orders is an enemy.\n\nAs a 2004 report from the Pentagon\u2019s Defense Science Board explains, \u201cMuslims do not \u2018hate our freedom,\u2019 but rather, they hate our policies,\u201d which includes the \u201clongstanding, even increasing support for what Muslims collectively see as tyrannies,\u201d such as Saudi Arabia.\n\nSaudi Arabia is a totalitarian dictatorship, an absolute monarchy currently ruled by the 81-year-old King Salman. However, his son and heir to the throne, the 32-year-old Mohammad bin Salman, is thought to be the de facto leader because King Salman suffers from dementia.\n\nMohammad bin Salman, also known as MBS, has announced a slew of initiatives and \u201creforms\u201d meant to modernize Saudi Arabia\u2019s economy and improve Saudi Arabia\u2019s image abroad. For example, Saudi Arabia recently ended its ban on women driving.\n\nFor the most part, however, Saudi Arabia remains the human rights horror story it\u2019s always been. There are no national elections or political parties. The extremist Wahhabi interpretation of Sunni Islam is the official state religion, and the public practice of any religion outside of Islam is illegal.\n\nFreedom of expression does not exist. Saudi Arabia\u2019s anti-terrorism laws \u201ccreate a legal framework that appears to criminalize virtually all dissident thought or expression as terrorism,\u201d as Human Rights Watch documents. In Saudi Arabia, \u201cterrorist acts\u201d include:\n\nSaudi Arabia is more gender-segregated than any other country in the world. As Amnesty International explained in its annual review of Saudi Arabia, \u201cWomen remained legally subordinate and inferior in status to men in relation to marriage, divorce, child custody and inheritance, and could not access higher education, take paid employment or travel abroad without the approval of their male guardian.\u201d\n\nThe death penalty is applied liberally in the kingdom, including for nonviolent offenses such as \u201cwitchcraft and sorcery,\u201d and while juveniles cannot be executed, they can be sentenced to death\u200a\u2014\u200ameaning, if a child receives a death sentence, he or she is held until turning 18, at which point the execution is carried out.\n\nSaudi Arabia executed at least 154 people in 2016. (The United States, meanwhile, shamefully retained its status as the only Western government to execute its citizens, killing 20 people in 2016.)\n\nExecutions are often carried out with a public beheading and sometimes followed by crucifixion\u200a\u2014\u200ameaning after the execution is carried out, the body is displayed publicly for a time. Ali al-Nimr, for example, has been sentenced to die by way of beheading and crucifixion for the \u201ccrime\u201d\u200a\u2014\u200acommitted at the age of 16\u200a\u2014\u200afor \u201cgoing out to a number of marches, demonstrations, and gatherings against the state and repeating some chants against the state,\u201d among other things.\n\n\u201cDonors in Saudi Arabia constitute the most significant source of funding to Sunni terrorist groups worldwide,\u201d as Secretary of State Hillary Clinton wrote in classified cables in 2009. While Riyadh \u201ctakes seriously the threat of terrorism within Saudi Arabia, it has been an ongoing challenge to persuade Saudi officials to treat terrorist financing emanating from Saudi Arabia as a strategic priority,\u201d she explained.\n\nIn other words, Saudi Arabia is generally content to allow Sunni-based extremist groups to continue operating, as long as they remain outside the kingdom and do not target Saudi leadership. This is because Sunni-based extremist groups largely align with Saudi Arabia\u2019s interest in undermining Iran and Iran\u2019s Shia allies across the Middle East.\n\nAs the journalist Ben Norton writes for Salon, \u201cThe Saudi regime has spent an estimated $100 billion exporting its extremist interpretation of Islam worldwide\u201d over the past few decades by \u201c[infusing] its fundamentalist ideology in the ostensible charity work it performs, often targeting poor Muslim communities in countries like Pakistan or places like refugee camps, where uneducated, indigent, oppressed people are more susceptible to it.\u201d\n\nSaudi Arabia is an ISIS \u201cthat has made it,\u201d in the words of Algerian journalist Kamel Daoud. The Saudi kingdom \u201crelies on an alliance with a religious clergy that produces, legitimizes, spreads, preaches and defends Wahhabism, the ultra-puritanical form of Islam that Daesh [ISIS] feeds on,\u201d he writes.\n\nIn the 1980s, Saudi Arabia matched dollar for dollar what the United States was spending on its CIA program funding the mujaheddin in Afghanistan. Most of these funds went to extremists such Gulbuddin Hekmatyar, despite his known habit for throwing acid in women\u2019s faces.\n\nToday, Saudi Arabia is creating a humanitarian catastrophe in Yemen, with U.S. support. Since 2015, Saudi Arabia has been bombing Yemen to defeat the Houthis, a group that Saudi Arabia accuses of being proxies for Iran\u200a\u2014\u200aan exaggerated claim."},
{"url": "https://medium.com/@francesc/source-d-why-i-left-google-71240c0f0204", "link_title": "Why I left Google", "sentiment": 0.22813427643784784, "text": "On November 1st I left Google and in my goodbye note I sneakily said I would \u201ctry my luck in a small startup with huge potential\u201d. A month has passed, and the time to explain more has come. So let me tell you what I\u2019m up to lately.\n\nI am now the VP of Developer Relations at source{d}. Maybe you\u2019ve never heard about it, maybe you\u2019ve heard a bit, or used some of their awesome open source libraries such as go-git, kmcuda, go-kallax, or proteus.\n\nBefore I tell you about what source{d} does, let me give you a bit of context.\n\nFor maintainers of any large codebase, such as open source projects or large tech companies, it is essential to be able to understand their codebases. Critical decisions from a business and engineering perspectives are made based on this information.\n\nA year ago I wrote an article on how one could use Bigquery to analyze all of the Go code available on GitHub.\n\nLater on, this kind of analysis started to become a requirement to justify additions to Go\u2019s standard library.\n\nFor instance, the function was added to Go with this proposal after an analysis of how many times we could find an equivalent piece of code on GitHub.\n\nThis approach is powerful, but it definitely has its limitations.\n\nFirst of all, it limits the analysis we can perform to regular expressions on source code. Most questions require a deeper understanding of the structure of source code, such as the abstract syntax tree, or even type information.\n\nAdditionally, when I said \u201call of the repositories on GitHub\u201d this was not completely accurate, it is a partial dump of all of those repositories, and even if it was complete many other repositories are not on GitHub: what about the Unix kernel?\n\nSo what does source{d} do? They\u00a0\u2026 We! provide a powerful platform to access all of this data in an easier and more powerful way.\n\nRather than limiting repositories on GitHub, source{d} is able to analyze any code repository in the world, including those that are not even on the internet by running our open source software on your own premise. We\u2019re very proud of the pipeline we\u2019re building to ingest every public git repo in the world.\n\nSecondly, we consider that the input to many good analysis should be the abstract syntax tree of a program rather than the flat suite of bytes that is the source code. We believe this so much that we\u2019ve created Babelfish, a project that one day will be able to parse any programming language and generate an abstract syntax tree in a universal format. We call this format a universal abstract syntax tree or UAST.\n\nFinally, while we love regular expressions, we believe that Machine Learning will revolutionize how we analyze programs. There\u2019s a never-ending list of use cases that could benefit from ML over source code: autocompletion (that doesn\u2019t require a connection to a 3rd party server), code linters, architecture analyzers, automated code reviews, and (one day) source code generation from unit tests or even natural language specifications.\n\nIf you\u2019re curious, you should go see our papers and blog posts on these topics.\n\nWhat\u2019s my favorite part of the company? The incredibly incredibly talented team tackling problems at different layers:\n\nBut the applications team at source{d} is not the only one building applications, because we\u2019re building a platform. We want to empower every developer with access to the largest code dataset and the most advanced ML tools, so with our tech and your creativity we can improve how fifty million developers in the world write code.\n\nAs VP of Developer Relations my job is to strategize how source{d} can empower developers all around the world to write better code by:\n\nsource{d} is building a platform by developers where developers can build tools for developers (*). So imagine how excited I am to be right in the center of this hurricane of Developer Relations.\n\nJoin the source{d} community slack channel, follow us on twitter, or drop me a line on francesc@sourced.tech.\n\nI\u2019m incredibly excited about the new opportunities that ML on code provides. Together we can build better tools, for better source code, for eventually a better world."},
{"url": "https://en.wikipedia.org/wiki/List_of_religious_populations", "link_title": "How Did Christianity Manage to Grow into 3 Continents?", "sentiment": 0.16088186813186814, "text": "This is a list of religious populations by number of adherents and countries.\n\nAdherents.com says \"Sizes shown are approximate estimates, and are here mainly for the purpose of ordering the groups, not providing a definitive number\".[2]\n\nCountries with the greatest proportion of Christians from Christianity by country (as of 2010 ):\n\nCountries with the greatest proportion of Muslims from Islam by country (as of 2010 ) (figures excluding foreign workers in parenthesis):\n\nRemarks: Saudi Arabia does not include other religious beliefs in their census, the figures for these other religious groups could be higher than reported in the nation. While conversion to Islam is among its most supported tenets, conversion from Islam to another religion is considered to be the sin of apostasy[49] and could be subject to the penalty of death in the country.\n\nCountries with the greatest proportion of people without religion (including agnostics and atheists) from Irreligion by country (as of 2007 ):\n\nRemarks: Ranked by mean estimate which is in brackets. Irreligious includes agnostic, atheist, secular believer, and people having no formal religious adherence. It does not necessarily mean that members of this group don\u2032t belong to any religion. Some religions have harmonized with local cultures and can be seen as a cultural background rather than a formal religion. Additionally, the practice of officially associating a family or household with a religious institute while not formally practicing the affiliated religion is common in many countries. Thus, over half of this group is theistic and/or influenced by religious principles, but nonreligious/non-practicing and not true atheists or agnostics.[2] See Spiritual but not religious.\n\nCountries with the greatest proportion of Hindus from Hinduism by country (as of 2010 ):\n\nCountries with the greatest proportion of Buddhists from Buddhism by country (as of 2010 ):[81]\n\nAs a spiritual practice, Taoism has made fewer inroads in the West than Buddhism and Hinduism. Despite the popularity of its great classics the I Ching and the Tao Te Ching, the specific practices of Taoism have not been promulgated in America with much success;[82] these religions are not ubiquitous worldwide in the way that adherents of bigger world religions are, and they remain primarily an ethnic religion. Nonetheless, Taoist ideas and symbols such as Taijitu have become popular throughout the world through Tai Chi Chuan, Qigong, and various martial arts.[83]\n\nThe Chinese traditional religion has 184,000 believers in Latin America, 250,000 believers in Europe, and 839,000 believers in North America as of 1998 .[89][90]\n\nAll of the below come from the U.S Department of State 2009 International Religious Freedom Report,[91] based on the highest estimate of people identified as indigenous or followers of indigenous religions that have been well-defined. Due to the syncretic nature of these religions, the following numbers may not reflect the actual number of practitioners.\n\nCountries with the greatest proportion of Sikhs:\n\nThe Sikh homeland is the Punjab state, in India, where today Sikhs make up approximately 61% of the population. This is the only place where Sikhs are in the majority. Sikhs have emigrated to countries all over the world \u2013 especially to English-speaking and East Asian nations. In doing so they have retained, to an unusually high degree, their distinctive cultural and religious identity. Sikhs are not ubiquitous worldwide in the way that adherents of larger world religions are, and they remain primarily an ethnic religion. But they can be found in many international cities and have become an especially strong religious presence in the United Kingdom and Canada.[112]\n\nCountries with the greatest proportion of Jews (as of 2010 ):\n\nNote that all these estimates come from a single source. However, this source gives a relative indication of the size of the Spiritist communities within each country.\n\nCountries with the greatest proportion of Bah\u00e1'\u00eds (as of 2010 ) with a national population \u2265200,000:\n\nLargest Bah\u00e1'\u00ed populations (as of 2010 ) in countries with a national population \u2265200,000:[143]"},
{"url": "https://simpleintelligence.com/", "link_title": "Marketplace for Deep Learning Models", "sentiment": 0.0, "text": ""},
{"url": "http://nautil.us/issue/20/creativity/rent-arlington-halls-brain", "link_title": "Story of a Genius Brain Implant", "sentiment": 0.12147830446463251, "text": "Eight Hours To Go\n\nThorne hesitated. The clinic\u2019s storefront consisted of a glass elevator that went only down. Below the earth, into the unknown. A sign on its door read in elegant silver script: \u201cRent a Brain Today, Genius Guaranteed.\u201d Thorne could see straight through the waiting elevator to the barren forest beyond. A frigid breeze shuddered through the branches and whipped at his cheeks.\n\nCadence squeezed his hand. It felt cold and clammy, like his own. They\u2019d driven two hours north of Manhattan to reach this famed destination for the wealthy and connected elite. To say they didn\u2019t belong was ironic in its understatement. They were 22 years old, fresh out of Julliard\u2014she, a budding opera singer, he, a jazz pianist\u2014and poorer than the illegal immigrants who squatted in the apartment next door.\n\nBut their doomed prospects had changed since Thorne\u2019s acceptance into the prestigious Arlington Hall Piano Competition, with its grand prize of $100,000 and the promise of international renown. Each pianist would have twenty minutes to improvise\u2014live on stage\u2014the most brilliant and original jazz piece possible, in the grand tradition of 1920s jazz legend Arlington Hall. A handpicked group of music industry power players was going to judge the winner. And then Thorne, in his recurring fantasy, would rise to thunderous applause, his fingers tingling with ecstatic energy, and accept the top prize. The life he dreamed of would fall into place like a perfect arpeggio\u2014the diamond ring he\u2019d soon be able to afford, the touring invitations, the record deal.\n\nThe only problem was his paralyzing fear: What if he froze? It had happened before\u2014multiple times\u2014in concerts far less consequential. For this one, there couldn\u2019t even be any preparation. The contest, after all, was about showcasing creativity on the spot. The emcee was going to assign each player a time and key signature and a first measure. The rest would be up to them.\n\nAt home, alone with his trusty Yamaha keyboard, Thorne could compose with the daring, nuanced complexity that had earned him the honor of a finalist spot. Yet under any sort of public pressure, that boldness flattened to mediocrity. It was as if the creative part of his brain shut down. He couldn\u2019t create anything worthy of playing. His inspiration vanished. His mind stuttered and his fingers betrayed him. He cringed just imaging the humiliation\u2014at Carnegie Hall no less, in front of 2,800 people.\n\nCadence nudged his arm. \u201cYou ready, love? We can\u2019t be late.\u201d\n\n\u201cYou do want this, right?\u201d\n\nHe glanced at the ground. \u201cYeah.\u201d\n\n\u201cYou better, considering how long it\u2019s taken to save\u2014\u201d\n\n\u201cI know,\u201d he said. \u201cI just still kind of feel like it\u2019s cheating.\u201d\n\nShe scoffed, pushing a blonde curl out of her face. \u201cNo one will be able to tell. The implant is the size of a grain of rice.\u201d\n\nShe pressed the \u201cdown\u201d button on the elevator before he could reply.\n\n\u201cThis decision is going to change our lives,\u201d she said. \u201cJust wait.\u201d\n\nOnce they were underground, a perky receptionist led them to a private room that looked more like an executive suite than a doctor\u2019s office. The walls were beveled chrome, and instead of a patient\u2019s exam table draped in thin paper, Thorne sat on a supple leather massage chair. Cadence whistled as she plunked into an identical chair beside him. A mahogany coffee table showcased the clinic\u2019s catalog in a laminated gold binder\u2014the types of brains available for 24-hour rental. Thorne flipped through it while they waited for the micro-neurosurgeon. The brains were listed in descending order of price: Einstein\u2019s was the most in demand, and thus the most expensive, at $10,000 for a day. Shakespeare\u2019s was a close second ($9,500), followed by Leonardo da Vinci\u2019s ($8,750) and Aristotle\u2019s ($8,000). There were dozens of geniuses available in every field throughout history, from philosophy and science to art, music, and literature.\n\nThe procedure straddled the cutting-edge of biotechnology, according to the glossy marketing brochure. Using DNA sequenced from a specimen of the genius, the innovative researchers at Rent a Brain had created a miniscule bionic interface that, when implanted at the base of your skull, re-wired your neuronal processing circuits in the image of the original brain. So you retained your own memories and identity, but you could temporarily experience the world as that genius. After 24 hours, the carbon nanotube implant would dissolve on its own and your brain would revert to its natural state without any lasting effects. The method was safe, patented, and guaranteed to work\u2014just like the slogan promised.\n\nThorne had already picked out his genius months ago: the famously dazzling and fiery Arlington Hall, of course. Cadence liked to joke that it was a no-brainer.\n\nThorne didn\u2019t want to show her now that he was nervous. He couldn\u2019t afford to back out or they would lose the $3,000 deposit.\n\nBut most importantly, the competition was tonight.\n\nWithout the literal guarantee of genius, who knew how badly he might freeze up?\n\nNo one will be able to tell, he reminded himself. It would be their little secret. Once he was rich and famous, he could have the luxury of guilt. Anyway, he knew he deserved to win. This was just going to ensure it.\n\nThere was a knock on the door. An alarmingly young man in a white coat entered. He couldn\u2019t have been older than 26. He offered Thorne a toothy grin and an extra-firm handshake. The embroidery on his lapel read: Dax Weber, M.D.\n\n\u201cAre you the\u2014micro-neurosurgeon?\u201d Thorne asked in dismay. Cadence shot him an admonishing look.\n\n\u201cAt your service,\u201d the kid-doctor said. \u201cDon\u2019t worry, you want someone young. The older guys can\u2019t hang \u2026 their hands are too shaky to do microsurgery.\u201d\n\nHe held up both hands at eye level, and Thorne saw that they were perfectly still. He felt mildly reassured. The doctor turned his back to lift a needle from a tray on the counter. \u201cSo, Arlington Hall, huh? He\u2019s a popular pick. More fun, I hear, than some of our other composers.\u201d\n\n\u201cOh yeah?\u201d Thorne mumbled. His own hands were sweating. The back of his neck was hot and flush. He wondered if he might faint\u2014and then the thought of fainting brought on a wave of dizziness. Cadence stroked his arm as the doctor made small talk.\n\n\u201cA lot of people go for Beethoven but then want a refund when they see how manic he was.\u201d He smirked. \u201cMaybe some brains should come with a warning. But don\u2019t worry\u2014Hall\u2019s a great choice.\u201d\n\nThorne managed a smile, eyeing the needle in his grip. It was at least three inches long.\n\n\u201cSo first I\u2019m going to insert a local anesthetic. You\u2019ll just feel a tiny pinch. Then I\u2019m going to made a small incision and insert the interface\u201d\u2014he held up a tiny black bead smaller than his pinky nail\u2014\u201cstitch it up, and you\u2019ll be good to go. Any questions?\u201d\n\n\u201cAre you sure no one will see it?\u201d\n\n\u201cPositive. Your hair will cover the incision. Ready?\u201d\n\nThorne nodded, thankful for the first time for his thick unruly locks. The doctor approached him brandishing the needle. Thorne grit his teeth at the sting, but numbness quickly set in. Five minutes later, the whole thing was over.\n\nThorne opened his eyes. He hadn\u2019t realized he was squeezing them shut. His head was gently throbbing. But he felt no different yet.\n\nThe doctor winked.\u00a0 \u201cIt takes about twenty minutes to take effect.\u201d\n\n\u201cGreat,\u201d he said weakly. Twenty minutes was exactly how long he had tonight to make or break his career.\n\nSeven Hours To Go\n\nThe transformation struck him without warning, like a blow to the head. A pleasant warmth expanded throughout his skull and then, in the same instant, he noticed a definite internal shift. It was like ten cups of coffee zapping his brain, arousing him to his surroundings in a way he had never experienced. Though he was typically oblivious, he now felt a sense of thrilling presence as he and Cadence walked to their rental car in the clinic\u2019s parking lot.\n\nStrange perceptions bombarded him. The leaves crunching under their feet\u2014step, step, crunch\u2014suddenly reminded him of a drum beat. The hiss of the wind, which before he\u2019d barely registered, now evoked a high-pitched flute. A playful melody emerged in his mind as if without his permission, set to the rhythm of his stride.\n\n\u201cHmm?\u201d He looked down absent-mindedly at his hands, as the swelling orchestra in his head broke off. His fingers were playing a syncopated imaginary top line against his leg. He balled them into fists and stared at her.\n\nShe raised her eyebrows. \u201cYes, you were.\u201d\n\nA slow smile spread across her face, and Thorne realized how beautiful she looked under the dappled light of the dying trees. He wasn\u2019t particularly sentimental\u2014he shied away from displays of affection\u2014but all at once had the urge to take her, right then and there. She was reaching for the car door when he grabbed her wrist and wrapped his arms around her, pressing his mouth hard on hers.\n\n\u201cThorne!\u201d she exclaimed, laughing through the kiss. \u201cWe have to get back so you can get ready\u2014\u201d\n\nHe silenced her with his lips.\n\nThorne had never felt less nervous before a concert. He was scheduled to perform last out of three finalists. As he waited backstage in his dapper black tux, he watched the green room\u2019s flat screen, which was broadcasting the competition on primetime. The sound was off\u2014no contestant was allowed to hear any other, for fairness\u2019s sake\u2014but he was able to watch his first competitor and the audience\u2019s reaction in real time.\n\nShe was Reza Andrews, a well-known rising star in the jazz world, a fellow Juilliard alum whose arrogance was matched only by her indulgence of it. The camera zoomed in on her long French-manicured fingers, which were flying over the ivories as if she couldn\u2019t channel her virtuoso capabilities fast enough. Her sleek black braid swayed as she practically levitated off the piano bench, vibrating with the frantic blur of her hands.\n\nThorne yearned to hear the music she was creating, to judge its merit against the last four hours of earth-shattering practice he had just wrapped up at home. There was no question he was at the top of his powers. (If they could be properly called his.) Never had he felt more creative, more bursting with ideas for chord progressions, bass lines, key changes, melodies. How could Arlington Hall have sustained this level of genius every day of his life? No wonder he\u2019d had a reputation for intensity. The world as Thorne knew it now seemed intractably dull, and he dreaded the moment that the implant would dissolve. The back of his neck itched slightly and he reached up to scratch it, wondering if it was possible to become addicted to another person\u2019s brain. In a way, this was the most intimate experience he\u2019d ever had, even though it was with a guy who was long dead.\n\nOn the screen, Reza finished with an annoying dramatic flourish, and the audience immediately jumped to its feet. Even from his distance backstage, the roars of the crowd penetrated his private green room. Yet he wasn\u2019t worried. Let them lap her up, he thought, feeling generous. In the front row, he saw Cadence standing and clapping obligingly. He couldn\u2019t wait to kiss her later, after he was declared the victor.\n\nThe second finalist was a new hot shot on the jazz circuit, Asa Hudson. He was only 18, but he\u2019d already garnered notice from the mainstream media. A natural talent, he\u2019d never been formally trained\u2014a point of controversy in the snobby jazz world. Winning the competition would forever shut up the critics who called him a poser. Asa took the stage with a little wave, his chubby face flush with anticipation. Thorne felt a stab of pity. He was going to eviscerate the poor kid.\n\nThe twenty minutes of his performance passed quickly. Even though he couldn\u2019t hear it, Thorne found himself riveted to the screen. Asa appeared to launch into his improv with the confidence of someone much more seasoned. He closed his eyes as he played, yet never stumbled or even slowed. He pounded the piano in three definitive final chords and then turned to the audience with a giant grin.\n\nBut when the camera panned to their faces, Thorne gasped. They actually looked angry.\u00a0 Some people were even booing. It made no sense. Asa Hudson froze, glancing wildly back and forth. He seemed just as confused as Thorne felt. The rattled emcee ushered the kid off-stage, waving his arms for the audience to quiet down.\n\nThere was no time to ask questions. Thorne was up next.\n\nYou got this, he thought. Focus.\n\nSomeone knocked on his door. An usher, probably. It was time.\n\nBut when he opened it, Cadence was standing there, terrified and breathless. Her mouth was twisted into a grimace, and she kept rubbing her chest as if to dispel its tightness. She snuck a glance over her shoulder, then slipped into his room and quickly closed the door.\n\n\u201cWhat the hell?\u201c He reached past her for the knob. \u201cI\u2019m about to go on\u2014\u201d\n\nShe looked him straight in the eye. \u201cYou can\u2019t.\u201d\n\nHe wanted to shake her. \u201cCadence, I\u2014\u201d\n\nThorne started to pace. Sweat pooled under his armpits. \u201cI don\u2019t understand \u2026\u201d\n\nBut he did. With the clarity of Hall\u2019s brain, he couldn\u2019t help catching on.\n\n\u201cI saw that kid scratch his neck,\u201d she whispered. \u201cRight before he started playing.\u201d\n\nThorne stared at her in horror.\n\n\u201cAnd that bitch Reza, did you notice when she was swaying, her braid moved?\u201d\n\nShe pressed her fingertips to her temples. \u201cThey rented him too! They have his brain so they\u2019re playing too close to his style. I mean, no one else has ever been able to improvise quite like Arlington Hall, am I right?\u201d\n\nCadence spun on her heel, ticking points off her hand. \u201cHis quartile harmonies, his sidestepping dissonance, his hard swinging bebop\u2014it\u2019s freaking legend. But Reza and that kid, they both pulled it off. And now no one\u2019s buying it.\u201d\n\n\u201cWe\u2019re all cheaters,\u201d he moaned. \u201cWe all deserve to lose.\u201d\n\n\u201cIt\u2019s my fault.\u201d She buried her face in her hands. \u201cI pushed you into this, but you never needed the genius, only the confidence. You\u2019re good enough to win on your own!\u201d\n\nThere was another knock on the door. \u201cThorne?\u201d called an usher. \u201cYou\u2019re on in sixty seconds.\u201d\n\nHe balked at Cadence, his face whiter than ivory. It would be a miracle if he didn\u2019t faint.\n\n\u201cBe right out,\u201d he shouted. He looked back at her in panic.\n\n\u201cI\u2019ll never have this chance again. I can\u2019t just back out now!\u201d\n\nShe hesitated. \u201cThen go out there and try to come up with something that\u2019s yours.\u201d\n\nThere was no time to answer because the usher was calling again, this time urgently: \u201cThorne? You\u2019re on.\u201d\n\nCadence attempted a smile that looked like a wince. \u201cGo,\u201d she whispered. \u201cYou\u2019ll figure something out.\u201d\n\nA fog of dread carried him through the door.\n\nThe disgruntled audience was in no mood to welcome him. Thousands of narrowed eyes sized him up as he stumbled onto the stage and took a quick bow. The emcee introduced him with enthusiasm bordering on desperation, trying too obviously to pretend that nothing was amiss. The show must go on, Thorne thought. And so it would.\n\nHe sat at the piano as the emcee reeled off his challenge: E flat major, 9/8 time signature. A recording boomed through speakers overhead, playing the first measure of a piece he would have to complete. The jazzy notes sounded spunky, almost coy, like the start of a game of hide and seek.\n\nThen, silence. The crowd waited. Twenty minutes started ticking down. He tensed. Think. What would I play?\n\nHis mind instantly fed him a melody line that he recognized as a variation of one of Hall\u2019s old masterpieces. Every element of Hall\u2019s unique sensibility was there\u2014the swinging rhythm, the harmonic palette, the dissonance. He strained past it, trying wildly to come up with something different. Something, anything else.\n\nSomeone started to boo. He hadn\u2019t yet played one note.\n\nHe closed his eyes and let his hands crash onto the piano. Out of sheer retaliation, he started to play the chords of Beethoven\u2019s 5th, but with a syncopated upbeat tempo.\n\nMore boos hurled at him. \u201cReal original!\u201d some jerk shouted.\n\nAnd then, like a schizophrenic, his hands somehow transitioned from the Beethoven\u2014ingeniously, he had to admit\u2014back to the first melody line he\u2019d heard in his brain: the classic, unmistakable Hall. It fit perfectly with the E flat major, 9/8 time challenge. It was too damn good not to play. So he let his hands play.\n\nAn indulgent minute went by, and he was really getting into it now, giving himself over to the master in control at the base of his brain. But the boos were growing, too. Others were joining in. Out of the corner of his eye, he saw a couple people standing in the front row, cupping their mouths.\n\nWho was he kidding? He wasn\u2019t going to win like this. He wasn\u2019t even going to get through the piece.\n\nIn the middle of a measure, he jumped to his feet and turned to the hostile crowd. Their boos ceased. Hundreds of surprised faces stared up at him, the whites of their eyes glistening in the darkness.\n\n\u201cYou\u2019re right, okay?\u201d he yelled. \u201cWe all ripped off Hall!\u201d\n\nThen he reached up behind his neck and dug his nails into his skin. Almost wanting the pain, he ripped open the stitch and scraped at his raw flesh until he felt the smooth edge of the implant bead. It was pulsing in tandem with his racing heartbeat. He plucked it out and flung it on the stage. Blood dripped from his fingers, staining the white cuff of his sleeve.\n\nHe had never commanded an audience like this. Every single person was gazing at him, reveling in their scandalized disgust. For a moment, no one peeped.\n\nRight away he felt the muscles in his head contract and his consciousness shrivel. His connection to Hall vanished, along with his effortless flow of musical ideas, like the rapid ebb of a powerful tide.\n\nThe only grain that remained was the certainty that he needed to get the hell offstage. All pretense gone, with blood dripping down his neck, he ran. That was when the roars started.\n\nCadence met him stage left, motioning for him to hurry, and dragged him toward an emergency exit backstage. It was clear she had already scouted their escape and he loved her for it.\n\n\u201cIt\u2019s over,\u201d he said, as soon as they tumbled outside into the cold. \u201cIt was over before it began.\u201d\n\n\u201cI know.\u201d She leaned her head on his shoulder and he wrapped an arm around her waist. They walked in silence all the way home.\n\nThorne was about to start packing up his keyboard. It was past rush hour on the subway platform in midtown, so his core audience of commuters was thinning out. He had thirty minutes to drop off his keyboard and get downtown before his bartending shift at The Blue Note, where he worked five nights a week.\n\nHe didn\u2019t resent his job. Every night was a free show, and every performance, an education. He studied with the diligence of a prot\u00e9g\u00e9, without a mentor to care. If he\u2019d learned anything from his spectacular failure, it was to follow his own creative passions without restraint. It was easy now, there was nothing at stake.\u00a0 After logging hundreds of thankless hours on the subway platforms, he\u2019d hardened to tough crowds and his stage fright had faded. He even learned to find inspiration in the motley subway throngs\u2014the constant, fiery rush of underground travelers stimulated his mind. By now, he could play anywhere and for any audience. Not that it mattered at all. He was nothing in the jazz world now. After the scandal, he\u2019d exploded like a rocket, with fiery mentions strewn all over the media, until he finally burned into oblivion. Occasionally, though, someone recognized him, which was why he wasn\u2019t too surprised to notice a man on the platform watching him now.\n\nWhen they locked eyes, the man walked closer. He was an older guy, slightly scruffy, rocking a leather jacket and washed-out jeans\u2014casual, except for his unwavering focus on Thorne.\n\n\u201cThis is a joke, right?\u201d The man raised his eyebrows. \u201cYou, playing here?\u201d\n\nThorne reddened. Any fool was allowed to play in the subway, even a reformed cheater like him. Was he really never going to live it down?\n\n\u201cSorry, no.\u201d He started to lift his keyboard off its stand.\n\nThe man kept looking at him, a strange grin playing at his lips.\n\n\u201cOne doesn\u2019t have to be a genius to recognize a musician of your caliber.\u201d\n\nThere was a slight emphasis on the word genius that told Thorne this man knew exactly who he was\u2014but he wasn\u2019t holding it against him.\n\n\u201cNah, indie. I have about 50,000 subscribers on YouTube, though.\u201d He didn\u2019t add that most of his fans had discovered him after the scandal, but so what? Followers were followers.\n\n\u201cSure.\u201d Thorne knew that some hardcore music fans were opting to get a new brain chip implanted that could stream sound waves directly into their auditory cortexes. A handful of dedicated channels had sprung up in recent months to serve the burgeoning market.\n\n\u201cI run a premium startup channel for live jazz. We broadcast from a studio around the corner.\u201d The man pointed his thumb toward the 42nd Street exit. \u201cI\u2019ve actually been trying to recruit new talent for our weekday morning slot.\u201d\n\nHe handed over a card from his jacket as a train pulled into the station.\n\n\u201cGotta run,\u201d he said, \u201cbut why don\u2019t you give me a call? We should talk.\u201d\n\nHe flashed Thorne a smile full of promise before jogging away.\n\nThorne watched him disappear onto the train before looking down at the card. Its fancy raised letters read: Cooper Gordon, Producer, NeuroJazz Studios, 321 West 42nd Street, New York, NY 10036. A phone number followed.\n\nHe didn\u2019t know how long he stared at it. He had to go, otherwise he\u2019d be late for the bar, but suddenly his fingers found their way to the keys as he started to improvise one last piece. An encore.\n\nHis hands darted up and down in a game of his own invention, catching up to each other, then crossing over with glee, skipping, hopping, flying to their next destination. He forgot the ticking clock. He forgot he was in a dank, dreary subway station. Its high ceilings and open acoustics welcomed every joyful note.\n\nIf he tilted his head and closed his eyes, it sounded almost like a concert hall.\n\nKira Peikoff, a journalist and novelist based in New York, has written for The New York Times, Slate, Salon, and other publications. She is the author of the thrillers Living Proof and No Time To Die. @KiraPeikoff"},
{"url": "https://www.pcmag.com/news/357671/exclusive-qualcomms-iphone-x-still-outpaces-intels", "link_title": "Qualcomm's iPhone X Still Outpaces Intel's", "sentiment": 0.10052442230524421, "text": "Qualcomm-powered iPhone X models get consistently better LTE speeds than Intel's on America's most common LTE band, according to new test results from Cellular Insights.\n\n \n\nWhile Apple's iPhone 4s through 6s units all used modems from Qualcomm, last year the company decided to split its business between Qualcomm and Intel, resulting in two iPhone 7 units with very different LTE performance. Since then, Apple has become Intel's largest smartphone modem customer by far. This year, Apple doubled down, continuing the Qualcomm-Intel split.\n\n \n\nThere are three iPhone X models sold globally. Using lab equipment, Cellular Insights tested two of them: the Qualcomm-powered A1865, sold by Sprint, Verizon, and U.S. Cellular and in Australia, China, and India; and the Intel-powered A1901, sold by most other global carriers including AT&T and T-Mobile. (The third model, A1902, is only sold in Japan.) Here in the US, we anticipate that the SIM-free model sold directly by Apple will be the A1865, as that's the model that supports all four US carriers.\n\nFor this test, Cellular Insights looked at performance on LTE Band 4, which is used by every major US carrier except Sprint, as well as in Canada and parts of Latin America.\n\n\n\n \n\nCellular Insights attenuated an LTE signal from a strong -85dBm until the modems showed no performance. While both modems started out with 195Mbps of download throughput on a 20MHz carrier, the Qualcomm difference appeared quickly, as the Intel modem dropped to 169Mbps at -87dBm. The Qualcomm modem took an additional -6dBm of attenuation to get to that speed.\n\nMost consumers will feel the difference in very weak signal conditions, where every dBm of signal matters, so we zoomed in on that in the chart below. At very weak signal strength, below -120dBm, the Qualcomm modem got speeds on average 67 percent faster than the Intel modem. The Intel modem finally died at -129dBm and the Qualcomm modem died at -130dBm, so we didn't find a lot of difference in when the modems finally gave out.\n\nThe iPhone 8 and 8 Plus have the same division of modems, although we did not test those models specifically.\n\n \n\nRohde & Schwarz, the global leader in test and measurement equipment, provided Cellular Insights with the cutting-edge CMWFlexx solution (shown below) consisting of two CMW500 Wideband Communication Tester boxes, CMWC Controller, and R&S TS7124 RF shielded box equipped with four Vivaldi antennas for up to 4\u00d74 MIMO, ensuring high reproducibility of near-field OTA MIMO measurements. The study was done independently by Cellular Insights and shared with PCMag.\n\nThe two iPhone X units were running iOS 11.1.2. Cellular Insights' methodology was the same as last year's, which you can read in its 2016 report.\n\nCompared to last year's tests, while Intel's modem hasn't caught up to Qualcomm's, there's a considerably smaller difference between the two. Below, we've copied the Cellular Insights chart for last year's iPhone 7 Plus tests: you can see that the Intel iPhone 7 Plus modem drops off a cliff between -105 and -110dBm, while it tracks a little below the Qualcomm modem's performance much more closely this year. This year's Intel modem is also able to squeeze out some performance at -129dBm, as opposed to the -125dBm of last year's device.\n\nWe wonder if Apple is specifically tuning the phones to have similar performance, though, because of the difference between 2017 and 2016 Qualcomm results. While the peak and weak-signal performance of this year's Qualcomm modem were both better than last year's, the speeds Cellular Insights saw on Qualcomm's modem between -97 and -117dBm were actually lower than last year's, and much closer to those of this year's Intel modem. Apple may be trying to make sure that T-Mobile and AT&T don't become jealous of Sprint and Verizon.\n\nBoth the Qualcomm and Intel iPhones use the companies' latest retail modems as of September 2017. The Qualcomm model uses the X16, which is also in the Samsung Galaxy S8, LG V30, Google Pixel 2, Essential PH-1 and other flagship phones. The Intel model uses the Intel XMM7480.\n\n \n\nThe Qualcomm X16 modem in the iPhone X supports 4x4 MIMO antennas, 4-way carrier aggregation, and LAA, all of which can be bundled together in various ways to make \"gigabit LTE\" networks. All four US carriers currently say they're doing gigabit LTE using 4x4 MIMO and 3-way carrier aggregation.\n\n \n\nHowever, those features are disabled in the new iPhones, possibly because the Intel modem doesn't support 4x4 MIMO or LAA, and Apple wants a level playing field. That makes both models of the iPhone X \"600Mbps\" rather than \"gigabit\" phones. There's one exception: in Australia, the Qualcomm modem is capable of 80MHz, four-way carrier aggregation on bands 1+3+7+7, and thus \"800Mbps\" speeds. A similar four-way combination (2+4+7+7) could have benefitted Canadian carriers where they have 75MHz of spectrum deployed, but the iPhone does not support that band combination.\n\n \n\nThe iPhone 8/X modems get a maximum of 200Mbps per 20MHz channel, as opposed to 150Mbps on the iPhone 7 models. The iPhone 8/X modems are able to net higher speeds using the same 20MHz channels because of their support for 256QAM encoding, which packs more data into each transmission symbol. The iPhone 7's Qualcomm X12 modem supported 256QAM, but Apple left it turned off, possibly because Intel's XMM7360 didn't have 256QAM support. The XMM7480 does, so Apple is turning the X16's 256QAM support on.\n\nThe iPhone X may be Qualcomm's last hurrah with Apple, though. Qualcomm and Apple are locked in a web of lawsuits basically centering on Apple not wanting to pay the license fees that Qualcomm wants to charge.\n\nUntil now, Apple has been stuck with Qualcomm modems because it's the only provider offering high-end modems that work on the Sprint and Verizon CDMA networks. Intel's XMM7560 modem, which is supposedly coming to market next year, will support CDMA and thus Apple won't have any need for Qualcomm.\n\nFurther down the road, Apple may cast off Intel as well. The company recently hired a Qualcomm executive and is rumored to be working on a project to develop its own modems, which might result in a product in 2019 or 2020.\n\nFor now, though, getting an iPhone with the Qualcomm modem is still the way to go if you want the best possible LTE performance. You can do that by purchasing the factory-unlocked, SIM-free model directly from Apple in the US or Australia, or by purchasing a Verizon Wireless or Sprint unit. Sprint units come locked to Sprint, but Verizon units are unlocked."},
{"url": "http://www.pewresearch.org/fact-tank/2017/12/01/first-time-internet-users-who-they-are-and-what-they-do-when-they-get-online/", "link_title": "First-time internet users: Who they are and what they do when they get online", "sentiment": 0.08051267779839211, "text": "Decades after internet access became widely available, Pew Research Center surveys show that about a tenth of American adults (12%) remain offline. But what happens when some of them take the plunge and connect? A new analysis provides a glimpse of the online behaviors of those who are new to the internet.\n\nThe Center provided internet-connected tablet computers to 112 people who are members of our American Trends Panel. These panelists, who previously received our surveys through the mail, had never used the internet under any circumstances. This change allowed these respondents to become internet users if they wished by using the tablets for online activities other than taking surveys.\n\nThis is not a large sample. Still, these newly internet-enabled adults answered some questions that provide insight into who late adopters of the internet are, the online activities they perform and their struggles with new devices. Here is what we learned about this modest sample of new users:\n\nFor starters, having access to the internet did not lead to more online exploration for some of the people we studied. About four-in-ten (39%) reported they had used the new tablet they were given\u00a0only for taking surveys and did not attempt any other online activity we queried. This is consistent with past Center findings that many non-users of the internet say they are not interested in going online because they do not want or need the technology.\n\nSome had difficulties with their tablets. Pew Research Center surveys have shown over time that later adopters of the internet often say they need help with their new devices. Not surprisingly, a share of these new users struggled with the device. Seven-in-ten called tech support to get help with the tablet, and 43% experienced login or password issues. Nearly a third (32%) reported that it was a challenge learning how to use the touch screen. And 14% said it was a challenge to keep the tablet charged.\n\nSome ventured out into online activities. In addition to using the tablet to take the American Trends Panel surveys, 61% of these panel members performed at least one other online activity. Some tried relatively simple activities: 26% got news and 21% used an app. A share also used the tablet for things that are not necessarily online tasks: 33% played games and 26% took pictures or videos. Smaller shares reported performing social activities like using email or texting and social media.\n\nThese new users had a particular demographic profile. As a group, compared with more-veteran internet users, the first-time users in the sample skewed older, more female and had lower household incomes and educational attainment. In this sample, females outnumbered males by about two-to-one, in contrast with the overall internet population, which is half female. In addition, very few of the newcomers were younger than 50.\n\nPew Research Center\u2019s telephone surveys of American adults have shown over the years that internet users are more likely to be younger and better educated and to have higher household incomes, and there has been general parity between men and women adopters since 2000. For example, the most recent Center survey shows that 99% of adults ages 18 to 29, 98% of adults who make $75,000 or more a year and 98% of college graduates are internet users.\n\nNew users liked going online to learn new things and access entertainment. The first-time internet users in this study were also asked some questions about the impact of their tablets on several internet activities. The Center did not get enough responses to do a statistical analysis of the findings. But some of these adults found the tablet most helpful for learning new things, accessing entertainment like videos, movies and online music, and staying in touch with family, friends and neighbors."},
{"url": "http://sharpsightlabs.com/blog/quick-intro-color-density-plot/", "link_title": "How to use color in density plots (in R)", "sentiment": 0.15835698961805159, "text": "Right now, many people are pursuing data science because they want to learn artificial intelligence and machine learning. And for good reason. Machine learning is white hot right now, and it will probably reshape almost every sector of the world economy.\n\nHaving said that, if you want to be a great machine learning expert, and a great data scientist in general, you need to master data visualization too.\n\nThis is because data visualization is a critical prerequisite for advanced topics (like machine learning), and also because visualization is very useful for getting things done in its own right.\n\nSo let\u2019s talk a little more about data visualization. As you begin learning data visualization in R, you should master the basics: the how to use ggplot2, how to think about data visualization, how to make basic plots (like the bar chart, line chart, histogram, and scatterplot).\n\nAnd I really mean that you need to master these basics. To be a great data scientist, you need to be \u201cfluent\u201d in these basics. You should be able to write the code for basic charts and plots without even thinking about it. If you can\u2019t, you should go back and practice them. Don\u2019t get shiny object syndrome and try to move on to advanced topics before you do. Show some discipline. Master the foundations.\n\nAfter you do master the foundations though, you\u2019ll need to learn some intermediate tools.\n\nOne such thing that you\u2019ll need to learn is how to work with color. Specifically, you\u2019ll need to learn how to manipulate the \u201cfill\u201d color of things like density plots (as well as heatmaps).\n\nWith that in mind, let\u2019s take a look at using color in density plots.\n\nAs always, we\u2019re going to use the meta-learning strategy of learning the tools with basic cases. Essentially, we\u2019ll learn and practice how to modify the aesthetic for very simple plots. Later, once you get the hang of it, you can move on to more advanced applications.\n\nAs always, first we will load the packages we will need.\n\nNext, we will set a \u201cseed\u201d that will make the dataset exactly reproducible when we create our data. Without this, running and would produce data that is similar, but not exactly the same as the data you see here. To be clear, it won\u2019t make too much difference for the purposes of this blog post, but it\u2019s a best practice when you want to show reproducible results, so we will do this anyway.\n\nNow, we will create our data frame.\n\nWe will use to create 20,000 uniformly distributed values for our x variable, and to create 20,000 random normal values for our y variables. We\u2019re also using the function to ultimately create a / out of these two new variables.\n\nNow that we have a dataset created, let\u2019s create a simple plot of the data. Ultimately, we will be working with density plots, but it will be useful to first plot the data points as a simple scatter plot.\n\nHere, we\u2019re using the typical syntax: we\u2019re specifying the data frame inside of and specifying our variable mappings inside of .\n\nOk. We can at least see the data points and the general structure of the data (i.e., the horizontal band).\n\nHaving said that, these data are very heavily overplotted. There are a few ways to mitigate this overplotting (e.g., manipulating the alpha aesthetic), but a great way is to create a density plot.\n\nTo create the density plot, we\u2019re using . I won\u2019t explain this in detail here, but essentially in this application, calculates the density of observations in each region of the plot, and then fills in that region with a color that corresponds to the density.\n\nThis isn\u2019t bad. It gives us a sense of the density of the data (you can see the thick band across the middle). However, there are two issues.\n\nFirst, the differences in density are not completely obvious, because of the color scale. The default light blue/dark blue color scheme doesn\u2019t illuminate the differences in data density.\n\nSecond, this is just not very aesthetically appealing. It just doesn\u2019t look that good.\n\nTo fix these issues, let\u2019s modify the color scheme. I\u2019ll show you a few options. Some will work better than others, and after you see these, I\u2019ll encourage you to experiment with other color palettes.\n\nLet\u2019s first take a look at the color palette options.\n\nYou can examine a large number of ready-made color palettes from the package by using .\n\nAs you can see, there are quite a few palettes from . We\u2019ll use a few of these to change the color of our plot.\n\nNow let\u2019s use a few more color palettes.\n\n\u2026 and a scale from red, to yellow, to blue.\n\nI think they work a little better than the default color scheme, but I think we can do better, so let\u2019s try one more.\n\nThe following plot uses a custom color palette from the package.\n\nI should have called this blog post \u201cggplot for people who love Mark Rothko.\u201d\n\nOk, the viridis color palette (and a related set of palettes in the package) is probably my favorite option. Not only do I think this color palette is one of the most aesthetically attractive, it\u2019s also more functional. As noted in the documentation for the package, the viridis color palette is \u201cdesigned in such a way that it will analytically be perfectly perceptually-uniform \u2026 It is also designed to be perceived by readers with the most common form of color blindness.\u201d\n\nAdmittedly, when you move on to more complex datasets later, it will take a bit of finesse to properly apply these color palettes.\n\nBut as I noted earlier, when you\u2019re trying to master (or any programming language), you should first master the syntax and techniques on basic cases, and then increase the complexity as you attain basic competence.\n\nWith that in mind, if you want to master these color and fill techniques, learn and practice these tools with simple cases like the ones shown here, and you can attempt more advanced applications later.\n\nTo master data visualization and data science, you need to master the essential tools.\n\nMoreover, to make rapid progress, you need to know what to learn, what not to learn, and you need to know how to practice what you learn.\n\nSharp Sight is dedicated to teaching you how to master the tools of data science as quickly as possible.\n\nSign up now for our email list, and you\u2019ll receive regular tutorials and lessons.\n\nIf you sign up for our email list right now, you\u2019ll also get access to our \u201cData Science Crash Course\u201d ."},
{"url": "https://www.bloomberg.com/view/articles/2017-12-01/pivot-to-millennials-it-might-work-for-airlines", "link_title": "Trying to spark an emotional connection in the commoditized airline market", "sentiment": 0.1352988215488215, "text": "The commoditization of air travel has\u00a0led to an industry-wide race to the bottom in terms of price, and an uncomfortable place in general for the companies and customers alike.\u00a0A new airline\u00a0is unleashing an over-the-top\u00a0strategy\u00a0to spark a new emotional connection with a coveted -- and fickle -- demographic.\n\nJoon, the Air France-KLM subsidiary airline that begins operations this week, is on a mission to win over millennials, even hipsters. Its opening argument is a marketing understatement for the ages. Joon introduced itself as \"a fashion brand, a rooftop bar, an entertainment channel, a personal assistant\" before\u00a0admitting -- as an afterthought -- that it's \"also an airline.\"\u00a0The cabin crews' outfits riff on millennials' beloved athletic clothing. The bar serves smoothies. Virtual reality entertainment is available for business class travelers. Even\u00a0the destinations are hipster favorites: Barcelona, Berlin, Lisbon. Joon checks so many boxes that it's\u00a0making\u00a0millennial news sites like Mashable\u00a0cringe.\n\nBut that\u00a0isn't what's intriguing about Joon's marketing. Even if millennials moan about being associated with banal trappings, it rings true nonetheless. They do like smoothies. They are glued to screens and uncomfortable without Wi-Fi\u00a0(which will be free next year). There are international herds of them -- dressed in fashionable sweatpants -- in Berlin. Besides, what generation appreciates postmodern self-mockery and self-parody more than them?\n\nThey, however, don't care which airline they fly.\u00a0As the Boston Consulting Group\u00a0noted\u00a0in a 2013 report, millennials are four times more likely than non-millennials to strongly disagree when asked if they were loyal to one or more airline. They are also less likely to collect frequent flier miles or subscribe to loyalty programs than older travelers.\n\nOne reason the frequent flyer programs are evolving away from miles and toward credit card bonuses is that airlines are trying to make them cheaper. But the other reason is that more people travel like millennials: They use an aggregator app to find flights and just pick the cheapest option. As Euromonitor analyst Nadejda Popova wrote in a post accompanying the market research company's recent analysis of airline loyalty programs, \"With the increasing number of price comparison and review websites, many travelers are more bargain hunters than loyal clients.\" Price pressure has already all but killed off first class, once a major differentiating point for airline marketers. And there's less and less difference between traditional and discount airlines as the former try to shrink cost and the latter, locked in their own wars, seek to improve service.\n\nAn airline can still have an emotional relationship with its passengers, but it won't necessarily help it as a business. I was recently one of many witnesses to the heartbreaking story of the last weeks of Air Berlin, the airline that once connected walled-in West Berlin to the rest of the world. It just couldn't compete with bargain-based brands\u00a0RyanAir and EasyJet. Pilots and flight attendants, many of whom would be unemployed after the airline closed, made sentimental, heartfelt announcements during the last flights. Some had tears in their eyes as they handed out Air Berlin's trademark chocolate hearts to disembarking passengers, who grew emotional in response. The airline's final flight, out of Munich, was fully booked well in advance, and people were paying thousands of euros for tickets. The flight was deemed worthy of a blow-by-blow account in Germany's most popular tabloid, Bild.\n\nYet no white knight showed up for Air Berlin, and its planes have been sold off to Lufthansa and the low-cost carriers.\n\nSo why is\u00a0Air France-KLM, which finally posted a profit after seven years of back-to-back losses, betting on millennials?\u00a0That same Boston Consulting Group report said millennials traveling for business are four times more likely than older passengers to pay for Wi-Fi and 60 percent more likely to watch in-flight entertainment. They are also 60 percent more likely to pay for extra legroom and are far more open than older passengers to paying for roomier seats. As leisure travelers, millennials have less money than the average flier, so they're generally not picky, but it's clear they'd like the same amenities for which they pay with their expense accounts when traveling for business.\n\nSo there's nothing unreasonable\u00a0about Air France KLM's experiment. Joon's pricing is set between the low-cost carriers and traditional rivals, and it offers various levels of the combination of comfort, connectedness and entertainment that millennials seem to want. It's dedicating\u00a0just 28 out of the company's 228 aircraft. If it works, expect other airlines to focus more on entertainment and communication options. They'll become a more important differentiation point -- one of the few than still matter beyond price.\n\nAnd perhaps attendant uniforms will finally stop looking like school uniforms or vintage movie costumes.\n\nThis column does not necessarily reflect the opinion of the editorial board or Bloomberg LP and its owners."},
{"url": "https://blog.emojipedia.org/google-fixes-burger-emoji/", "link_title": "Google Fixes Burger Emoji", "sentiment": 0.06433566433566434, "text": "Google has updated its hamburger emoji after CEO Sundar Pichai last month said he would drop everything to address the previous design.\n\nThe new burger design sees the cheese moved from its previous location at the bottom of the \ud83c\udf54 Hamburger emoji to place the cheese on top of the burger patty. This change applies to the forthcoming Android 8.1 release.\n\n\n\n Above: Android 8.1 features the new burger emoji design. Image: Google / Emojipedia composite.\n\nOther emojis to change in Android 8.1 include \ud83c\udf7a Beer, \ud83c\udf7b Beers and \ud83e\uddc0 Cheese.\n\n\ud83c\udf7a Beer and \ud83c\udf7b Beers no longer have froth appearing at the top of a half-poured stein of beer.\n\n\ud83e\uddc0 Cheese fixes a bug where holes on the edge of the wedge appeared to be painted on, showing a line running through them.\n\nAs this is a beta update, no changes are final, and these could change prior to the public release.\n\nHow the new burger emoji affects the serving of the burger at Google offices is not clear. For Googlers' sake I hope the cheese is returned to the top of the patty where it belongs!\n\nResponses to this update have been positive on Twitter, with the previous \"cheese-under\" design having few fans.\n\nNow Tim, how about that \"lettuce under\" design?\n\n\n\n Above: Comparison of all burger emoji designs including Apple's burger with lettuce under the patty. Note: Android is still showing the current 8.0 image in this comparison, not the new 8.1 design.\n\nAndroid 8.1 is in developer preview now, with a full release expect in late 2017. These emoji changes appeared in developer preview 2 which was released this week.\n\nDevelopers can download this release from Google, and a rollout will commence to the public when the final version of Android 8.1 is complete."},
{"url": "http://patft.uspto.gov/netacgi/nph-Parser?Sect2=PTO1&Sect2=HITOFF&p=1&u=/netahtml/PTO/search-bool.html&r=1&f=G&l=50&d=PALL&RefSrch=yes&Query=PN/9805375", "link_title": "United States Patent: 9805375: Content-based price reductions and incentives", "sentiment": -0.0546875, "text": "Customers in an electronic environment can be presented with the option to receive advertising, such as audio, video, or interactive content, in order to receive discounted pricing or similar benefits. In one embodiment, a customer can select to watch a video advertisement on a detail page for an item, and the displayed price for the item will be shown to decrease as the customer continues to watch the video. Such an approach enables the provider to obtain additional revenue from the advertisement, which can offset any loss or reduction in price of the item. Revenue can be generated in other ways using these ads, such as by displaying advertisements that will enable a customer to obtain lower prices on other items, such as accessories or services relating to an item that is determined to be of little or no profit for the provider."},
{"url": "https://threatpost.com/flaw-found-in-dirty-cow-patch/129064/", "link_title": "Flaw Found in Dirty COW Patch", "sentiment": 0.013297723781594748, "text": "A flaw in the original patch for the notorious Dirty COW vulnerability could allow an adversary to run local code on affected systems and exploit a race condition to perform a privilege escalation attack.\n\nThe flaw in the Dirty COW patch (CVE-2016-5195), released in October 2016, was identified by researchers at the security firm Bindecy. On Wednesday, they released details of the vulnerability (CVE-2017-1000405) found in the original Dirty COW patch, affecting several Linux distributions.\n\nThe scope of affected products is significantly smaller than the original Dirty COW bug, which impacted many more Linux distributions and the Android operating system.\n\n\u201cIn terms of scope, the difference is just that the current bug is not applicable to Android and Red Hat Enterprise Linux. All other distributions \u2013 Ubuntu, Fedora, SUSE \u2013 suffer from the issue. So, the scope is still large. We estimate that millions of machines are vulnerable,\u201d said Daniel Shapiro, researcher at Bindecy, credited for finding the flaw along with colleague Eylon Ben Yaakov.\n\nThe vulnerability, CVE-2017-1000405, is rated \u201cImportant\u201d and scores 6.1 on the CVSS scale.\n\nRed Hat Software notified customers of the flawed patch on Thursday noting the issue does not affect the Linux kernel packages as shipped with Red Hat Enterprise Linux 5, 6, 7 and Red Hat Enterprise MRG 2, according to Red Hat\u2019s customer portal.\n\nDirty COW was patched in October 2016 after it was discovered in public exploits. The vulnerability was found in the copy-on-write (COW) feature in Linux and could be used by an attacker with local access to obtain root privileges on a Linux or Android device.\n\nThe flaw, which was introduced in 2007 in version 2.6.22 of the kernel, allows an attacker to elevate privileges by taking advantage of a race condition and gain write-access to read-only memory.\n\nThe flaw allows an attacker with a local system account to modify on-disk binaries, bypassing the standard permission mechanisms that would prevent modification without an appropriate permission set.\n\nCopy-on-write manages memory resources and allows for more than one process to share a page until a user writes to it, known in programming as marking a page dirty. The vulnerability allows an attacker to exploit the race condition to write to the original page before it\u2019s marked dirty.\n\nThe October 2016 patch addressed the Dirty COW vulnerability for both regular pages and transparent huge pages (supported since kernel approximately 2.6.38), according to Shapiro.\n\n\u201cThere is a code flow that wasn\u2019t taken into account that breaks the logic of the patch for transparent huge pages,\u201d he said.\n\n\u201cIn the original vulnerability the exploit targeted pages backed by read-only files, with the new bug we could write to a read-only special huge-page called \u2018zero page\u2019. It is assumed to be initialized with zeroes and some software rely on that assumption (including privileged processes),\u201d Shapiro said.\n\nA more detailed description of the flaw can be found in a technical write-up by Yaakov here.\n\nAccording to the disclosure timeline, researchers reported the vulnerability to the Linux Kernel Organization on Nov. 22. A CVE was assigned the same day and a patch was committed to the mainline kernel Nov. 27. The vulnerability was officially made public on Friday.\n\nImmediate mitigation includes disabling the use of \u201czero page\u201d.\n\n\u201cIt is possible to prevent the zero page from being mapped as a huge page, by modifying a configuration tunable in the /sys directory\u2026 This prevents the flaw from being exercised in this method. # echo 0 > /sys/kernel/mm/transparent_hugepage/use_zero_page Disabling huge pages: It is possible to mitigate this flaw by disabling hugepages on a system,\u201d according to a description of mitigations steps.\n\n\u201cThe real deal here is the astonishing fact that such a hyped vulnerability was patched incompletely,\u201d Shapiro said."},
{"url": "http://penguindreams.org/blog/bee2-automating-haproxy-and-letsencrypt-with-docker/", "link_title": "Automating HAProxy and LetsEncrypt with Docker", "sentiment": 0.12191094619666047, "text": "In a previous post, I introduced Bee2, a Ruby application designed to provision servers and setup DNS records. Later I expanded it using Ansible roles to setup OpenVPN, Docker and firewalls. In the latest iteration, I\u2019ve added a rich Docker library designed to provision applications, run jobs and backup/restore data volumes. I\u2019ve also included some basic Dockerfiles for setting up HAProxy with LetsEncrypt and Nginx for static content. Building this system has given me a lot more flexibility than what I would have had with something like Docker Compose. It\u2019s not anywhere near as scalable as something like Kubernetes or DC/OS with Marathon, but it works well for my personal setup with just my static websites and personal projects.\n\nIn this iteration of Bee2, I\u2019ve added sections in the configuration file for docker, applications, and jobs. The docker section contains general settings, such as which volumes to backup and what prefix to use for Bee2 managed containers. Both applications and jobs are for configuring Docker containers. Applications are containers that run continuously and jobs are tasks that are designed to be run once and exit, such as building content for a website.\n\nStarting with the docker section, we have a prefix that will be appended to all the containers that are created (which defaults to bee2 if it\u2019s omitted), and a backup section listing each server, the named volumes which should be backed up and the location to store the resulting tar files.\n\nNext we have jobs and applications. Items listed in the jobs section are checked out to the local machine from a given git repository. The Dockerfile in the base of the git repository is built and run on the given machine (in this case, web1). The following example builds the static website for dyject, a Python library I wrote for dependency injection. It writes its output to a volume which is accessible by the Ngnix container as we\u2019ll see later.\n\nThe applications section contains a list of docker applications and their configurations. Each application is given a user defined name, a build_dir (which references a directory in dockerfiles in the Bee2 source), environment variables, Docker volumes, linked containers and exposed ports.\n\nThe environment variable domains can potentially have the special keyword all, which is processed into a list of all domains being used by all applications on a given server. Because this lists needs to be passed as an environment variable to docker containers, it\u2019s formatted as a space separated list, with each entry being a server, a colon and a coma separated lists of domains belonging to that server, as show below:\n\nThis highlights one of the fundamental issues with Docker, in that each container is expected to be configured using environment variables. For more complex configurations, it might make more sense to pass a JSON string as an environment variable, but that would require each container having tools within it to deserialize the passed in JSON.\n\nThe following applications section configures an HAProxy instance with publicly exposed HTTP/HTTPs ports, a Certbot to issue LetsEncrypt certificates and an Nginx instance to serve static web content:\n\nBee2 communicates with Docker over the VPN tunnel that was configured in the last tutorial. Once the servers and provisioned and configured, the docker containers can be run using the following commands:\n\nTo run or rebuild a specific container instead of every container listed in the configuration file, that container can be appended to the end of the command.\n\nState information is stored using the backup command. Backups are timestamped, and running restore will pull the latest backup available in the location specified by storage_dir. An entire infrastructure stack can be rebuilt from scratch while maintaining state information by running commands like the following:\n\nA full list of Docker commands can be found by running .\n\nI\u2019m extending the HAProxy container maintained by Docker and the official Certbot container maintained by the EFF. I try to use official containers maintained either by Docker or the project owners whenever possible. There are many HAProxy+Certbot custom container implementations currently out there, most of which place both services within the same container and then run both of them using some type of supervisor. This is necessary since HAProxy requires a signal to indicate it should reload when the SSL/TLS certificates are updated by Certbot. This seems to go against the generally accepted best-practice of isolating Docker containers to only one process.\n\nTaking a closer look at the Certbot container configured above, I place all the certificates on a volume so that they can be shared with HAProxy and be backed up. Environment variables that start with a dollar sign ( ) will be replaced with the full name of a container including the prefix and container type. In this case, will be replaced with As stated earlier, the special variable , when used with will be replaced with a full list of all domains associated with a given server.\n\nIn this configuration, the Docker socket is shared to the Certbot host. This is not secure nor recommended. (Although it is considered an accepted answer on StackOverflow.) If Certbot is ever compromised, an attacker could have complete access to the Docker daemon and other running containers. In this configuration, it\u2019s essential to keep the Cerbot container up to date with the latest image to prevent any potential security vulnerabilities. In future releases, I hope to add a container with a proxy service, designed to preform necessary container tasks and provide another layer of isolation between the Docker socket and services which need to communicate to other containers.\n\nThe Docker socket is used for two things. It checks to see if HAProxy is up and running before launching Cerbot and it reloads HAProxy when certificates have been renewed. Checking to see if a container is active is done using the check_docker python script. Signaling HAProxy to reload is done by using like so:\n\nThe official HAProxy Docker image uses a systemd wrapper binary as its entry point in order to pass signals sent to the container to the underlying HAProxy process. The documentation recommends copying in a custom or using one from a mounted volume. Since I\u2019m generating my configuration dynamically when the container starts, I had trouble figuring out the best way to run my script and still be able to forward signals to HAProxy. After a few failed attempts at trying to handle my own signals and forward them on, either in Bash or Python scripts, I eventually I settled on a custom script that would make an call to the base containers like so:\n\nThis allows me to run my custom haproxy-config.py script which sets up virtual hosts, SNI and Certbot, and then out to the . This replaces my process with the stock binary signal manager that comes with the official Docker container. I call my startup script within the Dockerfile like so:\n\nAll my static content is hosted via nginx. The HAProxy script will create vhost/SNI entries for every domain in the domain map passed to it, using port 8080 on the destination container. HAProxy handled SSL redirects and offloads the SSL traffic. The following configuration, modified from a stackoverflow answer, will atomically direct virtual host requests to an appropriate folders located at and issue 301 redirects from the www subdomain back to the root. The option needs to be used to ensure nginx doesn\u2019t add port 8080 to folder name redirects.\n\nThe nginx Dockerfile is fairly straightforward as well. By default, the base nginx container sends all of its access and error logs to and as it is considered best practice with Docker. I\u2019ve modified nginx\u2019s configuration to keep separate log files for each individual host, so that they can be run through a log parser later for analytic purposes. Since nginx worker threads run as an unprivileged user within the container, by default nginx doesn\u2019t have permission to write to its own log directory. However, if permissions are set in the Dockerfile for the directory that the Docker log volume will be mounted into, those permissions carry over to the mount itself, allowing nginx to store its logs and also have those logs available to other containers.\n\nBy default, Docker\u2019s exposed ports do not listen on both the IPv4 and IPv6 addresses of the host. Configuring Docker to listen on IPv6 involves giving the Docker daemon a slice of the host\u2019s subnet. I acomplished this by taking the subnet provided to me by my hosting provider, adding a to it and adding it to the configuration file using the existing Ansible role and template:\n\nBee2 was never really meant to a general purpose provisioning system. I attempted to use existing tools such as Terraform and Docker Compose, but had trouble with some of their limitations. It\u2019s primary purpose was to aid in the migration of my personal websites and projects from my existing hosting provider, which requires considerable manual configuration, to an automated provisioning system. Although only targeting one provider currently, creating my services in code should ease in further migrations, as well as quickly spinning up new applications to experiment with.\n\nThe initial Docker work was based in part of the frame work used in my side project BigSenseTester, where I use a Ruby script to create Docker containers and run the automated integration tests for BigSense. The vSense project also had configuration management tools for HAProxy and Certbot. Although I was able to leverage some of this existing work, there was still a considerable amount I needed to add and adapt for this particular iteration of Bee2.\n\nWorking on Bee2 has given me a deep appreciation to all the intricacies involved in writing provisioning services and automating configuration management. Although I\u2019ve gained a lot of flexibility by writing a custom application to take care of my specific desires in a provisioning tool, it comes at the expense of the time needed to develop it, instead of the future projects I hope to host with it. Hopefully the work I\u2019ve done can help others in developing their own development and operation tools, as well as speed up development of my own projects in the future."},
{"url": "http://antonpug.com/blog/2017/11/29/stop-commenting-your-code", "link_title": "Stop Commenting Your Code", "sentiment": 0.10740740740740741, "text": "The function-level comment is too wordy, does not provide a clear description of what the method is intended for. It attempts to explain everything that is happening inside, but even then, it misses some of the key details.\n\nKeep your function-level comments concise and clear. You should be able to explain the one thing that function is doing. If you can't - you should probably break down the function."},
{"url": "https://arstechnica.com/gadgets/2017/12/chrome-will-block-third-party-software-from-meddling-with-its-processes/", "link_title": "Chrome to stop third-party software injections because they make it crash", "sentiment": 0.07407142857142857, "text": "To boost the stability of Chrome, Google has announced that it's going to start blocking third-party software from being injected into the browser.\n\nThird-party software such as anti-virus scanners and video driver utilities often injects libraries into running processes to do things like inspect network traffic, or add custom menu options to menus. Malicious software can also do the same to spy on users, steal passwords, and similar. Google has found that people who have such injected code are 15 percent more likely to see their browser crash. As such, it's going to start blocking such injections.\n\nThe change will start in Chrome 66, due in April 2018. If that version crashes, it will warn users that there is something injected that could be causing problems. Chrome 68, due in July 2018, will start blocking the injection; if the browser doesn't run properly, it'll allow the injected software but show a warning. Chrome 72, due in January 2019, will block code injection entirely.\n\nGoogle says that with its extension and native messaging APIs, many applications that need to inject code into Chrome processes can use these alternative, safe, supported mechanisms instead. Google will also allow certain exemptions even after Chrome 72. Accessibility software (such as screen readers), Input Method Editors (used to compose complex scripts, and essential for many Asian languages), and any code that's been signed by Microsoft will continue to be allowed.\n\nMicrosoft made a similar change to its Edge browser back with the first major update to Windows 10 in November 2015. Libraries that are signed by Microsoft, or included in signed drivers, are permitted, but everything else is blocked."},
{"url": "https://medium.com/@chrisconley/finding-winning-and-retaining-your-first-ten-engineers-b747232c3c1f", "link_title": "Finding, Winning, and Retaining Your First Ten Engineers", "sentiment": 0.23196248196248195, "text": "As a new, relatively unknown startup, hiring great engineers in the Bay Area is tough.\n\nThere are startups with impressive teams of Stanford grads, Google alumni, and repeat entrepreneurs. There are big companies such as Facebook that offer very attractive compensation packages. Not to mention the organizations with insane growth trajectories paired with intriguing technical challenges.\n\nIn short, there is a lot of competition.\n\nAll is not lost though of course. With a good bit of perseverance, attention to detail, and time, you\u2019ll have a cohesive team of engineers chomping at the bit to help you build a great company."},
{"url": "https://www.eff.org/deeplinks/2017/11/naftas-digital-trade-chapter-could-be-finalized-next-month", "link_title": "NAFTA's Digital Trade Chapter Could Be Finalized Next Month", "sentiment": -0.026418067226890753, "text": "The fifth round of negotiations over a modernized North American Free Trade Agreement (NAFTA) wound up last week in Mexico. Following conclusion of the round, Mexican Trade Minister Ildefonso Guajardo told reporters that he hoped that the next round, to be held in Washington, DC in the week of 11 December, could see sufficient progress made that the agreement's Digital Trade chapter could be closed... all before the public has seen a single word of it.\n\nThe history of such predictions leads us to suspect that this may be an optimistic timeline, but the fact that the Minister made it at all does go to confirm that the Digital Trade chapter is seen as being uncontroversial in the negotiations. But it isn't unimportant. The provisions likely to be found in this chapter include some topics that are critical to the digital economy.\n\nSome of these rules, depending on how they are worded, could be beneficial for the rights of users online. In particular, harmonizing at a higher level of safe harbor protection for platforms would boost protection for freedom of expression and human rights online, at the same time as helping online innovators and startups. In a\u00a0joint letter sent to the USTR earlier this month, startup advocacy group Engine made a case for the inclusion of broad intermediary liability rules in NAFTA's Digital Trade chapter:\n\nBut other rules proposed for NAFTA's Digital Trade chapter are more troublesome. For example, rules on domain names belong at\u00a0ICANN\u00a0and should be kept out of trade agreements. \u00a0Rules on issues such as the circumstances in which countries can\u00a0limit the flow of data\u00a0across their borders or can require the placement of\u00a0servers on domestic soil, and rules limiting regulators from\u00a0requiring access to the source code\u00a0of imported products are being set through trade agreements.Rules on critical areas such as data localisation and transfer should be included after careful consideration and only following public input into the development of those rules.\n\nWhile limitations on data flows and demands for source code can be used for protectionist purposes that don't merit our support, there are also legitimate reasons why banning them outright\u00a0would be a bad idea. In particular, it is important that countries retain the flexibility to make and enforce personal data protection laws, even if these do to some extent inhibit the free flow of such data in commerce. We should also think twice about preventing countries from reviewing the source code of imported products, when this could be used to address the real problem with insecure devices posing security and privacy risks to users.\n\nThe NAFTA negotiating countries shouldn't rush in to closing the Digital Trade chapter of the agreement before these nuances have been addressed in an inclusive, balanced, and accountable way. That includes receiving input on these provisions from those who know their subject better than trade negotiators do\u2014including privacy experts, cybersecurity professionals, and representatives of Internet users. But unfortunately this is not possible while text proposals and consolidated drafts remain secret, and while the Trade Advisory Committees conduct their work behind closed doors, subject to confidentiality obligations.\n\nEFF and other public interest advocates are doing the little that we can in these difficult circumstances to inform negotiators of our concerns, but we have no way to know for sure whether they are listening. If it is announced during next month's negotiation round that the Digital Trade chapter of NAFTA has been closed before we've even seen it, the negotiators and their political masters will stand accountable to the public for any bad choices that they have made."},
{"url": "https://www.eff.org/fcc-contemplates-repealing-net-neutrality-protections-indian-telecom-regulator", "link_title": "Indian Telecom Regulator Reaffirms Support for Principles of Non-Discrimination", "sentiment": 0.07926786521935777, "text": "Net neutrality is the principle that Internet service providers (ISPs) should treat all data that travels over their networks fairly, without improper discrimination in favor of particular apps, sites or services. Even as the Federal Communications Commission (FCC) is pushing a plan to end net neutrality protections in the U.S., India's telecom regulator has called for strengthening the principle of non-discriminatory access to the Internet.\n\nThis week the Telecom Regulatory Authority of India (TRAI) recommended amending all existing ISP licenses in India to explicitly prohibit discriminatory traffic management practices. Having rules in place that restrict ISPs and telecom providers' ability to control access to content via their networks is important for a free and an open Internet. Such rules prevent network providers from degrading the quality of service or blocking access to apps to earn revenue or to limit competition.\n\nThe FCC's Open Order 2015 had also banned throttling, blocking and paid prioritization in the provision of broadband Internet access service. Unfortunately, as of last week FCC has proposed eliminating these bright-line rules against blocking, throttling, and pay-to-play in favor of a simplistic transparency requirement. Even as the FCC attempts to create a pay-for-play Internet, in India TRAI seems to be adopting a layered framework for regulatory intervention designed around two closely interrelated areas.\n\nFirst, TRAI has been working to create reasonable and equal rules to govern services provided by telecom operators and Over-the-top (OTT) services. OTT services refers to communication or non-communication based services that ride on telecom operators' networks. In India, TSPs operate under a licensing regime which come with strict obligations. On the other hand OTTs have flourished without such regulations. The disparity in regulation was not an issue when OTT services were new. Their rapid growth over the years and shrinking telecom revenues led to demands for introducing licensing for OTTs or creating restrictions on the services which they may offer.\n\nWhile it is important to create uniformity in the regulation of functionally equivalent services, calls for regulating Internet based OTT service providers ignore the differences that exist between them and telecom operators. While TSPs operate at both the network and application layer, OTTs can only function at the application layer of the Internet. Therefore, it is inappropriate to bring OTT service providers under the licensing regime similar to those that currently apply to TSPs.\n\nMoreover, the advent of 4G technology has allowed for changes in the network architecture which in turn have helped markets evolve and ushered in regulatory changes. For example, traditional telecom services like voice calls are also capable of being delivered over an IP based network and may share the same infrastructure as Internet based services.\u00a0Content providers are no longer reliant on telecom operators for last-mile access and are using content delivery networks (CDNs) to directly interconnect.\n\nOver the years India has also moved to the Unified Licensing regime under which the Unified License with authorisation for Access Services (ULA) now allows for interconnection between IP Telephony and the telecom network. TRAI's recent interventions suggest a principles based approach that is cognizant of these new, complex and evolving dynamics. In TRAI's Recommendations on Regulatory framework for Internet Telephony\u00a0issued in October 2017, the authority notes \"that as per the present licensing framework, Internet Telephony service can be provided independent of the Internet access service. In other words, the Internet Telephony service is un-tethered from the underlying access network.\"\n\nImportantly, TRAI's has limited its recommendations on VoIP to communication OTT players. The mandate of licensing and/or regulating non-communication OTTs is that of the Parliament and will require a major overhaul of Information Technology, Telecommunications and Broadcasting legislations. By staying within its mandate and not crafting regulations for non-communication OTTs, TRAI has left the door open for regulating such services through instruments outside of a stifling licensing regime.\n\nIn parallel to creating uniformity of regulation TRAI's interventions have also been focused on codifying the principle of net neutrality including its different components and exceptions. In February 2016 TRAI issued an order prohibiting differential pricing which led to Facebook's Free Basics programme to be banned in India. TRAI's latest recommendations on net neutrality focus on modifying licensing terms fall under this second category of TRAI's interventions.\n\nUnlike its order on differential pricing order TRAI's latest recommendations on licensing issues are not binding. This is because while TRAI has the power to frame regulations on issues such as pricing, QoS, and interconnection, the Department of Telecom (DoT) has final authority on matters related to granting or modification of licences in India. But if TRAI's recommendations are accepted by the DoT, ISPs in India will be explicitly prohibited from and penalised for blocking, throttling, slowing down, or granting preferential speeds or treatment to any content on their networks.\n\nThe recommendations also lay down a set of principles for introducing net neutrality. TRAI recommends that the principle of non-discriminatory treatment of content should apply specifically to Internet access services. It also suggests that network management should be a permissible exception to net neutrality noting \"that allowing TSPs to carry out reasonable traffic management practices is necessary for delivering IP traffic on best efforts, which is essential to the design of the Internet.\"\n\nTRAI has advised exceptions for \"other legitimate purposes\" from the requirements of non-discriminatory treatment in the provision of Internet access services. Exceptions have been provided for congestion management, for blocking unlawful content pursuant to a court or government order, and for maintaining security and integrity of the network. Discrimination in traffic management has also been recommended for Content Delivery Networks (CDNs) as they do not change the priority of the data packets.\n\nThe regulator specifies that exceptions to net neutrality should only be allowed when they meet the basic requirements of reasonableness. In other words, there must be legitimate grounds for network management such as maintaining integrity of the network or for user security and/or if the user has specifically requested for such a service. It also recommends transparency in network management and advises that DoT should retain the flexibility in licensing regime to specify further details and change regulations regarding the scope and assessment of reasonable traffic management practices.\n\nThe authority has also advised supplementing \"existing disclosure and transparency requirements by framing additional regulations in this regard.\" \u00a0While TRAI has not specified what such regulations should look like, the recommendation essentially seeks to introduce a transparency requirement for standardised reporting of network management practices, service information including privacy policy and redressal options and most importantly the exercise of exceptions to net neutrality.\n\nFinally, TRAI introduces the concept of a multi-stakeholder, not-for-profit body led by industry, with ISPs, telecommunications companies, large and small content providers, representatives from research and academia, civil society organisations and consumer representatives be created for monitoring traffic management in India. It is unclear why it recommends that such a cooperation platform be industry led but one reason could be because transparency enforcement applies most to private companies.\n\nTRAI has introduced the concept of \"Specialized Services\" in its recommendations on differential access. TRAI defines the concept as \u201cservices other than Internet access services that are optimized for specific content, protocols or user equipment, where the optimization is necessary in order to meet specific quality of service requirements.\u201d In other words specialised services refers to services provided on a network that is either physically distinct from the Internet using different pipes or logically distinct from the Internet using access controls over the same pipes.\n\nFollowing TRAI's definition this includes services that demand high QoS (such as remote surgeries) or for which best efforts delivery is not feasible on the Internet (such as autonomous vehicles). Similarly services being provided over a Closed Electronics Communications Network would qualify for being classified as specialized service. TRAI suggests creating an exception from net neutrality obligations for such special categories of services. Similar exceptions have been provided in in the EU through Amendment 236. On the other hand, regulators in Netherlands, have avoided creating exceptions for specialised services based on the rationale that defining the concept is not necessary to protect the functioning of managed, non-Internet based services.\n\nTRAI's recognition of specalized services is an notable development. Going forward, the concept of specalized services will be relevant for its intervention on creating regulatory parity on a number of issues currently under consultation. The U.S\u00a0FCC Open Order 2010 states that \u201cspecialized services\u201d such as facilities-based VoIP and Internet Protocol-video offerings differ from broadband Internet access service and may drive additional private investment in broadband networks. The FCC had also pointed out that such services can provide end users valued services, supplementing the benefits of the open Internet. It remains to be seen if the definition of specalized services will be tailored and applied in other areas such as Internet telephony and IoT.\n\nThe recognition of specalized services is also relevant to the codification of exceptions for net neutrality. Provisioning exceptions for specialized services will allow ISPs to charge for providing guaranteed levels of service and quality for certain forms of data or time sensitive communication. \u00a0Concerns have been raised that establishing conditions for violations of net neutrality regulators creates the possibility that network operators may prioritise high quality specialised services over the provisioning of \"standard\" Internet.\n\nAddressing such issues TRAI has laid down the parameters such as for the provision of specialized services. It notes, \"While allowing for the provision of specialised services, service providers should ensure that they have adequate network capacity to offer the critical services in addition to the overall provision of Internet Access Services.\u201d\n\nTRAI has also specified some categories that qualify for specalized services, \u201cThe license agreement identifies the categories of services that can be offered by licensed service providers. This includes the provision of VoIP and IPTV services, which may also qualify as specialised services under the suggested definition.\u201d It has also recommended that DoT retain the flexibility to \"amend the license from time to time to specify the categories of services permitted to be carried out by licensed service providers.\"\n\nOverall the recommendations are good news for both users' right to a free and open Internet in India and creating a stable regulatory environment for businesses to operate there. The strong recommendations are also reflective of the giant strides the Indian telecom regulator has made in outlining a nuanced approach to this complex issue. TRAI's leadership, its transparency and efforts to listen to the voices of its citizens create a stark contrast with the FCC's regressive approach."},
{"url": "http://www.scenariomagazine.com/the-neo-generalist/", "link_title": "The Neo-Generalist", "sentiment": 0.13649974488372274, "text": "This is a free article from\u00a0SCENARIO 01:2017. If you are not a current subscriber to\u00a0SCENARIO\u00a0or a member of\u00a0The Copenhagen Institute for Futures Studies, then\u00a0subscribe\u00a0or get in touch with us\u00a0here.\n\nWork specialisation and the division of labour have been central characteristics of civilisational development, from ancient times to our post-industrial present. Yet the case can be made that we may have taken our inclination to specialise too far. In their new book The Neo-Generalist, authors Kenneth Mikkelsen and Richard Martin claim that our cultural, societal and professional worlds are enthralled by extreme and inhibitory specialisation, and that it is time to make a change. They argue that now more than ever, we need the outlook of the \u2018neo-generalist\u2019 if we want to thrive in an uncertain future.\n\nSo what exactly is a neo-generalist? He or she is both specialist and generalist, masters several disciplines and has an eclectic and inquisitive outlook. A neo-generalist is less willing to stay within the bounds of highly specialised fields that lead to \u2018silo mentalities\u2019 and stagnant thinking, and more keen to adopt a multidisciplinarian approach to work. Neo-generalists search for inspiration in both their neighbouring disciplines and in fields unrelated to their professional expertise. This, argue Mikkelsen and Martin, allows the neo-generalist to to bridge people, ideas and domains, and suggest new solutions to problems that it would be harder for a hyperspecialist to spot.\n\nMany of the lessons presented in The Neo-Generalist are drawn from interviews with professionals, artists, writers, scientists, athletes and film makers, as well as from historical figures that each in their separate ways embody the neo-generalist approach to work and life. This diverse cast of characters underlines a point central to the book: that there is no fixed, one-way approach to neo-generalism, and that what Mikkelsen and Martin are describing is more of a mindset than a how-to guide. Read our interview with Mikkelsen and Martin below.\n\nYou argue that the world needs more generalist thinking if we want to avoid being stuck in self-enclosed \u2018silo mentalities\u2019, and that we should \u2018generalise to specialise\u2019. Can you explain what you mean by this?\n\nKenneth: The governing narrative in society is specialisation, which makes it hard for many people to appreciate and understand what defies easy categorisation. Neo-generalists are people with a diverse set of interests that practice serial mastery. They have the capacity to switch in and out of specialism and generalism as context dictates. We claim that their work is often overlooked, undervalued and misunderstood in a world that imposes a sense of order by attaching labels to people and separating ideas into spatial and mental boxes.\n\nMost thinking today suggests a relationship predicated on the false understanding of specialists and generalists as discordant practices. We present the two practices, not as a dichotomy, but as a continuum, suggesting an equal and mutually amplifying relationship that can be found in their close collaboration.\n\nSilos exist in structures. But they also exist in our minds and social groups. Silos breed tribalism and go together with tunnel vision. We argue that the pendulum has swung too far in the direction of hyperspecialism, and that there is a strong need for neo-generalists if we are to resolve the world\u2019s interconnected global, social, environmental and economic challenges. We need hyperspecialists to work alongside neo-generalists who not only serve as connectors, bridging between disciplines, but who see the big picture and bring into play metaskills like combinatorial creativity, systems thinking and pattern recognition.\n\nRichard: Consider this hypothetical scenario. Two people separately seek to address a water supply issue in a sub-Saharan village. One has a geology degree. Their subsequent career has involved specialism in water reuse and desalination in Latin America. The other has an interdisciplinary academic background, which includes topics as diverse as geography, anthropology, geology, political studies and languages. Their career has been multifaceted, requiring them to draw on different aspects of their educational background, as well as acquiring new skills, while they have fulfilled a variety of roles around the world.\n\nWhich do you think is most likely to effect an appropriate solution that meets the community\u2019s needs in Africa? The one-track specialist, now finding themselves confronted with a slightly different challenge, or the multidisciplinarian?\n\nDo you think the opposite case could be made: that increased specialisation is what has allowed us to accomplish otherwise unattainable goals \u2013 from ancient bureaucracy to the space shuttle \u2013 by dividing complex tasks out among ourselves?\n\nRichard: No, I do not. I believe that the multidisciplinarians have been necessary to many of these accomplishments. Often they are the ones who have the vision, the big-picture perspective, to join up the different fragments that have resulted from the work of the specialists. It is difficult for a President, Prime Minister, CEO or General to pursue a specialism once they attain these positions. Their leadership responsibilities require neo-generalism.\n\nSomeone has to maintain a bird\u2019s-eye view while being willing to swoop down into the minute detail on occasion too. Think, for example, of the different elements that went into the first Apple Macintosh computer. They were sourced from or inspired by different people, different companies. But it took someone with neo-generalist proclivities to see how they would all fit together not just as a piece of technology but as an experience.\n\nExtreme compartmentalisation and fragmentation can result in dysfunction and systemic failure. You mention the space shuttle. An amazing accomplishment on many fronts. But to what extent were localised specialism and lack of connection and understanding factors in the Challenger and Columbia incidents?\n\nKenneth: We are not arguing that specialists are irrelevant or that we should do away with them. There is proven value in specialisation. In a historical context, clusters of knowledge formed around a craft or discipline have played a major role in the development of societies. Murano [a group of islands north of Venice, ed.) became a center for glassmaking in the 13th century when the Venetian Republic ordered glassmakers to settle on the islands, fearing that fires could destroy the inner city\u2019s wooden buildings. It is, however, not the hoarding of knowledge that produces important innovations. It is when ideas are shared, discussed and built upon in a diverse network of individuals and organisations that breakthrough innovations happen. The invention of greenhouses, spectacles, microscopes, telescopes and the camera all depended on utilising glass in new ways. But it was not the glassmakers of Murano that came up with these innovations. They did not have the imagination, ingenuity or skills to apply their specialised knowledge to other domains. The lesson to take away, is that information spillovers depend on people who can cross boundaries, bring a broader perspective into consideration and apply existing knowledge in a different context.\n\nHierarchical bureaucracy, the standardisation of best practices and linear thinking served us well in the industrial age, but we are beginning to see societal and ecological crises and massive institutional breakdowns as a consequence of this somewhat antiquated approach.\n\nIn what areas of society do you see hyperspecialism as being most damaging or inhibitory? Where could we benefit from a neo-generalist approach?\n\nRichard: Education. It all starts in schools and the mandates imposed on them by governments obsessed with measurement. The tendency to always value the quantitative over the qualitative is disturbing. The advocacy of admittedly important STEM disciplines at the expense of the humanities and social sciences is madness. Both are essential. There is a constant stream of business and leadership literature on the importance of community, networks, trust and relationships, yet those very subjects (literature, art, history, philosophy, anthropology) that help us achieve an understanding of humans and our interactions are being diminished by policymakers.\n\nSince the late Renaissance, on through the Enlightenment and into the Industrial era, we have witnessed this tendency to segregate disciplines. Why do we continue with it? Why should someone who wants to pursue a career as a physicist suddenly stop learning about music and art in their mid-teens and focus only on mathematics and the sciences? Is it not the case that certain poets and novelists have disseminated the wonders of scientific discovery to a broader audience than a scientist alone could reach?\n\nKenneth: The first example that comes to my mind is the financial crisis in 2008. The fragmentation of the financial system made it impossible for anyone to have an interconnected view of how risks were developing in the markets and banking world. We now know that specialist teams inside the institutions were operating in silos, competing for resources and failing to communicate and collaborate. To make matters worse, people were incentivised to take dangerous risks that sub-optimised isolated parts at the expense of the system as a whole.\n\nThe more expertise people gain, the more likely they are to develop rigid standpoints, focusing on giving answers rather than asking questions. Privilege, pride, ego, fear and laziness are all persuasive reasons for conserving what we have and slowing down change. When our careers depend on fitting in, we are less motivated to venture beyond the well-known territory of our specialism and challenge the complacency of the status quo. Neo-generalists do not just talk about new ways of thinking and being, they pioneer new ways of operating that we all can learn from, regardless of our occupation.\n\nIn your book, you list many examples of neo-generalists: artists, businessmen, athletes, etc. who have refused to adhere to a singular mode of thinking. Which person, living or dead, would you say is the best example of a successful neo-generalist?\n\nKenneth: From our interviews and extensive research it is clear that there is no simple formula for becoming a successful neo-generalist. We indicate that in the book\u2019s subtitle, Where You Go is Who You Are.\n\nWe aspired to write a poetic, smart-thinking book that invites the readers to make their own interpretation. Some people will be irritated by this approach, others will hopefully find it liberating and inspiring. Having said that, we did identify certain characteristics shared by neo-generalists.\n\nThey are comfortable living with not knowing and with ambiguity. They are self-directed learners, driven by an insatiable appetite to know more and explore new ideas. Just as cultures are not static, neither are our identities. Neo-generalists embrace this state of constant becoming. It is by living in more than one world that they know how to connect people and ideas, and shift perspective. Constantly, they examine and critique how they think, act and live. It is such habits that make shape their legacy and make them natural leaders.\n\nRichard: This is not a game that I would like to play, for a number of reasons. In The Neo-Generalist, we make three important points: First, there is no right answer, just contextually and temporally convenient ones. Second, to aspire to best practice is to accept that no further progress can be made. We refuse to subscribe to that point of view. To settle, to stand still, is the beginning of the end. Third, with the infinite loop, we indicate that life as a neo-generalist is one of constant shifts and adaptation.\n\nThere is no single point on the specialist\u2013generalist continuum where you can say, \u2018That is what a neo-generalist looks like.\u2019 Because the whole continuum reflects it, and our underlying message is that anyone can be a neo-generalist. Admittedly, most people we spoke to or who we researched in relation to the book probably had a preference for the space we denoted as polymathic generalism on the continuum. But they were highly adept at applying themselves at deep specialisms too. It is impossible to extract a model or an ideal from what we researched. No two people are exactly the same.\n\nBy way of illustration, compare how Kenneth and I have used writing. For Kenneth, trained as a journalist, it appears as a deep specialism. For me, writing is one of my most generalist traits; an arena in which I feel able to apply myself to whichever subject happens to take my interest in whatever style I fancy adopting. These differences became more overt in the way we wrote the book too, with Kenneth planning and mapping, and me discovering exactly what I wanted to say in the act of writing. Yet we are both neo-generalists. The same but different.\n\nWhat needs to be done to make us think more like neo-generalists?\n\nRichard: We could start by thinking in terms of continuums rather than either/or polarities. In the book, we visualise specialism and generalism as an infinite loop. If you begin from the perspective of both/and rather than either/or, you are immediately opening yourself to a more rounded, empathic point of view. One from which surprise, creativity and connection can all flow. One which enables high levels of responsiveness.\n\nKenneth: Our society will undergo a major transformation in the coming years as we make our way further into the Fourth Industrial Revolution. Technology is influencing many segments of life, and I think it is imperative that we have a much wider discussion about how we live a good and examined life under these new conditions. I see neo-generalists being important stewards of that conversation given their curious, responsive and adaptive nature. I hope that our book can serve as a conversation starter and hopefully open people\u2019s eyes to a more inclusive way of looking at the value that specialists and generalists add to society."},
{"url": "https://medium.com/@andrew_subarctic/things-you-cant-do-in-rust-juggle-743e34348f72", "link_title": "Things you can\u2019t do in Rust: juggle", "sentiment": 0.3916666666666667, "text": "I love Rust and want it to be better. The dev teams know about all issues presented. I just want to generate discussion and enthusiasm for making a good language better.\n\nThe error message is pretty straightforward \u201ccannot borrow \u2018v\u2019 as mutable more than once at a time\u201d. This means the compiler thinks that v is being mutably shared in two regions at the same time, when really there is just a nested scope. Non-lexical lifetimes are meant to fix problems like this."},
{"url": "http://www.tomshardware.com/news/brad-templeton-robocars-security-plan,36015.html", "link_title": "Robocars Should Be 'Disconnected,' Warns Former EFF Chief", "sentiment": 0.097309819121447, "text": "Brad Templeton, former EFF ChairmanBrad Templeton has been a software architect, a former Electronic Frontier Foundation (EFF) chair, an adviser to Google's self-driving car project, and a Chair for Computing at the Singularity University. He has recently started warning about the cybersecurity issues self-driving cars, or \"robocars,\" may face if automotive companies don't start to take security more seriously as they race to bring them to market.\n\n\n\nAccording to Templeton, robocars should not only be \"disconnected\" from the internet (in complete opposition to the \"connected car\" trend) to drastically reduce the attack potential against them, but car makers should also strive to secure everything from the cars' self-driving software platform to their sensors, manufacturing facilities, and update servers. Nothing should be left out, and everything should be designed with security in mind.\n\nBelow you can read the whole interview in which he talks about the state of security in today's car industry, as well as his proposals for how to make a robocar that would be resilient against cyberattacks.\n\n\n\nTom's Hardware: We\u2019ve asked a few companies in the past how \u201chackable\u201d their \u201cconnected cars\u201d are, and they all seem to say that they take security very seriously. However, we\u2019ve seen a few recent news stories about connected cars getting hacked in various ways. Do you think carmakers take security more seriously when it comes to their self-driving platforms compared to their connected cars? On a scale of 1 to 10, where 10 would mean their robocars are virtually unhackable, what\u2019s the grade you\u2019d give most self-driving cars right now?\n\nBrad Templeton: That\u2019s not easy to answer. First, nobody has published their security architecture. However, most cars today have limited connectivity. \u00a0They only talk back to HQ, they are not trying to talk to infrastructure or other cars. They will talk to the car\u2019s internal systems though, and in many cars, these are fairly vulnerable because they were not designed for security.\n\nMost teams report that they are taking security seriously but I am not aware of any that have published what that means.\n\nTH: How connected (or disconnected) should the robocars' critical systems and the entertainment systems be? Should they operate on completely different hardware computing platforms, or would operating in separate virtual security domains suffice?\n\nBT: I believe having fully distinct platforms and networks is the best choice. Why take a risk you don\u2019t have to? What do you really gain from connecting them two way?\u00a0 You can connect them one way \u2013 the driving system streams out status data which untrusted systems can display to the user.\n\nNote as well that the robocar of the future may not have much of an \u201centertainment system.\u201d That\u2019s in your phone, which is where you want it to be. The car may offer a larger screen, speakers, microphone, and other input devices to the phone, which is fine, but the intelligence belongs in the phone, not in the car.\n\nSo if the car\u2019s system is just some speakers for your phone to play music on, why does it need a connection to the driving system?\n\nTH: In a recent article, you said that sensors should also communicate over encrypted and authenticated channels. Are you aware if any of the automotive companies working on self-driving car systems are doing that currently? How would an attacker exploit these sensors?\n\nBT: There are different types of attacks we worry about. The most scary are attacks that can come over the air, especially over the internet, because those could compromise any car, or large number of cars at once, and could come from a remote attacker anywhere.\n\nThe next class would be ones that come over the air locally, through things like Bluetooth or DSRC, or tire pressure sensors. Those are not quite as scary but still pretty bad because if you can infect one car, it can drive around talking to other cars and infecting them, and soon you can reach every car.\n\nLeast scary are attacks that require physical access to the car. \u00a0That\u2019s where you\u2019ll find most attacks that involve compromising a sensor or the car\u2019s physical network. That\u2019s still something to worry about, but the attacks don\u2019t scale up to large numbers of cars. As such, I suspect this is not as high on priority lists.\n\nDown the road there is the risk that a sensor might get so \u201csmart\u201d that its internal processors \u2013 and all sensors will have processors \u2013 might be compromised just with malicious sensor data. That\u2019s not super likely but it\u2019s not impossible, [and] it should be on the laundry list.\n\nTH: How important is secure manufacturing for critical robocar components? Should manufacturing processes have to be regularly audited, too? Is that the case right now?\n\nBT: If a component can talk to your driving system directly, there is a risk that if it is malicious, it might take that over. \u00a0Mainly you want to be paranoid about all inputs.\u00a0 The makers of components you use need to be trustworthy, and their own security procedures have to be trustworthy.\u00a0 \n\n\n\nFor example, if your radar manufacturer is itself trustworthy, but they have a security breach or compromised insider which allows an attacker to plant malware into the firmware of the radar, and that radar is put on a trusted internal network, it could compromise you.\u00a0 It is difficult to fully vet all internal security procedures at all your suppliers, but you should try, and at the same time be wary that your components might be out to get you.\n\nTH: Do you believe robocars should have to pass certain government or third-party security screening and certification programs before they are allowed on the market?\n\nBT: This might become the case eventually. \u00a0I don\u2019t believe any regulatory body has the capability to do this well at present. There is a risk that one could make a procedure so complex that it slows the deployment of even important safety updates. Companies should certainly produce at the minimum a self-certification document on their security hygiene rules.\n\nTH: What\u2019s your opinion on self-driving car software being open source? Should consumers petition carmakers to open source all critical software that is used by the autonomous driving system? Would it even matter if it was open source, from a security point of view?\n\nBT: This is a controversial issue. There is evidence that allowing all parties to scrutinize the code is the best path to finding vulnerabilities. This is particularly true when many parties are using the same code and are motivated to keep it secure and high quality. This is a trade-off against the fact that access to the source code can make it easier for attackers to discover vulnerabilities and build exploits for them.\u00a0 \n\n\n\nIt is complicated by the problem that manufacturers, who will be required to certify the safety of their vehicles, will try to design them so that they can\u2019t run any code that is not signed by the manufacturer. \u00a0This means that tinkerers won\u2019t be able to easily tweak and improve the code, which is one of the key benefits of open source. \u00a0While millions use slightly modified versions of operating systems like Linux on their PC, that won\u2019t be the case with cars.\n\nTH: Some cars have come out with entertainment systems that used a three- or four-year-old Android OS version, that likely comes with a browser that hasn\u2019t been updated in years, too. Should car manufacturers continue to develop their own entertainment systems, or should they focus on better integrating their systems with the car owner\u2019s or passenger\u2019s mobile devices?\n\nBT: From a business standpoint, users want their music and other entertainment on their phones, and don\u2019t want to have to use a different system when they get in a car. Car makers are reluctant to give up the large fees they charge for infotainment systems. The car should primarily offer a screen and speakers to the phone. From a security standpoint, neither the infotainment system nor the phone can be trusted, so they should be air-gap isolated from the driving system.\n\nTH: Are the current industry-specific programming languages good enough for writing self-driving platforms with them, or should the industry use safer programming languages to significantly reduce their software\u2019s attack surface?\n\nBT: This is another challenging question. The easy answer is yes, we should all be using better languages and tools which are designed for security. On the other hand, since these are young and not well deployed, they don\u2019t have the same wealth of tools available and fewer programmers are highly trained in their use, so work will be much slower. \u00a0I believe the whole industry has to bite this bullet, however.\n\nTH: A few years ago, BMW, for instance, was sending software patches over unencrypted connections. Today, they are one of the main carmakers focusing on building robocars. How important is server-side security for self-driving cars?\n\nBT: Actually, you can\u2019t trust the network, so you should design not to trust it. Properly done, all software patches are digitally signed by multiple parties and so it is OK to send them over untrusted networks. \u00a0(On the other hand, cars should not even parse incoming messages that are not signed and verified.) \u00a0This is easy and I would presume BMW does this. Harder is the problem of worrying that an internal breach inside a company has them produce a compromised update which is then signed by their keys and trusted by the cars. You need to make it so that no update is signed unless all changes to it have been audited by well designed and secure code review, and all tools which build the update (like compilers, linkers, etc.) are also secured.\n\nThis is one clear place for open source. \u00a0The software development tools need to be secured, and updates to them must be verified as well.\n\nTH: In your post, you also mentioned that it would be best if robocars would receive their patches at \u201cupdate stations\u201d rather than automatically over the air. Automatic updates are usually considered a good thing by security experts. Why do you think they are a bad solution for self-driving cars? What would be the best way for robocar manufacturers to update their cars?\n\nBT: This is a radical trial balloon to make people think differently. All updates, whether over the air or done in a physical place, must be well audited and signed. However, different updates will have different urgencies and affect different parts of the system. You can have over the air updates, and need them for urgent situations, but to keep them secure, you might require that over the air updates need to be signed by well secured keys kept in physical vaults by senior executives. \u00a0Ie. \u00a0You can\u2019t do an OTA update without having the CEO go to the vault in her office to pull out a signing key. And the CTO and team leads. Lower priority updates, with lower risk, might not need signing at that level but could instead require the vehicle go to the depot, so that it\u2019s impossible to do an update without people noticing it.\n\nTH: For the past few years, people have been getting excited about Vehicle to Vehicle (V2V) and Vehicle to Infrastructure (V2I) communications. Are these technologies necessary for the success of robocars and do they represent any danger to the security and safety of robocars?\n\nBT: They are definitely not necessary for the success of the cars, and the major teams have no plans to depend on them. Since there will always be lots of vehicles (and pedestrians and deer) with no transponders, it is necessary to get to \u201csafe enough\u201d with just your sensors. Extra information can at best be a minor supplement. Because it will take more than a decade to get serious deployment of V2V, other plans (such as use of the 4G and 5G mobile data networks) make much more sense for such information.\u00a0 \n\n\n\nIn addition, it is a serious security risk, as you say, to have the driving system of the car be communicating complex messages with random cars and equipment it encounters. Since the benefits are minor and the risk is high, this is not the right approach.\n\nTH: If self-driving cars are hacked, who should take the blame? Is it the car owner, the car manufacturer, the third-party vendor of the autonomous driving system, or should governments just focus on catching the malicious hackers and ignore everything else?\n\nBT: Morally, of course, the blame is always on the attacker. \u00a0However, makers of systems have a duty to make them robust. Liability is rare, right now, in computer security, but it probably will fall on whoever put the car on the road (the vendor or fleet operator. They, however, will insist on assumption of liability by the maker of the driving system, if that is another company.\n\nTH: Do you believe that remote hacking of self-driving cars will keep people away from using them, or do you think these cyberattacks will be rare enough that most people will largely ignore them?\n\nBT: If there is a \u201cnightmare\u201d attack, where somebody compromises an entire fleet of cars, and is able to cause physical harm or even make a demonstration of the ability to make them crash or run people over, that could cause people to stay away from using them. That\u2019s why there needs to be very high attention on any attacks which could take over an entire fleet.\u00a0 Attacks against a single car, particularly those that require physical access to the car, will still scare many people, but the truth is cars are already vulnerable to that today, and have been since the day somebody could cut your brake line or install an ignition bomb.\n\nAttacks that require proximity but not physical access (like a Bluetooth, V2V, or Wi-Fi attack) should scare anybody who thinks they might be an assassination target, but they also offer the risk of a \u201cvirus\u201d where cars infect other cars as they drive by.\n\nWe should work hard to secure these vehicles, but it would be a major error to not use them because of these risks. At least for now, the death toll from human driving is much higher. \u00a0We should not avoid technologies that prevent real deaths out of worry over hypothetical ones."},
{"url": "http://www.aiindex.org/2017-report.pdf", "link_title": "AI Index: 2017 Annual Report [pdf]", "sentiment": 0.0, "text": ""},
{"url": "https://medium.com/@melissamcewen/what-if-other-professions-hired-like-software-development-d40d2ae256fc", "link_title": "What if other professions hired like software development?", "sentiment": -0.02499999999999999, "text": "What if other professions hired like software development?\n\nThanks for applying to be a Civil Engineer at Acme Building Co., we have a small at-home exercise we\u2019d like you to complete to be considered for this position. The task is to build a small bridge over a body of water. We know everyone has a different approach to building bridges, so feel free to build any style you\u2019d like with your preferred materials. It can be built over anything, from a small trench you dug by hand to a minor creek. It should take about three hours."},
{"url": "https://www.atlasobscura.com/articles/welcome-interactive-fiction-wizard-sniffing-pig-controversy-video-games", "link_title": "Welcome to Interactive Fiction: You're a Wizard-Sniffing Pig", "sentiment": 0.10256772731348998, "text": "Buster Hudson discovered interactive fiction by chance. While exploring the vast world of online game sites, he happened upon a game called Counterfeit Monkey, in which you play a smuggler of language technology, pursued by the Bureau of Orthography and eager to escape an island named Atlantis.\n\n\u201cI fell in love,\u201d he says. \u201cI don\u2019t want to say interactive fiction is better than other video games, but it\u2019s a different experience. You get to explore a world through text.\u201d\n\nInteractive fiction, in brief, can be thought of as a computer game made only of words and symbols, or an online novel in which the reader can talk to characters, explore the setting, and maybe affect the plot.\n\nMany people, when they hear about interactive fiction, compare it to Choose Your Own Adventure books. Those who played computer games in the \u201880s might connect it to Zork, a text-based adventure in which players wander an underground empire in search of treasure. But interactive fiction can do much more than strand you in the past with Maya warriors or leave you stumbling around a dungeon for hours. A game might cast you a person struggling with depression, put you in conversation with a piece of art, or require that you eat your way out of a castle made of food.\n\nWhen Hudson started writing his own interactive fiction, he used his games to talk about the experience of being gay\u2014though so subtly, he says, that he\u2019s not sure anyone noticed. But his most recent work has wizards and goblins, too. The Wizard Sniffer is a game built around the troubled relationship between a parent and a child, in which you play a pig who\u2019s supposed to be able to sniff out wizards. The winner of this year\u2019s Interactive Fiction Competition (IFComp), it\u2019s a slapstick comedy of errors, with bumbling heroes, marriages of convenience, and affectionate monsters guarding surprising secrets.\n\nIFComp, now in its 23rd year, received more entries this year than ever before and, for the first time, offered a pool of cash prizes. Little known and little understood, interactive fiction has grown quietly, but is now permeating American culture more deeply than most people realize. A piece of interactive fiction was the spark that grew into the misogynist controversy known as Gamergate, and this year two works of interactive fiction were featured in the Whitney Biennial.\n\n\u201cPeople keep telling me interactive fiction is dead,\u201d says Nick Montfort, a poet and professor of digital media at the Massachusetts Institute of Technology. (In fact, there was an infamous forum thread in 2014 titled \u201cIF is Dead.\u201d) \u201cBut it seems to be continuing to appear in new contexts, and the old ones seem to be expanding.\u201d In 2017, interactive fiction is alive and growing.\n\nInteractive fiction traces its history to the text-based adventure game Colossal Cave Adventure, developed in 1976. In 1980, the early gaming software company Infocom released Zork, and for a brief time the company\u2019s games were some of the most popular computer programs that had ever existed. Then graphics appeared, and fewer people wanted to play games with only words when pictures were an option.\n\nMany text-based games rely on what\u2019s called a \u201cparser,\u201d which lets players type in commands and see how the game reacts. Certain words are standard actions or qualifiers: look, take, go, north, south, east, west. The most expansive parser games had large vocabularies of prompts, and revealed secrets to players who could guess the right words.\n\nIn the 1990s, people nostalgic for these games found their ways to Usenet boards for interactive fiction, where Infocom fans gathered along with people experimenting with hypertext fiction, in which links let stories branch and move in ways impossible on the printed page.\n\nFans created tools that made it easier to write and share new interactive fiction, and in 1993 one author, Kevin Wilson, organized the first Interactive Fiction Competition with the aim of encouraging people to write shorter games, instead of the hours-long epics they\u2019d been working on. To this day, entries in IFComp are supposed to be playable in under two hours.\n\nPhotopia, submitted in 1998, was one of the first competition games to push the boundaries of the medium. Text-based adventure games had always had puzzles\u2014they can be one of the great pleasures of these games\u2014but Photopia kept its puzzles limited and simple. The player could still walk around the settings and interact with other characters, but playing this game felt more like reading an emotional story than its forebears had. It made people cry.\n\nGames like Photopia pushed writers to experiment with the unique possibilities of interactive text. The form invites complicity: The person playing the game is cast as the protagonist and might be required to make frightening choices or commit unthinkable acts to proceed.\n\nStarting in the 2000s, it became popular to write games with tough ethical choices, says Stephen Granade, who organized IFComp for many years, and not everyone in the community appreciated the turn away from lighthearted romps. After the original renaissance of the form, the annual number of entries in the competition dropped below 50 from 2001 until 2015.\n\nThis year, though, IFComp had 79 entries, a record high. The growth of the past few years has come from the second mode of interactive fiction\u2014hypertext games.\n\nIn 2009, developer and writer Chris Klimas released Twine, an open-source tool that made it easy to create interactive fiction using links, rather than a parser, to invite player input. Twine lent itself to more personal stories of pain and struggles with the self and identity. Porpentine Charity Heartscape\u2019s howling dogs, submitted to IFComp in 2012 and featured this year at the Whitney Biennial, was made in Twine.\n\nTechnically, howling dogs is a \u201cchoice\u201d game, where paths branch and the reader chooses the next move, but the choices don\u2019t drive the plot. In the game, you find yourself in a featureless cell, you eat and drink and maybe shower, and you pull on a visor that transports you into a hallucinatory dream world. Inevitably you end back in the cell, and drawn back to the visor as conditions around you deteriorate. The game didn\u2019t win IFComp, but it convinced many people of the power and possibilities of hypertext work.\n\nNot everyone in the interactive fiction community is happy with the shift. That \u201cIF Is Dead\u201d thread in 2014 started with someone bemoaning the lack of attention to parser games.\n\nAt that time, this seemingly esoteric complaint was culturally loaded. Twine games had become popular vehicles for stories about LGBTQIA issues and the experiences of other marginalized people. Twine authors were more likely to be women than men. The game Depression Quest, the seed of Gamergate, which had begun months before, was a Twine game. If critics of Twine games thought they were just marking out room for the parser games they loved, their disdain\u2014some of the most aggressive parser partisans vowed to automatically give non-parser IFComp entries the lowest score possible\u2014came across as bias, or at least a tone-deaf move to exclude people subject to long histories of discrimination.\n\nIn this year\u2019s IFComp, the two top-ranking games were parser-based, but as parser games go they\u2019re welcoming to newcomers. \u201cParser-based interactive fiction is very good for letting you solve an underlying riddle,\u201d says Montfort, from MIT. \u201cIt lets you figure out something about this simulated world, maybe in the way a detective encounters some kind of mystery. The game contains a test for its own understanding.\u201d\n\nBut in some parser-based games that understanding can be elusive, because the text doesn\u2019t give enough clues, and leaves players groping around for the triggering words. In \u201climited parser\u201d games, such as The Wizard Sniffer, the list of words that can help you explore the world is short and defined. As the wizard-sniffing pig, the most powerful action you can take is to sniff. As the gluttonous child in Eat Me, the second-place game this year, the most powerful action you can take is to eat. And eat. And eat some more.\n\nThe games that placed third and fourth, though, were hypertext games. In Harmonia, by Liza Daly, you play an adjunct professor investigating the disappearance of the person whose class you\u2019re teaching. Most of the choices in the game are about how deeply you want to dig into the text. Links lead to footnotes. The world isn\u2019t made of rooms, but of historical facts.\n\n\u201cI was trying to recreate the experience of being in the library and following chains of reference,\u201d says Daly. The one dramatic juncture, where the player can change the course of the game, is a moment of real decision, rather than arbitrary choice.\n\nWill Not Let Me Go, which placed fourth, follows a man diagnosed with Alzheimer\u2019s disease. In some places, the words stutter along or are hard to locate. In another, the world you\u2019re exploring is your own house, where simple objects keep eluding you. The game\u2019s author, Stephen Granade, the former competition organizer, has written many parser games, and he found writing the hypertext Will Not Let Me Go a new challenge. \u201cSome of my skills in terms of how to write in second person to indicate what you should be paying attention to did carry over,\u201d he says.\n\nWhat connects these two modes of interactive fiction\u2014parser and hypertext? \u201cThere\u2019s no other experience based around text that so immediately and so intimately rewards close reading,\u201d says Jason McIntosh, who has organized the competition for the past few years. \u201cIt takes everything that\u2019s good about text, and everything that\u2019s good about video games, and combines them in the best way.\u201d\n\nHudson, who\u2019s drawn to the special power of parser games, sees interactive fiction writers pushing the storytelling possibilities of that style, too. Puzzles in parser-based games can be used as little more than entertaining diversions\u2014but they can also control pacing, add comedy, test a player\u2019s complicity, or develop characters. Once, says Hudson, a character connected to a puzzle might act more as a key or a door, rather than a more fully developed person. \u201cNow the puzzles exist because of the people,\u201d he says. \u201cThey help you spend time with the characters.\u201d\n\nHe\u2019s proud, too, that The Wizard Sniffer drew in some way from both modes of interactive fiction. \u201cNot only did I make a game that came in first,\u201d he says, \u201cI made a game that\u2019s a queer story that came first.\u201d There have been past winners with queer characters (one with a hidden commend to turn \u201cHETERONORMATIVITY OFF\u201d), but The Wizard Sniffer appears to be the first story built around a queer theme to ever win IFComp.\n\nAfter the \u201clargest and highest-quality year in the competition\u2019s history, [IFComp] has a lot of momentum right now,\u201d says Jacqueline Ashwell, who\u2019s taking over as organizer. The aim is to make next year\u2019s even better. One of the great charms of IFComp is that anyone who plays at least five of the games can act as a judge. All you have to do is wait a year and start exploring."},
{"url": "https://techcrunch.com/2017/11/30/graphic-india-raises-5m/", "link_title": "Graphic India raises $5M to build a Marvel-like digital comic brand for India", "sentiment": 0.14763419913419915, "text": "It\u2019s been some time since we wrote about Graphic India, a new media startup that believes India should have its own home-grown answer to cartoon empires like Marvel.\n\nThe 30-person company been busy developing its IP and bringing its creations to\u00a0audiences via film and TV since we last covered it in 2015, when it raised $2.5 million from investors, and now it has added to that war chest after pulling in an additional $5 million.\n\nThe new investment in Liquid Comics, Graphic India\u2019s parent company, comes from existing backers Start Media and Backflip Studios\u2019 co-founder Julian Farrior with 3One4 Capital and Zodius Capital founder Neeraj Bhargava among the others that took part. Previously, the\u00a0Chernin Group backed the startup via its Asia-focused CA Media fund.\n\nWhen we last spoke to Liquid Comics CEO\u00a0Sharad Devarajan, the company was on the cusp of moving into mainstream media after developing IP and selling comics via Amazon and other channels. It has since expanded further.\n\nAstra Force, its animated series starring Bollywood icon\u00a0Amitabh Bachchan, premiered on the Disney Channel, while another series \u2014\u00a0Baahubali: The Lost Legends \u2014 was broadcast on Amazon Prime and is set to be shown on Viacom18\u2019s India-focused channel Colors. Away from traditional media it has also seen some successes online. 18 Days: The Mahabharata \u2014 a series from prolific DC Comics\u2019 cartoonist\u00a0Grant Morrison \u2014 racked up seven million views across YouTube, Facebook and web video services.\n\nGraphic India also ventured into mobile with two library-based comic book apps, and it snagged a comic book and animation deal for smash-hit Indian film series Baahubali, which has made inroads in the U.S. market\u00a0and broken Indian box office records.\n\n\u201cIt was really India\u2019s Star Wars moment,\u201d\u00a0Devarajan said of the two Baahubali films. \u201cOur job was to\u00a0create an experience that went beyond the screen.\u201d\n\nNow the Bangalore-based company is looking to build on that progress with this new funding in the bank.\n\n\u201cWe\u2019ve been aggressive with digital comics, digital shorts and producing animated shows,\u201d\u00a0Devarajan told TechCrunch in an interview. \u201cNow the challenge is whether we can\u00a0unlock that great creative potential in the pop culture space in India.\u201d\n\nThat, he explained, will see the company focus on more film, TV and web streaming deals while pushing its own subscription-based digital comic app, and looking into games, merchandising and even augmented reality and virtual reality opportunities.\n\nAR and VR, he added, are longer term visions that will take some time to reach large scale audiences in the U.S., let alone. Initially, however, the focus is on more affordable devices like Google\u2019s Cardboard project, but Graphic India is actively exploring\u00a0the possibility for higher-end devices, which are becoming popular as \u2018VR arcades\u2019 within shopping malls and other public places.\n\nGraphic India\u2019s business model is pretty different to the usual kind of startups that we write about on TechCrunch. The animation industry is primarily concerned with two areas: developing original IP \u2014 characters and series \u2014 and putting that IP to work in films, TV series and merchandising.\n\nThe former can be done in-house, but the latter requires partnerships with writers, broadcasters, networks and more.\n\nBeyond building a platform for India \u2014 and one that\u00a0Devarajan stresses will help up-and-coming Indian talent get the recognition they deserve \u2014 the aim is to make the brand and its work globally visible. That means bringing Indian content, which is typically based on mythology, beyond the Indian diaspora and to international audiences across the world.\n\n\u201cOur mission is to transform India from outsourcer to source,\u201d\u00a0Devarajan said. \u201cI think we\u2019re making huge strides doing it.\u201d"},
{"url": "https://phys.org/news/2017-12-scientists-efficiency-gene-technology.html", "link_title": "Scientists propose efficiency 'rules' for enhancing new gene editing technology", "sentiment": 0.10613598166539344, "text": "The new method and its development are described online in the Nov. 28 in the Proceedings of the National Academy of Sciences.\n\n\"CRISPR is a tool to help scientists modify the genome, predict the outcome of certain traits and study them, but the tool itself only creates breaks in the genome. It does not control how a new DNA sequence is inserted into the genome,\" says Geraldine Seydoux, Ph.D., the Huntington Sheldon Professor in Medical Discovery in the Department of Molecular Biology and Genetics and vice dean for basic research at the Johns Hopkins University School of Medicine, and an investigator with the Howard Hughes Medical Institute.\n\n\"We set out to study how cells repair breaks induced by CRISPR with the goal of using the cell's natural DNA repair process to introduce new sequences in the genome. We were surprised to find that cells will readily copy sequences from foreign DNA to repair DNA breaks, as long as the foreign DNAs are linear,\" Seydoux adds. \"By studying how foreign DNA fragments are copied during the repair process, we came up with some simple rules to make genome editing as efficient as possible, optimize the tool, and do so with confidence.\"\n\nCRISPR, which stands for clustered regularly interspaced short palindromic repeat, has gained popularity among scientists in the last five years as a tool to efficiently cut DNA. It was adapted for use in mammalian cells from a natural viral defense process in bacterial cells that involves creating lethal cuts in viral DNA. Essentially, the tool is a streamlined set of molecular \"scissors.\"\n\nThe prevailing belief, among scientists, is that cells repair DNA breaks by inserting a random set of nucleotides, the chemical building blocks of DNA. This usually destroys any gene that's located at the spot where the DNA is broken.\n\nIt's also well known to scientists that, occasionally, cells use a different source\u2014a sequence from another piece of DNA, or \"donor\" DNA\u2014to seal the break in DNA. However, the new \"donor\" sequence cannot be inserted by itself into an empty space in the genome.\n\nInstead, the new donor DNA needs a kind of tape at each end to help it stick within the gap made by the cut. Scientists refer to this tape as the \"homology\" arms of the donor DNA.\n\nThe homology arms consist of nucleotides that overlap the intact portions of the DNA with matching genetic code. This helps the donor DNA \"stick\" to the intact DNA.\n\nYet, scientists regarded using donor DNA as an inefficient way to repair the genome, assuming that it required long homology arms, especially when inserting a long DNA sequence, and single-stranded or circular DNA, which are difficult to prepare in long sizes.\n\nAs scientists gained more experience with CRISPR, Seydoux says, \"Questions arose about the optimal design rules for donor DNA and the length of the homology arms.\"\n\nSeeking answers to these questions, the Johns Hopkins scientists inserted various combinations of donor DNA into human embryonic kidney cells, known for their ability to grow well and for their frequent use in cancer research. The scientists used donor DNA with a gene that codes for a fluorescent protein, which glows green in the cell's nuclear membrane when the gene insertion is successful.\n\nJohns Hopkins research associate Alexandre Paix found that linear DNA fragments function very well as donors, and are two to five times more efficient than circular DNAs (known as plasmids) in human cells. \"Linear DNA is very easy to prepare in the laboratory, using PCR,\" says Paix, referring to polymerase chain reaction tools, which are used to amplify DNA.\n\nPaix also tested various lengths of homology arms. He found that the sweet spot for homology arms is about 35 nucleotides in length, much shorter than scientists typically use.\n\nSpecifically, it was found that homology arms of 33 to 38 nucleotides in length were as successful as those with 518 nucleotides, yielding between 10 and 20 percent successful edits under optimal conditions. In contrast, when the scientists tested homology arms of 15 and 16 nucleotides in length, the insertion success rates dropped by half. They repeated these results in three different locations in the human genome.\n\nThey also found that the newly inserted sequence, not counting the homology arms, can be up to 1,000 nucleotides in length.\n\nThe team achieved success rates between 10 and 50 percent with inserts ranging from 57 to 993 nucleotides in length. Shorter sequences were more successfully inserted than longer ones. For example, new sequences that were 57, 714 and 993 nucleotides long were successfully inserted 45.4, 23.5 and 17.9 percent of the time, respectively. Beyond 1,000 nucleotides, new inserts with 1,122 and 2,229 nucleotides had little success\u2014about 0.5 percent of the time. \"At that size, it becomes very difficult to introduce the quantity of donor DNA needed for editing. Cells tend to 'choke' on so much DNA,\" says Seydoux.\n\nFinally, the team also found that the success rate of editing peaks when the new sequence is positioned within 30 nucleotides from the CRISPR cut site. \"Beyond 30 nucleotides, the insertion is not workable,\" says Seydoux.\n\n\"These parameters should accommodate most genes that scientists are seeking to edit. In fact, most experiments involve editing only two to three nucleotides close to the CRISPR cut site,\" adds Seydoux.\n\nThe research team also tested whether the same approach could work in mouse embryos. Using a PCR fragment with 36-nucleotide homology arms, the team successfully inserted a 739 nucleotide-long sequence coding for a fluorescent protein into 27 of 87 (31 percent) mouse embryos.\n\nSeydoux's research team is already using the repair rules to study DNA in Caenorhabditis elegans, a species of worm, and the researchers are studying whether the repair rules apply to other types of human cells.\n\nBefore the guidelines are widely adopted, Seydoux says they should be tested in more human cell types and other organisms.\n\nExplore further: Gene editing in the brain gets a major upgrade\n\nMore information: Alexandre Paix et al, Precision genome editing using synthesis-dependent repair of Cas9-induced DNA breaks, Proceedings of the National Academy of Sciences (2017). DOI: 10.1073/pnas.1711979114 \n\n"},
{"url": "http://nautil.us/issue/54/the-unspoken/why-a-hedge-fund-started-a-video-game-competition", "link_title": "Why a Hedge Fund Started a Video Game Competition", "sentiment": 0.15726022421065522, "text": "There\u2019s a weird way in which a hedge fund is a confluence of everything. There\u2019s the money of course\u2014Two Sigma, located in lower Manhattan, manages over $50 billion, an amount that has grown 600 percent in 6 years and is roughly the size of the economy of Bulgaria. Then there are the people\u2014financiers, philosophers, engineers\u2014all applying themselves to unearthing inscrutable patterns that separate fortune from failure.\n\nAnd there is the science and engineering, much of it resting on a towering stack of data. In principle, almost any information about the real world can be relevant to a hedge fund. Employees, so the stories go, have camped out next to harbors noting down tanker waterlines, and in retail parking lots counting cars. This data then has to be standardized, synthesized, and made accessible to the people who place bets on the market.\n\nBuilding the tools to do this is part of Alfred Spector\u2019s job. As the chief technology officer of Two Sigma, he is responsible for the engineering platforms used by the firm\u2019s modelers. A former vice president at IBM and former professor of computer science at Carnegie Mellon, Spector has seen software transform one industry after another, and made more than a few contributions of his own along the way.\n\nHe sat down with us for a conversation at Two Sigma\u2019s headquarters earlier this month.\n\nWhy would a company like Two Sigma run a public game competition?\n\nWe started the Halite AI Programming Competition because we want to be known in the tech community for doing things that the tech community likes. Game competitions are one of those things. Programmers like interesting programing challenges\u2014particularly ones that are contained enough that they can do off-hours. Plus we open-source everything so that the programmers can actually see the game environment and learn everything about the game. That gives programmers a lot of opportunities for creativity as to how the game can be played, and it becomes more fun.\n\nWhat effect did you notice the competition having on the Two Sigma brand?\n\nWhat we noticed is that when we go to campuses, people have heard of us more. We also hired someone that was at the top of the ranking.\n\nWhat was the goal of the game?\n\nBoth this year and last year\u2019s games are turn-based strategy games. In Halite 1 last year there were between two and six bots on the board to start. In the game, each bot starts with a single piece, which it can move up, down, left, or right. It can also stay still, in which case the piece gains strength. If it moves, it leaves behind another piece where it was, so the number of pieces on your side grows. All the players are doing this on a grid that\u2019s maybe 40 or 50 squared pieces, so a bot can make a huge number of different moves. This year\u2019s game, Halite 2, is in many ways similar, but it uses a space war theme, where a ship can move to a planet and take over the planet. When you put all this together, people come up with incredibly interesting winning strategies.\n\nWhat\u2019s an example of an interesting strategy that came out of the games?\n\nThere was an interesting, unanticipated strategy that emerged in the final week of last year\u2019s game. It was a non-aggression strategy. Some players determined that if they hung loose for a while, and didn\u2019t try to defeat other players, and just tried to gain space and stay out of trouble, it could help them. Remaining aggressive players would actually sort of hurt themselves, while the players that were being non-aggressive would actually then be in a position that, with moderately high probability, could win.\n\nHow was machine learning relevant to game strategy?\n\nThis year, we really focused a lot on advancing the ability of our players to use machine learning. In fact, we provided a limited number of Google credits for players to use GPUs (graphic processing units) in the Google Cloud, which allow for very rapid machine-learning algorithm training to be done. We make replays of all the games that have been played available, so that machine-learning systems could look at them and try to learn how to play the game better. It is still to be determined how well machine learning can do in a game as complex as Halite.\n\nWhat\u2019s the difference between an algorithmic approach and a machine-learning approach?\n\nComputers always execute code, and code embodies an algorithm of some form. When we think of machine learning, those algorithms learn, and in effect modify themselves, from data. We think of classical algorithms as having everything specified in advance. Machine-learning algorithms have more degrees of freedom. They learn from the environment in which they\u2019re operating.\n\nHow does Two Sigma get its data?\n\n\n\nI kind of liken it to the electromagnetic spectrum of economic data shining in on us. We see certain frequencies and we don\u2019t see others. Certainly, we get tick data. We understand the prices and volumes of tradable entities in public markets. We get fundamental data. We get earnings data and things of that form from many sources. Sometimes we are able to get data on the interest that the sell side of Wall Street has in stocks. We have a product called PICS, which enables sell-side contributors to tell us that they\u2019re recommending something. Both we and they benefit from this.\n\nHow can machines interpret this great variety of data?\n\nOne way is that a human has a hypothesis. For example, we can hypothesize that something will have an effect on the valuation of some security. What we can do then is create a mathematical representation of that predictive model and then see whether that hypothesis has proven true. We do an enormous amount of testing at Two Sigma. That\u2019s hypothesis-driven work and, in one form or another, it has been the mainstay of investing for a very long time. Another approach is to send some form of a machine-learning algorithm at a lot of data and at some economic outcome, say a stock price or something like that, and see whether the machine can figure out the pattern. That\u2019s a more challenging thing to go do because, even if you get a result that\u2019s positive, you don\u2019t necessarily feel that you know why.\n\nHow can humans learn to interpret machine learning?\n\nI think one approach is to experiment and look at the outputs that you get as a function of the different kinds of inputs that you could give. Maybe a deep learning algorithm is going to predict the weather. You know it knows the barometric pressure, the temperature, the wind conditions, et cetera. Now let\u2019s say you iterate over many of those elements and you look at how the predictions would change. You may then be able to say: This algorithm seems to be very sensitive to rapid temperature change. You\u2019re beginning to get an idea of what the algorithm does, and you\u2019re beginning to get explanative power.\n\nWill there always be a human in the loop in this process?\n\nNot necessarily. You could imagine that there\u2019s some way of deciding on orthogonal planes of data that you then send to the system. You could take a lot of data elements and then feed them through the system and see what predictions occur in an automatic fashion, and try to learn from that. You could imagine another learning algorithm layered on the first learning algorithm.\n\nShould we be wary of the unintended consequences of machine learning?\n\nThere was a very nice paper published on the reinforcement of gender bias as an unintended consequence. Imagine you build a machine learning system that is designed to show ads to people who will click on those ads. If you\u2019re showing ads for CEO positions, with the state of the world as it is today, perhaps it is more likely that males will click on them. If that\u2019s true, a system that\u2019s doing machine learning may learn to advertise CEO ads in publications that are frequented by men, thereby inadvertently promulgating an undesirable bias. I note that the teams building that algorithm had no idea of this unintended consequence. I give a talk, called the Opportunities and Perils of Data Science, where I argue that we have a much greater need to educate engineers and data scientists in all manner of ethical issues now as data science becomes more pervasive.\n\nHow will those education needs be met?\n\nWe will need to train people in every discipline and probably every walk of life to have more technological understanding. We already see it happening. We see many more high schools with computer science and programming training. We see a lot more of it in college. In fact, computer science has become the largest major at some universities: Stanford, for example. You see at other great universities introductory computer science courses really growing in enrollment. All this I think is good.\n\nJournalists, in particular, will need to understand data and algorithms better.\n\nIn the world of computer science we had hoped that we would make vast amounts of data available, and that journalists and political scientists could use that data to reach scientifically valid conclusions. We hoped the world, would become, if you will, more truthful. What actually has happened seems to be the opposite. Journalists have so much data that by choosing which data to use, they can draw many different conclusions. Admittedly, as anyone who\u2019s taken a statistics class knows, it\u2019s pretty difficult to draw truly valid conclusions from data. A lot of the data\u2019s erroneous as well, which makes it even easier to jump to really bad conclusions. But all this provides an opportunity for journalists that are grounded in really good rigorous approaches to using data. But frankly it\u2019s also a great risk that many journalists and very many members of the public will not know how to interpret data properly. We seem to be having more problems with the latter at the moment.\n\nIs educating the reader the antidote?\n\nI think we need education of the reader but I also think we need education of the journalist. With the data science that we have today it\u2019s possible to get data on a great number of highly detailed events in the world, and that number will only grow. With so much detail available, how can we put those detailed events in perspective in the very large world around us? An individual item, like some engineering failure or accident may or may not be of significant societal impact, but it can only be judged in context. That\u2019s a very hard thing for a journalist to do. And it\u2019s even more difficult for members of the public. So, I think we\u2019re going to become more dependent upon journalists. And journalists are going need a lot of perspective.\n\nCan machine learning be used to help education?\n\n\n\nBack when I was a father of young children, there were already reading tutors that we used. This would have been 13 years ago. I loved them. My children loved them. I don\u2019t know why they\u2019re not a more common part of education in the United States, but even more important, in parts of the developing world where there is more illiteracy. If we extend these types of immersive tutors into more domains and add machine learning and AI techniques, these tutors can have broad impact and can adapt themselves to the learning styles of our children. There\u2019s every reason to think that they will be more like an individual tutor rather than a large, university lecture course. Interestingly, Halite is a pretty good example of an immersive, educational programming opportunity.\n\nWhat datasets would you like to see made available to the public?\n\nI think there\u2019s enormous opportunity in medicine with the right data. We need to build the right datasets of phenotypes, genetics, disease, and more. These comprehensive databases of epidemiological information may not directly generate the answers we need, but they will tee up a vast number of hypotheses that our medical researchers will find very interesting. You see this beginning to happen at 23andMe, though it is focused primarily on genetic data. Imagine we could do that across all of the medical institutions in the country, and we really, really go to work on all of this data.\n\nDo you have any sense of what\u2019s keeping medical data so fragmented?\n\nThe problem is, first, as a society we are really worried about the privacy of that data. Ensuring patient privacy is really complex and slows down the application of data to science. The second problem is the data itself is actually very complex. Data that\u2019s gathered at one institution may not be directly comparable with data gathered at another institution. Third, a lot of the data is wrong. There was an article a number of years back by a Science News reporter who reported that the evaluations of her own gut biome from two independent labs were vastly different. Finally, there is always concern about the ownership of data, and the prospect that it might somehow be financially valuable.\n\nWhat new approaches to machine learning are you excited about?\n\nPeople are trying to come up with mechanisms for probing causality, for asking \u201cWhy has the machine reached a particular conclusion?\u201d Another area is so-called \u201cadversarial\u201d networks. Machine learning can do quite well in many environments, but it can also be fooled. Black and yellow stripes were claimed by one algorithm to be a school bus. There has to be more research on how to actually deal with these adversarial approaches and systems, which could become an abuse challenge. A third area is reinforcement learning, where the computer plays against itself in order to learn. Often, this is very time consuming and slow, but researchers are looking at knowledge representation so that the algorithm could learn in one domain and then transfer some of the knowledge to another, which would make reinforcement learning faster. I believe ultimately in the \u201cCombination Hypothesis\u201d where we will augment machine learning with other approaches, such as inferencing, to build truly intelligent systems.\n\nHow did you get interested in science?\n\nI got interested in computer science because I was taking economics courses in college that required mathematics, and the mathematics class required some programming. I was really enamored of the programming in that class, and it just came very naturally to me. I was also enamored with some of the modeling that seemed to be plausible in the 1970s. A lot of people at that time were interested in natural resource limitations and concerns we\u2019d run out of oil, not be able feed the growing population, et cetera. So, a lot of almost Malthusian modeling began to be done, and I found that most interesting. I should add that another reason I got interested was because I had been a pizza chef prior to college, and I was paid two-and-a-quarter an hour. Programming was more lucrative."},
{"url": "https://github.com/maxamel/GDH", "link_title": "Show HN: GDH \u2013 Generalized Diffie-Hellman key exchange Java implementation", "sentiment": 0.02685928303905832, "text": "A Diffie-Hellman key exchange library for multiple parties built on top of the asynchronous, event-driven Vert.x framework.\n\nDiffie-Hellman has been the de-facto standard for key exchange for many years. Two parties who want to communicate on an insecure channel, can use it to generate symmetric keys, and encrypt the messages between them. Diffie-Hellman (or derivatives of it, e.g. Elliptic Curve Diffie-Hellman) is commonly used in many authentication protocols and confidential tunneling schemes such as SSL/TLS, SSHv2, SNMPv3, and many more. The most common and general scenario for the use of Diffie-Hellman is two parties that want to exchange messages over an insecure network. Common use-cases are client to web-server or peer-to-peer file-sharing communication. However, the case where multiple parties need to share a secret key is rarely addressed. Such cases may arise in complex distributed systems where participants are located on different machines, and need to communicate with each other directly, rather than through one central entity. Instead of generating a secret key for each pair of participants, it is possible to generate a single secret key shared by all participants, in a manner which is resistable to eavesdropping and Man-In-The-Middle attacks. This is where Generalized Diffie-Hellman comes in.\n\nThe following sequence diagram illustrates how the key exchange is performed. At first, two large numbers are distributed among the participants in plaintext. These numbers are the cyclic group generator (g) and a large prime(N). Then the participants come up with their secret numbers (a,b,c) which they do not reveal to anyone. They then begin a series transactions at the end of which, they can each calculate the same secret key, without it ever being transmitted on the wire. In old-style Diffie-Hellman we would have 3 different keys produced, one per each couple of participants. This scheme can be performed for any number of participants. The number of messages needed for N participants to complete a key exchange is N(N-1).\n\nThe basic usage of the library is spinning up verticles and initiating a key exchange between them. Once you have the key you can start encrypting/decrypting messages safely between the verticles. Note this library only provides a key exchange platform and utility methods for encryption/decryption. The network layer (e.g messaging protocol) must be implemented by the user.\n\nThe basic object used for deploying and undeploying verticles is the PrimaryVertex.\n\nThe verticle object participating in the key exchange is the GDHVertex. Let's define our first GDHVertex and call it activeVertex as it will be the one who initiates key exchanges. All other verticles will be passive. The following example will be run between two verticles on localhost, but can be run with multiple participants in a distributed environment.\n\nNow let's define another verticle to participate in the key exchange.\n\nOnce we have all participants defined, we can go ahead and form a group with the Configuration of one of the verticles. The id of the group is determined by its nodes, so if you construct 2 groups with the same nodes it will essentially be the same group.\n\nNow it's all set up and you can run the verticles and initiate a key exchange. The most important rule when developing with Vert.x (or any asynchronous platform) is DO NOT BLOCK THE EVENT LOOP! So remember not to perform blocking operations inside the asynchronous calls.\n\nYou can also use blocking code for key exchange:\n\nYou can even use blocking code for the deployments. The verticle which initiates key exchanges should still be deployed using an asynchronous call (Otherwise you have to busy wait on it with a while loop!). All other nodes will participate in the exchange once they are up and running.\n\nAt any point you can access the exchanged key as a CompletableFuture object from any verticle. This object is a representation of the key. The actual key might not be available at this moment in time, but will be made available as soon as the exchange finishes. Here are just a handful of options you have with the CompletableFuture:\n\nDon't forget to kill the verticles when you're finished with them. As in the deployment, you can use either asynchronous calls or blocking code:\n\nThis project is analyzed on Sonarcloud. Every build the code runs through a couple of static code analyzers (PMD and findbugs) to ensure code quality is maintained. Each push to the Github repository triggers a cloud build via TravisCI, which in turn pushes the code into another cloud code analyzer (Sonarcloud). If anything goes wrong during any of these steps the build fails.\n\nThe code is tested by both unit tests and integration tests. The integration testing involves actual spinning up of verticles, performing exchanges and checking the correctness and security of the transactions. Testing must cover at least 80% of the code, otherwise the quality gate of Sonarcloud fails.\n\nGDH logs messages at different points during the exchange. This allows easy debugging and also lets users follow the exchange and helps understand the protocol. Logs are also used in tests. For example, verifying the final key after the exchange is NOT transmitted over the wire, or counting the number of messages required to complete a key exchange. So if you change the logging messages, make sure this hasn't affected any tests.\n\nPublished under the MIT License. This basically means the software is free and anyone can use it however they wish. No liability or warranty."},
{"url": "https://www.bloomberg.com/news/articles/2017-12-01/n-y-times-scales-back-free-articles-to-get-readers-to-subscribe", "link_title": "N.Y. Times Scales Back Free Articles to Get More Subscribers", "sentiment": 0.14083174178762423, "text": "Users will access only five stories before being asked to pay\n\nPedestrians pass in front of the New York Times Co. building in New York.\n\nThe\u00a0 New York Times, seeking to amass more paid subscriptions in an era of non-stop, must-read headlines, is halving the number of articles available for free each month.\n\nStarting Friday, most non-subscribers will only be able to read five articles rather than 10 before they\u2019re asked to start paying. It\u2019s the first change to the paywall in five years. A basic Times subscription, with unlimited access to the website and all news apps, is $15 every four weeks.\n\nScoops on the Trump administration\u2019s scandals and sexual-harassment allegations in Hollywood have already contributed to a surge in Times subscriptions, which jumped 60 percent in September from a year earlier to 2.5 million. With demand for journalism \u201cat an all-time high,\u201d the Times decided this was the right moment to experiment with giving away less online content for free, said\u00a0Meredith Kopit Levien, New York Times Co.\u2019s executive vice president and chief operating officer.\n\n\u201cIt\u2019s a very hot news cycle,\u201d Levien said. \u201cWe think it\u2019s as good conditions as any to demonstrate to people that high-quality journalism is something to be paid for.\u201d\n\nAs Facebook and Google capture a growing share of the online advertising market, publishers from the New York Times to Conde Nast are trying to shift their digital businesses from selling ads to persuading readers to pay for their journalism.\n\nFueled in part by demand for news about President Donald Trump, the Times\u2019 subscription business has thrived in the past year. The Times added 154,000 digital-only subscriptions last quarter, a 14 percent increase in new customers from a year earlier, though many signed up through promotional deals and may leave when regular rates kick in.\n\nThe subscriber boost has led to a surge in Times Co. shares, which are up 41 percent this year. The stock slipped 1.7 percent to $18.48 as of 9:55 a.m. in New York trading.\n\nBut enticing casual readers to open their wallets raises a tricky question: Just how many free articles do you let them sample before requiring them to sign up?\n\nThe decision comes with trade-offs. By reducing the number of free articles, the Times will likely see a drop in traffic at the website, which could hurt ad revenue.\n\nLevien said that tightening the Times\u2019 paywall would have a \u201cmodest impact\u201d on its digital advertising business, which increased 11 percent last quarter from a year earlier. The increase failed to offset the continued decline in print ad sales, which fell 20 percent.\n\nThe potential decline in traffic is worth the risk, she said, if it leads to more people signing up. Most of the Times\u2019 pageviews come from paying digital subscribers, she said.\n\nOther publishers have experimented recently with tightening their paywalls. The Boston Globe in May reduced its number of free articles to two from five, leading to a surge of new subscribers. The Washington Post tested requiring readers to enter their email address and sign up for its daily newsletter to keep reading articles for free.\n\nThe Wall Street Journal started blocking Google users from reading free articles in February, boosting paying customers while causing a decline in web traffic from the search engine. Google has since announced it will end its policy that required subscription-based publishers to offer a few free articles a day through its search engine.\n\nSince last June, the Times has limited the number of free articles for readers who arrive via social media, which contributed to its subscriber gains. Previously, articles read via Facebook or Twitter didn\u2019t count toward the paywall.\n\nThe Times may eventually offer a different number of free articles to non-subscribers based on how they arrive or their reading habits.\n\nThe publisher has struck deals with other media companies to sweeten the offer of a digital subscription. Earlier this year, for instance, the Times began working with Spotify Ltd. to give new paying digital customers subscribers free access to the music-streaming service."},
{"url": "http://www.dslreports.com/shownews/Was-Your-Name-Stolen-to-Support-Killing-Net-Neutrality-140801", "link_title": "Was Your Name Stolen to Support Killing Net Neutrality?", "sentiment": 0.06635101010101009, "text": "Was Your Name Stolen to Support Killing Net Neutrality?\n\nNew York Attorney General Eric Schneiderman has launched a new tool for users interested in knowing whether their identity was stolen and used to fraudulently support the FCC's attack on popular net neutrality rules. The NY AG's office announced earlier this month that it was investigating identity theft and comment fraud during the FCC's public comment period. Researchers have noted repeatedly how \"someone\" used a bot to fill the comment proceeding with bogus support for the FCC plan, with many of the names being those of folks who'd never heard of net neutrality -- or were even dead.\n\nThe new AG tool streamlines the act of searching the FCC proceeding for comments filed falsely in your name, and lets you contribute your findings to the AG's ongoing investigation into identity theft.\n\n\"The FCC is refusing to help us -- or anyone else -- conduct a serious investigation, so we\u2019re asking New Yorkers to help us get to the bottom of what happened,\" the AG's office said of the new tool.\n\nSchneiderman's office had previously sent a letter to FCC boss Ajit Pai, complaining that the agency ignored more than half a dozen requests for assistance over the last six months in investigating the rampant fraud occurring on the agency website. The FCC could provide details on who utilized the agency's APIs to file such bogus support en masse, but has so far turned a cold shoulder to said fraud. I had my own identity lifted in this matter, and my complaints to the FCC were met with apathy.\n\n\"Such conduct likely violates state law\u200a -- yet the FCC has refused multiple requests for crucial evidence in its sole possession that is vital to permit that law enforcement investigation to proceed,\" noted Schneiderman. \"We reached out for assistance to multiple top FCC officials, including you, three successive acting FCC General Counsels, and the FCC\u2019s Inspector General. We offered to keep the requested records confidential, as we had done when my office and the FCC shared information and documents as part of past investigative work.\"\n\n\"Yet we have received no substantive response to our investigative requests,\" stated the AG. \"None.\"\n\nAs such, the AG is taking its fight to the public itself.\n\nWe've already reported how some of the fraudulent activity may be tied to groups that have historically worked on PR and political campaigns for the telecom sector. If this fraud can be tied directly to the telecom sector, and it can be proven that the FCC knew this and did nothing in a misguided attempt to downplay legitimate public opposition to its plan, the numerous lawsuits facing the FCC in the new year (possibly including one from Schneiderman's office) could get very interesting, very quickly."},
{"url": "http://www.helenos.org/wiki/ReleaseNotes/0.7.1", "link_title": "HelenOS 0.7.1", "sentiment": 0.0, "text": "This document contains a summary of changes made to HelenOS since release 0.7.0."},
{"url": "https://www.youtube.com/watch?v=QXjU9qTsYCc", "link_title": "How do computers read code?", "sentiment": -0.09270833333333332, "text": "When you first learned to write code, you probably realized that computers don't really have any common sense. You need to tell a computer exactly what you want. But do you know about all the work the computer does to understand what you mean?\n\n\n\nTwitter: https://twitter.com/frameofessence\n\nFacebook: https://www.facebook.com/frameofessence\n\nYouTube: https://www.youtube.com/user/frameofe...\n\n\n\n\n\nVideo links:\n\n\n\nCrash Course Computer Science:\n\nhttps://www.youtube.com/playlist?list...\n\n\n\nBuilding the Bits and Qubits\n\nhttps://youtu.be/F8U1d2Hqark\n\n\n\n\n\nTools used:\n\ngdb\n\ngcc\n\n\n\n\n\nImages and other visuals:\n\n\n\nThe IDE in the intro:\n\nEclipse\n\n\n\nPython scripting:\n\nIDLE\n\n\n\nSource code distribution example:\n\nApache httpd on GitHub\n\n\n\nExecutable distribution examples:\n\nAudacity\n\nVLC media player\n\nBlender\n\n\n\nPunch cards:\n\nhttps://en.wikipedia.org/wiki/File:Fo...\n\nhttps://commons.wikimedia.org/wiki/Fi...\n\n\n\nEarly computers:\n\nhttps://en.wikipedia.org/wiki/File:BR...\n\nhttps://en.wikipedia.org/wiki/File:IB...\n\n\n\nComplex history of computer languages:\n\nhttps://en.wikipedia.org/wiki/Generat...\n\n\n\nMontage:\n\nSublime Text\n\nIntelliJ IDEA\n\nhttps://www.haskell.org/\n\nIntelliJ IDEA again...\n\n\n\nPrint \"Hello, world!\" command:\n\nPython shell\n\n\n\n\n\nMusic:\n\n\n\nYouTube audio library:\n\nSunflower\n\n\n\nIncompetech:\n\nCall to Adventure\n\nIf I Had a Chicken\n\n\n\nPremium Beat:\n\nCutting Edge Technology\n\nSecond Time Around\n\n\n\n\n\nSwoosh 1 sound effect came from here:\n\nhttp://soundbible.com/682-Swoosh-1.html\n\n...and is under this license:\n\nhttps://creativecommons.org/licenses/..."},
{"url": "https://arstechnica.com/tech-policy/2017/11/charter-is-using-net-neutrality-repeal-to-fight-lawsuit-over-slow-speeds/", "link_title": "Charter is using net neutrality repeal to fight lawsuit over slow speeds", "sentiment": 0.0351524504302282, "text": "The impending repeal of net neutrality rules is being used by Charter Communications to fight a lawsuit that alleges the company made false promises of fast Internet service.\n\nNew York Attorney General Eric Schneiderman in February filed the lawsuit against Charter and its Time Warner Cable (TWC) subsidiary. Meanwhile, Federal Communications Commission Chairman Ajit Pai this month submitted a proposal to roll back the FCC's net neutrality rules and to preempt state governments from regulating net neutrality on their own. \u201cLipstick on a pig\u201d: Time Warner Cable \u201cdeceived the FCC\u201d in speed tests\n\nSchneiderman's lawsuit in New York State Supreme Court doesn't allege violations of the core net neutrality rules (i.e., blocking or throttling specific websites). Instead, the lawsuit says that TWC promised Internet speeds that it knew it could not deliver and that the slow speeds affected all kinds of websites and online services. The suit also alleges that TWC deceived the FCC in order to get a better score on the commission's evaluations of Internet speeds.\n\nBut Charter told the court on Monday that the impending preemption of states on net neutrality will help its case. Charter submitted Pai's net neutrality repeal proposal into the record and directed the judge to the order's attempt to preempt state regulations.\n\n\"Charter submits that the FCC's proposed holdings regarding federal preemption nevertheless are instructive\" and said it supports the company's motion to dismiss the case.\n\nCharter is wrong, the attorney general's office said in a response filed in court yesterday.\n\nIn addition to bans on blocking, throttling, and paid prioritization, the net neutrality rules require ISPs to be transparent about their network management practices. Charter's court filing says that the FCC's transparency rule \"preempts the Attorney General's allegations that Time Warner Cable made deceptive claims about its broadband speeds.\"\n\nBut the net neutrality repeal doesn't add new preemption powers related to transparency, Schneiderman argues. The FCC is maintaining some of the transparency requirements even after the planned repeal. The attorney general's brief says:\n\nThe AG's office made three additional arguments. The FCC draft order \"repeatedly and emphatically stresses the continued availability of traditional state remedies and consumer protections,\" the filing said.\n\nThe FCC is also proposing to end its use of broadband \"nutrition labels\" that inform customers about possible limitations in their service. These nutrition labels provide a \"safe harbor\" that protects against punishment by the FCC.\n\n\"This is the same safe harbor that Defendants claim is the basis for their conflict preemption,\" the AG's office wrote. But after the repeal, that safe harbor will be gone.\n\nFinally, the AG's office said that Charter's filing \"omitted\" language from the FCC's draft order that undercuts its argument. The FCC order notes that \"states retain their traditional role in policing and remedying violations of a wide variety of general state laws.\"\n\n\"In sum,\" the AG's office wrote, \"the Draft Rule does not preempt [the attorney general's] consumer fraud action, but rather makes clear that the states have a longstanding and traditional role in protecting their citizens against frauds, including those committed by Internet service providers.\"\n\nCharter had noted that the net neutrality repeal proposal says that \"regulation of broadband Internet access service should be governed principally by a uniform set\u00a0of federal regulations, rather than by a patchwork of separate state and local requirements.\"\n\nBut the FCC's attempted preemption of state regulations is no slam dunk and could be challenged. The FCC's previous attempt to preempt state laws regarding municipal broadband was overturned by a federal appeals court.\n\nGoing back to the lawsuit's allegations, the AG's office said that \"[Charter] subscribers' wired Internet speeds for the premium plan (100, 200, and 300Mbps) were up to 70 percent slower than promised; Wi-Fi speeds were even slower, with some subscribers getting speeds that were more than 80 percent slower than what they had paid for.\"\n\nDeficient cable modems and routers leased to customers accounted for some of the alleged problems. The lawsuit also points to business disputes between Charter and other network operators, which slowed down Internet speeds when the companies didn't upgrade infrastructure quickly enough.\n\nCharter argues that the alleged conduct occurred entirely before it purchased TWC in May 2016. But Schneiderman's lawsuit alleged that the company \"continues to underserve [its] subscribers by failing to make the capital investments necessary to live up to [its] promised speeds.\"\n\nDisclosure: The Advance/Newhouse Partnership, which owns 13 percent of Charter, is part of Advance Publications. Advance Publications owns Cond\u00e9 Nast, which owns Ars Technica."},
{"url": "https://coreos.com/blog/kubernetes-and-containers-in-2018", "link_title": "Kubernetes and containers in 2018: Buckle your seatbelts", "sentiment": 0.14243904243904243, "text": "Kubernetes and containers in 2018: Buckle your seatbelts\n\nAs 2018 approaches, the momentum behind containers and Kubernetes shows no signs of slowing. In less than three years since Google donated Kubernetes 1.0 to the Cloud Native Computing Foundation (CNCF), we've seen its development accelerate to where it has become one of the highest-velocity open source projects in history. Vendors and IT shops from all segments of the industry are embracing Kubernetes for their containerization efforts. (If you are still new to Kubernetes, read our Primer.)\n\nTo us at CoreOS, this comes as no surprise. We recognized early on that orchestration would be the catalyst to launch containerized infrastructure into the mainstream. It's a tribute to the entire Kubernetes community that large enterprises already have Kubernetes clusters in production, and the roster keeps growing.\n\nSo what do we see in the Kubernetes ecosystem's future as 2017 draws to a close? The CoreOS crystal ball reveals a few likely directions for the New Year.\n\nIn 2017, the alarm bells for the consequences of inadequate data security rang louder than ever. In October, former Equifax CEO Richard F. Smith testified before Congress that \"technological failures and human error,\" including inadequately patched software, were what exposed the credit reporting agency to a record-breaking data breach this year.\n\nThe lesson is that the infrastructure practices of yesterday are too fragile and cumbersome to power the internet of today, and information security is often the first casualty. The numbers tell the tale: It's estimated there are 3,424,000,000 internet users today but only 29,000,000 IT practitioners, and more people come online for the first time every year. Meanwhile, the rise of new models such as scale-out architecture and DevOps mean the number of servers, VMs, containers, and other assets that need management is exploding. IT practitioners are simply outnumbered.\n\nIncreased automation is the only solution to this imbalance. In the New Year, expect IT organizations to increasingly demand such capabilities as automatic, zero-downtime updates; increased monitoring throughout the infrastructure; and automated vulnerability scanning for containers and processes. Given the recent increase in cyber-security incidents, including attacks by state actors, we can no longer afford to have human error be the weakest link.\n\nEach year the big public cloud vendors roll out more and better services on their respective platforms, and each year customers flock to them. As the cloud providers' earnings demonstrate \u2013 research firm IHS Markit has estimated the combined IaaS, PaaS, and SaaS market at $72 billion \u2013 this model is big business for them. But how about for the companies that come to depend on them?\n\nIT spending is often a sore subject for customers who have found themselves roped into costly contracts with big vendors. Don't be surprised, however, if 2018 is the year that cloud billing \u2013 and how quickly it can balloon out of control \u2013 becomes a hot talking point across the industry. Once customers become reliant on a vendor's proprietary cloud services for their applications, it becomes nearly impossible for customers to take their business elsewhere. The vendors know this, and customers who bought in early are just now getting their billing wake-up calls.\n\nThat's why the current murmurings about hybrid and multi-cloud models will only get louder in the coming year. This industry has seen this type of lock-in many times before, but it needn't happen again. The open source software movement has shown us that open, community-driven technologies can be just as powerful as proprietary ones, without imposing restrictions designed solely to benefit a single vendor. Cloud computing isn't going away, but customers are demanding choice \u2013 which is why application portability across data centers and clouds will surely be one of 2018's hottest topics.\n\nUnfortunately, putting the brakes on cloud lock-in won't be easy while the major cloud providers are busy stomping on the accelerator. So-called serverless computing is the newest cloud-native technology that's gaining interest, even as it threatens to lock customers to cloud vendors' proprietary platforms and data centers tighter than ever.\n\nThis push began with AWS Lambda and Azure Functions, which made it possible for developers to write code without provisioning or managing the compute resources needed to execute it. Based on the early success of these offerings, expect cloud providers to deliver more products along similar lines in the coming year. For example, AWS recently announced Aurora Serverless, a management-free relational database service.\n\nThe serverless model is appealing because it purports to eliminate the headaches of IT operations. Not only is there no hardware to buy, but there are also no VMs, instances, networks, or application services to manage and maintain.\n\nThe downside is that serverless represents the most egregious form of cloud lock-in, where customers rely on a single vendor to provide everything from servers and the data center they're housed in, to services and even the APIs needed to access them. When everything is proprietary, application portability is effectively reduced to zero. It's like dialing back the clock to the mainframe era, if not worse.\n\nThere is hope, however. Serverless as a development model need not be tied to proprietary clouds. Open source options built on top of Kubernetes could provide similar functionality. For now, however, this category is still emerging, and few projects are likely to reach production-grade maturity in 2018. Faced with no open alternatives, many customers will find serverless cloud offerings too attractive to pass up in the New Year.\n\nContainerization rose to prominence in 2015 and 2016 as a more resource-efficient alternative to VMs and an enabler of new models like microservices. It wasn't long, however, before the industry recognized that an orchestration layer was necessary to successfully deploy containers in production at scale. That's where Kubernetes came in. Today Kubernetes is the leading container orchestration tool for organizations of all sizes, on its way to potentially becoming as ubiquitous as Linux.\n\nSo what's next? As early adopters begin moving business-critical workloads onto production clusters, expect to see demand for more services built on top of Kubernetes. Infrastructure services like data stores, monitoring, and secrets management are already in demand. And we expect the catalog of these \"Kubernetes apps\" to grow rapidly as users recognize the advantage of having logging, configuration, and security centralized through the Kubernetes APIs.\n\nFurther, more software vendors will begin to deliver their applications as containers instead of VMs, once they see how containerization opens their applications up to more cloud providers, reduces the burden of security updates, and makes high-availability versions even easier to build. This will also open up new opportunities to move software that was stuck on premises to the cloud and vice versa.\n\nFinally, the time that organizations spend architecting and building the infrastructure around an application's deployment, scaling, and decommissioning \u2013 also known as Application Lifecycle Management \u2013 will be reduced to zero. The \"analysis paralysis\" that can grip an organization as it struggles to figure out what tools developers should use for dev/test, for deploying into a datacenter, and for deploying into the cloud will be eliminated by the ubiquity of the Kubernetes APIs. The portability of the Kubernetes API to all of these environments will standardize the tools these organizations will use, increase developer productivity, and reduce friction to starting new initiatives.\n\nOne project that's complementary to Kubernetes that we're definitely keeping our eye on is Istio, and we think you'll be hearing a lot more about it in 2018. Much in the same way that Prometheus provided Kubernetes cluster maintainers with invaluable monitoring capabilities, Istio is an open source project that aims to address lingering pain points around microservices architecture.\n\nIt does this by creating a \"service mesh\" that runs on top of Kubernetes and acts as an intermediary network between the various microservices that make up an application. Istio enables traffic management between services, enforces service identity and access policies, and offers observability into service dependencies and how traffic flows between them.\n\nOriginally created through a collaboration between Google, IBM, and Lyft, Istio is expected to soon become a project under the umbrella of the CNCF. We'd welcome that move, and once Istio's development comes under the auspices of the same organization that oversees Kubernetes development, you should expect to see a number of vendors leveraging it to build even richer solutions for managing container-based microservices applications.\n\nOf course, no one can really predict the future, especially in an industry as fast-moving as ours. But if we can be 100 percent confident in one thing, it's that 2018 will be yet another banner year for containers, Kubernetes, and the new methodologies and practices that they enable. These technologies, and the ones that will be built on top of them, are born out of real and pressing needs faced by modern enterprises of all sizes. At CoreOS, we're proud to have helped pioneer this transformative evolution in IT, and we can't wait to unveil what we have planned for the year ahead and beyond."},
{"url": "https://www.listennotes.com/developers", "link_title": "Show HN: Listen Notes Podcast Search API", "sentiment": 0.0, "text": "Simple & no-nonsense podcast search API. Search 411,217 podcasts and 24,110,252 episodes by people, places, or topics. It's the same API that powers this website. Start using the API now:\n\nIt's freemium model & pay as you go. You can find pricing details here"},
{"url": "https://blog.viromedia.com/https-blog-viromedia-com-getting-started-with-ar-app-development-using-react-native-arkit-arcore-d605543ce670", "link_title": "Getting Started with AR App Development Using React Native", "sentiment": 0.12864219114219114, "text": "Apple recently announced there were over 1000 AR apps in the iOS app store. These AR apps were developed by a wide range of developers from big companies like the NBA, Amazon and Ikea, to indie game developers and independent hackers. Developers are flocking to this new computing paradigm to build the next great app.\n\nThis guide will help you rapidly build an AR app (or add AR features to your existing app) using React Native and ViroReact. ViroReact support both ARKit and ARCore, so you can write one code base that run across both mobile AR platforms.\n\nUse our Quick Start guides to get setup with ViroReact in minutes. The Viro platform is free with no limits on distribution. Sign up to get your API key and start developing AR apps today:\n\nYou will also need either an iOS ARKit enabled device or an Android ARCore enabled device.\n\nOnce you complete the ViroReact set up guide and get to \u201cHello World\u201d, use this tutorial to build a simple AR app that helps you understand basic AR -> How to build an interactive AR app in 5 mins\n\nUse the following tutorials and sample code to add various features to your AR app:\n\nHow to build AR Portals in 5 mins\u200a\u2014\u200aThis tutorial is a step by step guide for developing AR Portals. Our goal by the end of this tutorial is to:\n\nAdd Snapchat-like AR Lenses to any app\u200a\u2014\u200aThis tutorial is a step by step guide for adding AR features like animated characters and effects into any app. Our goal by the end of this tutorial is to:\n\nHow to use Particles to enhance any AR app\u200a\u2014\u200aThis tutorial is a step by step guide for using particles to enhance an AR application. Our goal by the end of this tutorial is to:\n\nAdd 2D Controls to your AR app with React Native\u200a\u2014\u200aSample code that shows how to create 2D UI for controls/buttons that are \u201con the glass\u201d rather than \u201cin the scene\u201d.\n\nBy this point, you should be comfortable with the basics of AR app development. You can start building your own AR app by expanding upon what you created so far. Refer to our ViroReact Documentation to learn more about AR app development and other features like Videos, Images, Sounds, Physics and more. If you need assistance, post issues to our Github page. Look forward to seeing the great AR apps you build with Viro."},
{"url": "https://www.notebookcheck.net/HP-Envy-x360-15-Ryzen-5-2500U-Radeon-Vega-8-Laptop-Review.266614.0.html", "link_title": "HP Envy X360 15 (Ryzen 5 2500U, Radeon Vega 8) Laptop Review", "sentiment": 0.06380538186093741, "text": "Since this is the first commercially available notebook equipped with Raven Ridge, our Verdict can be split into two parts. The first part relates to the AMD hardware itself. On paper, the 25 W cTDP Ryzen 5 2500U APU and RX Vega 8 GPU are able to stand neck-to-neck with current 15 W Kaby Lake-R options (i5-8250, i7-8550U) while outperforming even the Iris Pro Graphics 580 in synthetic benchmarks. Combine this with the generally lower price tag and there is seemingly no reason to choose Intel over AMD with all else being equal.\n\nUnfortunately for AMD, all else is not equal and Raven Ridge is simply not yet ready for prime time. Our test unit is extraordinarily slow and suffers from random crashes. In particular, the system would crash more frequently when stressing the GPU or running gaming loads similar to the previous generation of AMD Dual Graphics notebooks like on the Asus FX550IU. Synthetic benchmarks may reveal the Vega 8 to be faster than the aging GeForce 940MX, but the opposite is true when running most modern games. This is classic AMD for better or worse - excellent performance-per-Dollar that's ultimately dragged down by inferior drivers and developer support.\n\nPotential buyers who are drawn in by the impressive processor performance will find the lower price attractive over an Intel Kaby Lake-R equivalent. On the other hand, gamers will find nothing but disappointment in the RX Vega 8 until its drivers are up to speed. It may be over twice as powerful as the UHD Graphics 620 in synthetic tests, but the MX150 is still the better investment for reliable 1080p gaming on a budget.\n\nThe second part of our verdict is on the HP notebook as a whole. The manufacturer has successfully incorporated Spectre-class narrow bezels onto its mainstream Envy lineup that's sleeker and just as tough as the outgoing generation. Beyond the chassis redesign, however, not much else has improved. This was HP's chance to boost all aspects of the Envy x360 15 series but we instead have the same dim 1080p touchscreen, limited color space, and PWM characteristics as last year's model. The speakers, SD reader, keyboard, trackpad, hinges, overall weight, and pulsing fan noise aren't tangibly improved over the 2016 model, either. The biggest draw, then, is the slimmer looks and perhaps the slightly longer battery life and USB Type-C Gen. 1 port on this latest redesign.\n\n\n\nAMD's new Raven Ridge platform is a commendable achievement, but it's too bad that it suffers from the same poor software and driver issues that have been plaguing the chipmaker for years. We cannot recommend this HDD-based AMD HP system until the GPU glitches have been patched."},
{"url": "https://genode.org/documentation/release-notes/17.11", "link_title": "Genode OS Framework 17.11", "sentiment": 0.07567772140140568, "text": "In contrast to most releases, which are focused on one or two major themes, the development during the release cycle of version 17.11 was almost entirely driven by the practical use of Genode as a day-to-day OS by the entire staff of Genode Labs. The basis of this endeavor is an evolving general-purpose system scenario - dubbed \"sculpt\" - that is planned as an official feature for the next release 18.02. The name \"sculpt\" hints at the approach to start with a minimalistic generic live system that can be interactively shaped into a desktop scenario by the user without any reboot. This is made possible by combining Genode's unique dynamic reconfiguration concept with the recently introduced package management, our custom GUI stack, and the many ready-to-use device-driver components that we developed over the past years.\n\nBy stressing Genode in such a dynamic and interactive fashion, we identified and smoothened many rough edges and usability shortcomings, ranging from the use of client-provided pointer shapes, the proper handling of keyboard modifiers, mouse acceleration, over the configuration of the user-level networking facilities, to improvements of the file-system support. Since the sculpt scenario is based on Genode's custom package-management concept introduced in version 17.05, it motivated the packaging of all components required by this system scenario. Altogether, there are now over 150 ready-to-use depot archives available.\n\nAt the platform level, the release unifies the boot concept across all supported x86 microkernels and offers the option to boot 64-bit kernels via UEFI. For both UEFI and legacy boot, Genode consistently uses GRUB2 now.\n\nFeature-wise, the most prominent topics are the native support of game-console emulators based on libretro, the ability to resize libSDL-based applications like avplay, and the further cultivation of Nim as implementation language for native Genode components.\n\nThe VFS and C runtime received improvements in several respects. First, we reintegrated the resolver library back into the libc library as it is an essential feature for network applications. The former split was an ancient artifact we implemented when integrating the lxip network stack as an optional alternative to lwip. Speaking of ancient features, we also remove the rcmd code from libc. This feature for remote-shell access is not used in modern environments. The VFS server was adjusted to handle incomplete calls to correctly.\n\nGenode's user-level network-routing component was originally introduced in version 16.08 and refined in version 16.11. In the current release, the NIC router has received two minor improvements regarding MAC addresses and ARP handling. In addition, it now has the ability to act as DHCP server or client for each configured domain.\n\nLet's first have a look at the minor changes. The MAC addresses that the NIC router allocates on behalf of its NIC clients are now of the proper type: \"local\" and \"individual\" and this way, conform to the ARP protocol. The NIC router now also considers ARP requests for foreign IP addresses coming from a domain. If there is no gateway configured for the domain, the NIC router itself jumps in as gateway and answers those requests with its IP address. Thus, if you have an individual gateway in a subnet behind the NIC router, make sure to have the gateway attribute in the according tag set.\n\nThe new DHCP server functionality is activated for a domain by the new sub-tag of the tag:\n\nThe attributes and define the available IPv4 address range whereas the lifetime of an IPv4 address assignment is defined by the attribute in seconds. The attribute is optional and declares the IPv4 address the NIC router shall state in the DNS-server option of DHCP. The DNS server may be located within a foreign subnet.\n\nWhen used as a DHCP server, the NIC router provides the following DHCP options to its clients: message type, server IP (set to the NIC routers IP), subnet mask, IP lease time, router IP (set to the NIC routers IP), DNS server (if configured), and broadcast address.\n\nIf you want the NIC router to act as DHCP client at a domain, simply omit the interface attribute in the tag. In this case, the router tries to dynamically receive and maintain an IP configuration for the affected domain. Make sure that your DHCP server provides the following DHCP option fields to the NIC router: message type, server IP, subnet mask, IP lease time, and router IP.\n\nAlso note that the NIC router drops all packets not related to its DHCP client functionality at a domain that (currently) has no IP configuration. As soon as the domain achieves to get a valid IP configuration, the router switches to the normal behavior.\n\nIn traditional Genode system scenarios, the selection and configuration of the used device drivers are defined at system-integration time. This approach works fine whenever the hardware platform targeted by a given scenario and the use case of the scenario is well known in advance. But it does not scale up to general-purpose computing where one system image must be usable on diverse machines, and the concrete use cases are up to the end user.\n\nThe new driver-manager subsystem composes existing Genode components within a dynamic subsystem. It spawns and configures device drivers that are fundamental for an interactive system on demand. When integrated as a building block in a Genode system, it provides the following feature set:\n\nThe new subsystem comes in the form of a depot package, which depends on all required components. Internally, it employs a dynamic init instance as a tool to start and manage driver components on demand. The actual management component is a simple program of about 500 lines of code that merely consumes reports and produces configurations. It is so simple that it does not even perform any dynamic memory allocation.\n\nThe new subsystem is present in the gems repository and illustrated by the gems/run/driver_manager.run script. It is also used as one cornerstone of the forthcoming general-purpose \"sculpt\" scenario mentioned in the introduction.\n\nUp to now, the acpica application was started up-front in most scenarios to get exclusive access to all PCI devices during initialization. Afterwards the platform driver took over the device access and announced the platform service. With the upcoming \"sculpt\" scenario, the desire arose to start the acpica application at a later stage, when the platform driver is already running. We adjusted the acpica and platform driver configuration slightly to cover this use case also.\n\nThe ROM-filter component is able to transform XML data from multiple ROM modules into a new ROM module. It is prominently used to generate component configurations depending on global system state. The current release makes this tool more flexible by allowing verbatim copies of input content into the output XML node as well as the use of input content as attribute values.\n\nIn version 17.02, we introduced a modular input-processing component called input-filter. The current release adds the following features to this component:\n\nBoth the PS/2 and the USB drivers have gained the new attributes , , and (with their default values shown). The attributes can have the values \"no\" (LED is turned off), \"yes\" (LED is turned on), or \"rom\". In the latter case, the driver reads the LED state from a dedicated ROM module called \"capslock\", \"numlock\", or \"scrlock\" respectively. The ROM module is expected to have a top-level XML node with the attribute set to \"yes\" or \"no\". The drivers reflect this state information by driving the corresponding keyboard-mode indicator LEDs.\n\nDriven by use cases like the \"sculpt\" scenario mentioned in the introduction, the Nitpicker GUI server and its helper components received an overhaul.\n\nBesides modernizing the implementation according to our today's best practices, we succeeded in removing the focus handling as the last remaining builtin policy from the GUI server to an external component, thereby making the GUI server much more flexible. This line of work is complemented with an improved way of supporting client-provided pointer shapes, and a new general component for handling global keys.\n\nNitpicker's existing \"hover\" report features the information of the currently hovered client (e.g., the client's label and domain). In the new version, the report also features the information whether or not the user has actively moved the pointer during the last half second. This is analogous to how the \"focus\" report features user-activity information about recent key press/release activity. When combined, the \"hover\" and \"focus\" reports provide a way to detect the absence of user activity, e.g., to implement a lock screen or screen saver. If both reports have no attribute, such a component can schedule a timer. Whenever either of both reports shows an attribute, the timer is reset. The lock screen becomes active once the timeout triggers.\n\nFor debugging purposes or for implementing global key combinations, Nitpicker now offers \"keystate\" reports. The report is updated each time, the user presses or releases a key. It lists all currently pressed keys along with the key count as observed by Nitpicker.\n\nThe new report features the information about the client, on which the user actively clicked most recently. It is useful to implement a click-to-focus policy outside of Nitpicker.\n\nTraditionally, Nitpicker had a builtin policy about the input focus, which ensured that only the user can change the focus. The input focus is changed whenever the user clicks on an unfocused view. If permitted by the policy of the domain, the clicked-on client receives the focus. The policy configuration allows one to define domains that never receive any focus, domains that receive the focus only temporarily while the button is kept pressed (the so-called \"transient focus\"), or domains that can receive the regular input focus.\n\nHowever, there are situations where this builtin policy stands in the way. For example, in a scenario based on virtual consoles, the user wants to be able to switch virtual consoles via keyboard shortcuts and expects the input focus to match the currently visible console regardless of any mouse clicks. Another example is the change of the input focus via key combinations like alt-tab.\n\nAs an alternative to the builtin policy, the new version of Nitpicker is able to respond to an externally provided \"focus\" state in the form of a ROM session. This state is driven by a dedicated component, like the new nit_focus component that implements the traditional click-to-focus policy. By supplying the focus as a ROM session to Nitpicker, it becomes easy to globally overwrite the focus if needed. One particular example is a lock screen that should capture the focus when becoming active, and yield the focus to the original owner when becoming inactive.\n\nThe new explicit focus handling can be activated by setting the attribute to the value \"rom\". Further down the road, we plan to make this option the default, with the ultimate goal to remove the original builtin policy.\n\nThe new global_keys_handler component replaces the former xray-trigger component. It transforms a stream of Nitpicker input events to state reports. The states and the ways of how the user input affects these states is configurable. Examples for such states are the system-global capslock and numlock states, or the Nitpicker X-ray mode activated by a global secure-attention key. The configuration looks as follows:\n\nA node declares a boolean state variable with the given name and its initial value (default is \"no\"). There may be any number of such variables.\n\nThe and nodes define how key events affect the state variables. Each of those nodes refers to a specific state variable via the attribute, and the operation as the attribute. Possible attribute values are \"on\", \"off\", and \"toggle\".\n\nThe node defines a state-dependent report with the name as specified in the attribute. The report-generation rate can be artificially limited by the attribute. If specified, the report is not issued immediately on a state change but after the specified amount of milliseconds. The node contains a number of conditions. Whenever one of those conditions is true, a report of the following form is generated:\n\nOtherwise, the report's attribute has the value \"no\". Possible conditions are and . The condition is true if the named boolean state variable has the value true. The condition is true if the currently hovered Nitpicker client belongs to the domain as specified in the attribute. The latter information is obtained from a ROM module named \"hover\", which corresponds to Nitpicker's hover reports.\n\nTo use the global-keys-handler in practice, one needs to configure the Nitpicker GUI server such that the press/release events of the global keys of interest are routed to the global-keys-handler. This can be achieved by Nitpicker's configuration nodes. For example:\n\nThe nit_fb component translates the Nitpicker session interface into the low-level input and framebuffer session interfaces such that raw framebuffer clients can be hosted as Nitpicker applications. The position and size of such an application is configurable.\n\nThe new attribute denotes the coordinate origin of the values specified in the and attributes. Supported origins are \"top_left\", \"top_right\", \"bottom_left\", and \"bottom_right\". This attribute allows one to align a Nitpicker view at any of the four screen corners.\n\nThe and attribute values can now be negative. If so, they are relative to the physical screen size. E.g., when using a screen size of 64 , the effective width for a attribute value of \"-100\" would be 640 - 100 = 540.\n\nThe pointer component that accompanies Nitpicker by default shows a static pointer shape only. In advanced scenarios, for example when multiple instances of VirtualBox are present on one screen, it is desired to show the shape provided by the currently hovered guest OS. This was accomplished by a special vbox_pointer component with access to both the client-provided shape and Nitpicker's hover report. Whereas this component sufficed for relatively static scenarios, the pointer's policy configuration became rather difficult in dynamic scenarios where the labels of the displayed VMs or applications are unknown at system-integration time.\n\nThe new version simplifies the shape handling by letting the pointer component play the role of a \"Report\" service that consumes \"shape\" reports. This way, the pointer implicitly knowns the label of the shape-providing client. It matches the labels of its report clients against the currently hovered client as obtained from Nitpicker's hover report. If there is a match, the pointer displays the matching client-provided shape. Since the new component is generically applicable, e.g., not only for VirtualBox-provided shapes but also for Qt5-provided shapes (Section Displaying of Qt5's custom pointer shapes), it has become Nitpicker's default pointer component.\n\nIn this release, support for Microsoft's proprietary RNDIS protocol was enabled in our Linux-based USB network driver. Thereby it is possible to use the network sharing (\"tethering\") features provided by many Android devices. The driver was tested using devices from different vendors.\n\nSince the RNDIS driver is based on the driver (the open protocol alternative phone vendors should be using), it had to be enabled as well. Due to lack of any devices supporting CDC, while enabled, the driver could not be tested and must be considered experimental for now.\n\nThe porting and enabling of the driver was done by Alexander Senier from Componolit. Thanks for this welcome contribution!\n\nWe extended the file-system server with the ability to mount and unmount the underlying file system on demand. The server will mount the file system on the first established session request and in return will unmount the file system when the last session is closed. In case all clients are shut down before the server is stopped, this prevents leaving the file system marked as dirty. Even if the file system itself is in a clean state, the dirty bit might otherwise trigger a false negative result when performing a file-system check.\n\nIn release 14.02, we added a e2fsprogs Noux port. Since the use of the VFS library within libc, Noux is not strictly needed anymore for running tools like the e2fsprogs utilities. On the contrary, it increases the complexity of a file-system management mechanism needlessly. With this release, we introduce a port of the tool from e2fsprogs to Genode that does not depend on Noux. It can be used by a management component to check an ext2 file-system prior to starting and in case of errors to attempt to fix them automatically.\n\nAdditionally, we significantly stripped down Genode's version of the Rump kernel. By integrating Rump directly into Genode's build system, compiling and checking out required Rump sources only, we were able to reduce the compile time of and the source archive size (from about 700 MiB to about 10 MiB).\n\nSupport for the Nim programming language was introduced in the 17.05 release and during this release period, our understanding of Nim, its idiom, and its interaction with the Genode framework progressed to a point where native components can be reasonably implemented using the language.\n\nThe component in the world repository toggles XML sections in and out of a file managed by when triggered by key input events. The component is written in Nim, acts as a \"Nitpicker\", \"Input\", \"Report\", and \"ROM\" client, and follows the Genode paradigm of a state-machine driven by asynchronous signalling. The application specific source is also less than one hundred lines of code.\n\nTo enable client usage of Genode services the respective or C++ classes are wrapped as Nim objects by taking advantage of the Genode class to be able to manually invoke constructors during object initialization. Wrapping service classes and their methods is currently done by hand, but changes to service interfaces are so gradual that it is more effective than automated code generation. Signal handling is achieved using anonymous procedures and happens when the thread of execution winds back to the initial entrypoint. This approach is just the same as for components that are linked to the library, and contrasted with components linked to the library. The Nim language has no conventions for a special \"main\" procedure like C or Go, so signals handlers are dispatched by default after all top-level statements have been executed.\n\nThe language has experimentally proven to be flexible enough to implement RPC servers, but more experience is required to determine if a garbage-collected language can manage to abide by transient RAM resource quotas, as any multi-session server must do to reliably serve an indefinite number of clients. The standard language runtime also depends on the library, which is relatively expensive and complicated for typical native components. This dependency also prevents the implementation of VFS plugins in Nim, which must be available as the C runtime is initialized. Removing the dependency is certainly possible, but it remains an open question of whether it is practical to maintain such radical changes.\n\nTo experiment with the Nim language, a recent release or development version of the compiler is required. To this end, the Genode toolchain uses a custom compiler by default. A script is provided to build the recommended version at tool/tool_chain_nim.\n\nWe adapted the component to the asynchronous session-creation procedure introduced in Genode release 16.11. The current release makes it possible to debug components that implement Genode services.\n\nQt applications often make use of custom mouse-pointer shapes, for example when a text input field is hovered. We enabled this feature for our Qt5 port by letting Qt report its custom pointer shapes to the newly enhanced pointer component described in Section Simplified handling of client-provided pointer shapes. The use of the new feature is illustrated in the qt5_calculatorform.run script. Note the rewriting of the session label.\n\nGenode supports user input with keyboard and mouse attached via PS/2 and USB as well as USB touch panels. The current release brings an option for Qt5 applications to support textual-information input in situations where a hardware keyboard is missing. The Qt5 input stack was extended for platform input contexts and the accompanied example run/qt5_virtualkeyboard.run showcases the feature.\n\nThanks to Johannes Kliemann for his contribution!\n\nThere are quite a few ports of SDL-based software available on Genode that work well when executed in isolation, e.g., a game running in full screen directly in the frame buffer. However, when running in a common desktop scenario, the fixed size of the frame buffer used in Genode's SDL video back end is a noticeable limitation. So, in addition to removing the usage of deprecated APIs in the SDL back ends, we lifted this limitation as well.\n\nRemoving the usage of the deprecated APIs, which rely on a global environment, led to the addition of the Genode-specific initialization function that has to be called prior to . For that purpose, we introduce a stub library . In accordance to the posix library, it handles command-line argument parsing, proper SDL initializing, and the call to SDL's function. For interacting with the Genode API, we might have to execute signal handlers, e.g., whenever a framebuffer mode change signal is received. This is complicated from within a thread that is running libc code, which is true for most if not all SDL-based components. Therefor and because those components come with their own event loop, that polls SDL for events, we start the function in its own thread. The main entrypoint of the component does all the signal handling and the dispatcher flag signals in a way that SDL can transform them into SDL_Events and inject them into the event loop.\n\nThis changes enable the seamless resizing of a running avplay instance.\n\nA component that has been in the world repository for almost a year has been refactored and is ready for mention. The is a native front end to games implemented as \"Libretro cores\". Libretro is an API that exposes generic audio/video/input callbacks from a dynamic library to a front end. The front end handles video output, audio output, input, and the application's life cycle. This novel arrangement is intended to minimize the effort of porting games to different platforms and to increase future backwards compatibility. On Genode, these cores are executed frame-by-frame as compelled by the front end rather than by a main loop within the game. Game assets are loaded as configured in a general manner at the front end and multiple input devices can be managed and mapped into cores. This in effect moves the platform abstraction layer tighter around the game engine and relinquished more control and configuration to a native layer provided by the user. Documentation on using the front end can be found in the world repository along with examples for emulating a few game consoles.\n\nWith the previous release, we already added support for GRUB2 when booting in UEFI mode. However, for non-UEFI boots, we still relied on GRUB-0.97 and ISOLINUX from the Syslinux Project as boot loaders.\n\nWith the experiences gained from GRUB2, we decided to modernize our bootloader chain for x86. With this release, we solely use GRUB2 during all x86 boots.\n\nFor ISO creation, we now leverage the images - shipped by GRUB2 - and , together with the tool. Due to this change, we were able to remove the ISOLINUX binaries and eltorito files of ancient GRUB1.\n\nThe final GRUB2 binaries are now integrated as external Genode port, which can be installed by invoking:\n\nThe port contains the GRUB2 binaries. Additionally, the port contains the instructions and the references to the git source code of GRUB2 used to generate the bootloader binaries. With the information provided within the port, one can easily reproduce the GRUB2 builds if desired.\n\nWith this release, we enabled support to leverage non-executable memory on Genode. On hardware and kernels supporting this feature, it is now enabled by default.\n\nOn ARM this feature is available to all supported kernels, namely our own hw kernel, seL4, and Fiasco.OC.\n\nOn x86 the 64bit kernels hw, NOVA, and Fiasco.OC support this feature.\n\nSeL4 currently misses support on x86. The remaining x86 32bit kernels (i.e., OKL4, Pistachio and Fiasco) don't offer non-executable memory support, since they do not configure the page-tables in the PAE (physical address extension) format, which is required by non-executable memory.\n\nIn the previous releases, we extended our seL4 support and thereby collected a patch series for the seL4 kernel, e.g. UEFI boot support. We submitted the patches to the seL4 developers who integrated most of our changes into the seL4 7.0 kernel release.\n\nAdditionally to the update, we extended the UEFI framebuffer support for the seL4 kernel so that our simple boot framebuffer driver may now utilize the graphics device if setup by GRUB2 during UEFI boot. The patches to the kernel got submitted to the seL4 maintainers for review and for inclusion.\n\nDuring the previous releases, several preparation steps were made to enable the execution of Genode's core as privileged code inside the protection domain of each component. With this release, we pushed the genesis of the base-hw core component and its kernel library to finally achieve that goal. Now, the virtual address space of each component is split into a privileged and an unprivileged part. The privileged part is shared between all components and does not vary when switching between different protection domains. Nonetheless, it is accessible by the privileged threads of core and the kernel library's context only. The advantages of this approach are less context switch overhead and less complex assembler code with respect to the platform-specific exception and system call entry path.\n\nGenode's configuration is based on XML and gets validated by xmllint during each run tool invocation. Up to now, we used xmllint to check for a valid XML syntax.\n\nWith this release, we added an additional semantic check for Genode's component. The check determines whether the XML nodes and attributes are known and understood by . This check is performed on each run tool invocation at integration time. The XML schema file is located in\n\nand gets applied by xmllint."},
{"url": "https://insinuator.net/2017/12/lets-talk-about-rfc-6980/", "link_title": "Let\u2019s talk about RFC 6980", "sentiment": 0.1412698412698413, "text": "Following my work with the FreeBSD implementation of RFC 6980 I was happy to present my work at last week\u2019s DENOG 9 meeting.\n\n To make it available to anyone who did not meet me there and go into some more detail that would have exceeded the boundaries of the talk, I will cover the topic here.\n\nAfter the preceding work on Windows Server 2016 and the FreeBSD testing, as a Linux user, lover and administrator, I of course wanted to take a look at how different Linux systems complied with the RFC 6980 standard.\n\nAs many people I spoke with before my talk weren\u2019t familiar with the topic I\u2019m going to give a short introduction. So if you just grabbed a link to this from twitter and don\u2019t want to take a detailed look at the RFC right now, here\u2019s a short sketchy description of the topic. If you\u2019re already familiar with the previous posts, feel free to skip the next two paragraphs.\n\nAn important design component of IPv6 is the Neighbor Discovery (ND) protocol, which provides a framework for all local management tasks like Router Discovery, Prefix Delegation, Address Autoconfiguration, Duplicate Address Detection and so on. As this only takes place on the local link, all of these mechanisms are unencrypted by design \u2013 if not replaced by SEcure Neigbor Discovery (SEND). Thus, clients on the network have no means of verifying the sender or data of ND messages. While in IPv4, a router was mainly a forwarding device, in IPv6 \u2013 through the Router Advertisement (RA) \u2013 a router also provides the client with the necessary information to connect to the network, like IP and prefix information. The risk of an attack, because of which I did this research, lies in an unauthorized client on the network sending a rogue RA, feeding clients a different IP address and default route and thus interceping its traffic by replacing the original router. Another problematic part of IPv6 design are Extension Headers. For the purpose of simplifying the IPv6 header, the \u201cNext Header\u201d field was introduced, thus allowing any number of extension headers to be placed in nearly any order in the IPv6 packet.\n\nRFC 6980 states that these ND packets, as they\u2019re only traveling on the local link, need not be fragmented. Thus, it advises the client (RFC 2119 \u201cMUST\u201d) to silently ignore such messages, if fragmented. In our preceding work, my colleagues and I could show that this was not properly done if the RA came in fragments with some arrangements of Extension Headers placed in the fragmentable part of the message. A possible protection mechanism is the Router Advertisement Guard (RFC 6105) which can be enabled on a switch interface and forbidding RAs to be sent on that interface. However, as this mechanism can be evaded by some creative aligning of Extension Headers as well, we could successfully combine both flaws in the past. This way we managed to provide Windows and FreeBSD targets with freely chosen prefixes, have them set corresponding IP addresses and set routes to our attacker.\n\nAfter the spooking results on FreeBSD and Windows, offering multiple possibilities to evade the Router Advertisement Guard on the switch and inject malicious route and IP information to the client, I wanted to know if it looked quite as shocking in the Linux world.\n\nWas my Debian laptop, my daily companion that I treasure and update regularly (and thus myself), that susceptible to fraud?\n\n Spoiler alert: It\u2019s not, but it\u2019s time for my Arch using colleagues to stop mocking me.\n\nPlease note: As this kind of benchmarking and testing is forbidden in some EULAs, I only used free Linux distributions and did not test any enterprise versions.\n\nI mainly reused my lab setup that consisted of\n\nWhat I did to evaluate the behavior was basically the same as in the preceding work, so I\u2019ll just cover the basics here, for more details feel free to read the previous posts linked above.\n\nOnce with the attacker connected to a plain switch interface and once with it plugged into a port where RAguard was enabled, I executed the following steps for every test case:\n\nThe observations were, albeit not as shocking as with Windows and FreeBSD 11.0, not completely pleasing.\n\nIn summary, the results were:\n\nAs this affects nearly everyone who has IPv6, a local link and a router, the feedback I got after the talk was overwhelming. Thank you to all of you guys who approached me with questions, additional input or praise. This was my first talk at any conference ever and it has been a pleasure to be able to give it, so thanks to the DENOG organizers as well! The reactions I got really broadened the scope of where I thought this might apply and gave a lot of input to what still is there to be tested.\n\nMany people approached me with the question of whether this was already being discussed with developers or vendors. The question of where this problem or incorrect behavior as of RFC 6980 originates is still to be discussed. My next steps will be looking at the different kernel versions, parameters and whether or not systemd-networkd is involved in the processing.\n\nHowever, if you\u2019re reading this and you are a kernel, systemd or other network stack developer, feel free to approach me on this topic.\n\nThanks for everyone who helped this talk be possible and a success and have a nice weekend!"},
{"url": "https://www.reuters.com/article/us-usa-internet-pai/fccs-pai-addressing-net-neutrality-rules-calls-twitter-biased-idUSKBN1DS2LB", "link_title": "FCC's Pai, addressing net neutrality rules, calls Twitter biased", "sentiment": 0.08085839598997495, "text": "WASHINGTON (Reuters) - The chairman of the Federal Communications Commission, Ajit Pai, accused social media company Twitter Inc (TWTR.N) of being politically biased on Tuesday as he defended his plan to roll back rules intended to ensure a free and open internet.\n\nPai, a Republican named by President Donald Trump to head up the FCC, unveiled plans last week to scrap the 2015 landmark net neutrality rules, moving to give broadband service providers sweeping power over what content consumers can access.\n\n\u201cWhen it comes to an open internet, Twitter is part of the problem,\u201d Pai said. \u201cThe company has a viewpoint and uses that viewpoint to discriminate.\u201d\n\nHe pointed to Twitter\u2019s refusal to let Representative Marsha Blackburn, a Republican, advertise a campaign video with an anti-abortion message.\n\n\u201cTo say the least, the company appears to have a double standard when it comes to suspending or de-verifying conservative users\u2019 accounts as opposed to those of liberal users,\u201d Pai said.\n\nA spokesperson for Twitter said that at no time was Blackburn\u2019s video censored and that her followers would have been able to still see it.\n\n\u201cBecause advertisements are served to users who do not necessarily follow an account, we therefore have higher standards for their content,\u201d the Twitter spokesperson said.\n\nTwitter in October declined a campaign video advertisement by Blackburn, who announced she is running for the U.S. Senate, saying that a remark by Blackburn about opposing abortion was inflammatory. Twitter later reversed its decision.\n\nPai\u2019s criticism came a day after Twitter and a number of other internet-based companies - including AirBnb, Reddit, Shutterstock, Inc, Tumblr and Etsy (ETSY.O) - sent a letter urging the FCC to maintain the net neutrality rules.\n\nTrump is a prolific user of Twitter, often posting his unvarnished thoughts on the news of the day. He used Twitter throughout his presidential campaign to circumvent traditional media and talk directly to voters.\n\nPai has also been a frequent user of the website - acknowledging during the speech, \u201cI love Twitter\u201d - to push his case in favor of the rule changes. On Tuesday afternoon, he even posted a link to his remarks critical of Twitter on his own Twitter account.\n\nFollowing Pai\u2019s remarks on Tuesday, at an event organized by the libertarian-leaning R Street Institute, two other FCC commissioners said they would support his proposal when they vote on Dec. 14.\n\nThe proposed rollback of net neutrality has been seen as a victory for big internet service providers such as AT&T Inc (T.N), Comcast Corp (CMCSA.O) and Verizon Communications Inc (VZ.N), which favored a repeal. On the other side, websites such as Facebook (FB.O) and Alphabet Inc\u2019s (GOOGL.O) Google have favored the rules.\n\nThe rules prohibit broadband providers from giving or selling access to speedy internet, essentially a \u201cfast lane,\u201d to certain internet services over others.\n\n\u201cSo when you get past the wild accusations, fear mongering and hysteria, here\u2019s the boring bottom line,\u201d Pai said. \u201cThe plan to restore internet freedom would return us to the light touch, market-based approach under which the internet thrived.\u201d"},
{"url": "https://www.forbes.com/sites/paularmstrongtech/2017/12/01/use-this-science-to-get-40-more-clicks-on-your-facebook-and-google-ads/", "link_title": "Use This Science to Get 40% More Clicks on Your Facebook and Google Ads", "sentiment": 0.12387502848029165, "text": "Excuse the clickbait title but\u00a0researchers from Columbia, Stanford and Cambridge have published data showing that advertisements tailored to customers personalities\u00a0can achieve 50% conversion rates.\u00a0Using a combination of language and imagery that is chosen to match a customer's personality generates 40% more clicks and 50% higher conversion rates. The data also shows this even works\u00a0when only a minimal amount of distinguishing data - a single Facebook Like, for example - is available.\n\nBusiness use of Applied Psychology has come a long way since\u00a0the early days of the discipline and\u00a0the platforms that are common today were not even\u00a0conceived when the science was in its infancy. Commercial psychographic personalisation is exploding thanks to improvements in computing power and data collection. DataSine, a UK-based company, is showing\u00a0large conversion rates using different algorithms to improve the customer experience for clients including European retail banks.\n\nDataSine\u2019s\u00a0A.I. platform lets marketers automatically tailor their content to match individual customer personalities by\u00a0altering the language, keywords, images and colours.\u00a0The system even goes so far as to recommend who to email, who to call, and what time of day is best to contact each person - the holy grail for many marketers. By personalising e-mails, websites and social media posts, DataSine helped increase customer engagement at a Belgian bank by 80%.\n\nThe company has plans for the application of its technology according to James Gin, Chief Scientist at DataSine;\u00a0\"Psychographic personalisation is a new frontier not just in marketing efficiency and ROI, but as a framework for understanding what content and products users want. We believe that smarter targeting and messaging is a stepping stone towards developing truly customer-centric thinking, which will lead to goods and services that are personalised to individual needs.\u201d\n\nWhile the academic researchers worked with designers to manually tailor introverted and extraverted adverts, DataSine claims that their platform runs on\u00a0A.I. which learns personality preferences from hard data. Instead of relying on Facebook likes, DataSine personality profiles are predicted directly from customer behaviour. A future that brands will continue to\u00a0push for as Facebook and Google\u00a0require more and more ad money for the same returns.\n\nUsing psychographic data commercially is just one element to the next phase of marketing's evolution as new technologies like facial recognition and chatbots intertwine with datasets and deep learning techniques to produce further efficiencies and insights. Some businesses\u00a0are still failing to invest in technology and the science that is now\u00a0available and these are the businesses that are most at risk of critical business issues as competitors seek\u00a0to\u00a0gain market share from them."},
{"url": "http://marketrealist.com/2017/11/which-tech-stocks-have-outperformed-faang-stocks-in-2017/?utm_source=yahoo&utm_medium=feed&yptr=yahoo", "link_title": "Which Tech Stocks Have Outperformed FAANG Stocks in 2017?", "sentiment": 0.178475935828877, "text": "The FAANG stocks\u2014Facebook, Apple, Amazon, Netflix, and Google\u2019s parent, Alphabet\u2014have seen stellar returns this year. These stocks have helped propel the S&P 500 Index (SPY) 15.0% year-to-date (or YTD). However, the FAANG stocks are not the best-performing tech stocks this year.\n\nFacebook (FB) stock has risen 56.6% YTD as its robust revenue growth continues. Apple (AAPL) stock has returned 49.6% YTD, and Amazon (AMZN) stock has surged 53.0% in 2017. Netflix (NFLX) stock has soared 55.2%, and Alphabet (GOOG) stock has returned 32.7% in 2017.\n\nInterested in NVDA? Don't miss the next report. Receive e-mail alerts for new research on NVDA Success! You are now receiving e-mail alerts for new research. A temporary password for your new Market Realist account has been sent to your e-mail address. Success! has been added to your Ticker Alerts. Success! has been added to your Ticker Alerts. Subscriptions can be managed in your user profile.\n\nWhile these returns are commendable, these stocks have not been the best-performing stocks in 2017. Mobile payment company Square (SQ) has seen its stock soar 196.7% in 2017 despite the recent decline in its stock price. However, Square is a much smaller company than the FAANG stocks.\n\nChinese (FXI) companies Alibaba (BABA) and Tencent Holdings (TCEHY), which have an aggregate market cap of more than $1.0 trillion, have also outperformed the FAANG stocks. Alibaba stock has risen 112.5% YTD, while Tencent stock has more than doubled with returns of 116.7% in 2017. These Chinese companies have profited from a wave of spending on the back of increasing Chinese incomes."},
{"url": "https://medium.com/@omidh14/javascript-get-chained-1b7f0a647aff", "link_title": "JavaScript: Get Chained", "sentiment": 0.11374999999999999, "text": "You have done everything you could, Your functions just do the one thing that their name says and they don\u2019t make any changes to passed inputs. You have put a lot of effort into this project, Stayed up all night just reduce the number of lines of a function, Used all your willpower to resist the urge of not writing unit tests and deeply thought about the commit messages.\n\nYou have kept every part of your code consistently clean because you knew that even a little rush or laziness could make your project to end up as an unreadable project or decrease its maintainability.\n\nEverything is done. You just have to document your API endpoint so your users be able to communicate with each other.\n\nIt works! But not satisfying.\n\nMuch better! how hard can it be? Just return a function that returns a partial function\u2026 But wait! The order of chained methods is fluent but not practical, When the process reaches except the message has already been sent to everyone so the order must be changed into something like this:\n\nHmm\u2026 Not bad that much! Okay, But original send function is asynchronous so the connection will be closed just before sending the message. So:\n\nNow it doesn\u2019t worth all the trouble of creating chained methods."},
{"url": "https://www.citylab.com/equity/2017/11/can-seattle-handle-its-own-growth/546254/?utm_source=SFTwitter", "link_title": "How Seattle Is Dealing with Its Rapid Growth and Economic Success", "sentiment": 0.13659659927701165, "text": "A new survey finds Seattle residents are ambivalent about the dramatic economic expansion in their city.\n\nSEATTLE\u2014If it didn\u2019t rain here so much, the city might consider adopting a new motto: The future\u2019s so bright we have to wear shades. Seattle exemplifies the powerful current of economic vitality that is transforming many of the nation\u2019s largest cities as they connect more deeply to the digital economy and global markets. Over the past decade, Seattle has added 220,000 jobs, an increase of nearly 15 percent. Amazon, which employs 40,000 people here and holds about one-fifth of the city\u2019s premier office space, has keyed that growth, but the revival has spilled far beyond it. Thirty-one Fortune 500 companies now operate research and engineering hubs in Seattle, up from seven in 2010. More construction cranes are working here than in any other U.S. city, many in the South Lake Union area where Amazon has centered its burgeoning operations. Seattle is now adding about 60 people daily, many of them well-educated Millennials. That\u2019s the city\u2019s most rapid rate of population increase since the Klondike Gold Rush around 1900.\n\nSeattle is also confronting a homelessness crisis, grinding traffic congestion, and a housing-affordability squeeze that is displacing not only low-income families but also middle-income earners, such as teachers and police officers. Svenja Gudell, chief economist for Zillow, the housing website based here, reports that over the past year, house prices grew faster in Seattle than any other city, and rents increased faster than anywhere except Riverside, California. Like other new economy hubs such as Austin and Denver, Seattle is also struggling to connect its own kids from low-income and minority neighborhoods\u2014kids of color now represent a majority of its public-school students\u2014to the opportunities bursting around them. In the 20th century\u2019s last decades, many cities struggled against systemic decline. (In the 1970s, after a wave of layoffs at locally-headquartered Boeing, local residents put up a famous billboard that read: \u201cWill the last person leaving Seattle\u2014Turn out the lights.\u201d) Now, with that fear behind them, Seattle is testing whether cities can manage the challenges of success. \u201cI\u2019d much rather be in the position we are today where we have economic growth and [are] thriving economically than the opposite of that,\u201d Tim Burgess, the city\u2019s acting mayor, told me at a forum Tuesday night. \u201cWhat\u2019s important for city government is to make sure we are addressing \u2026 the built-in injustices when that economic growth happens, because we know that some [people] are left behind in that situation.\u201d\n\nFew cities have moved as aggressively as Seattle to confront the challenges of growth. An Atlantic Media/Allstate Regional Renewal poll of the Seattle region released this week showed that the area\u2019s residents are acutely aware of both sides of that equation. The survey, conducted as part of a nationwide Atlantic Media project that is exploring local innovation, found enormous optimism about the region\u2019s economic trajectory. Three-fourths of those surveyed said they believed it would be best for their career and family life to remain in the Seattle area, and about two-thirds said that young people would have more economic opportunity if they remained as well. About two-thirds likewise described the local job market as good or excellent. Two-thirds said the region was moving in a positive direction. But 70 percent of those surveyed said the city was unprepared to handle its growth. Another 70 percent agreed the region \u201cis growing in a way that is benefiting only a few and making it too difficult for average families to live here.\u201d Strikingly those views were almost as prevalent among those who had moved to Seattle as adults as they were among lifelong residents. Over half of those surveyed gave negative marks to the region\u2019s transportation mobility and two-thirds gave poor ratings to its housing affordability. (The survey, conducted from September 20 to 24 by FTI Consulting\u2019s Strategy Consulting and Research practice, has a margin of error of plus or minus 4.9 percent.)\n\nIn recent years, the city has increased its local minimum wage to $15 per hour; launched a pioneering program to expand access to public pre-school; required employers to provide hourly workers with more scheduling certainty; and developed a sweeping plan to mandate that developers construct more affordable housing. Jenny Durkan, who earlier this month was elected as the city\u2019s first woman mayor since 1926, has proposed to fund up to two years of community college tuition for the city\u2019s high school graduates. On Monday, the city approved a tax on short-term rentals (such as Airbnb) to fund expanded services for the homeless, and later this week, it will appear in court to defend a tax on high-income earners the city council unanimously approved in July. The jury remains out on many of these initiatives. A University of Washington study concluded that reduced hiring and hours worked for low-income workers has blunted the benefits of the higher minimum wage. Local critics consider the housing reforms too meager. The proposed levy on high earners may violate state restrictions on taxing incomes. But the impulse that binds these disparate ideas is the right one. As the biggest cities regain their place as the nation\u2019s locus of economic opportunity, they must find ways to channel their growth to benefit all of their residents, not just a well educated, tech-savvy few\u2014many of which are relocating from elsewhere. Seattle hasn\u2019t necessarily found all the right answers, but it is ahead of most places in asking the right questions. This post originally appeared on The Atlantic."},
{"url": "http://time.com/5044760/hiv-world-aids-day/", "link_title": "'I Spent Decades Planning to Die.' What It's Like to Survive HIV for 30 Years", "sentiment": 0.030708009646365823, "text": "In 1986, I moved from Atlanta to San Francisco because I had fallen in love with a man who lived here. The HIV test had come out a year earlier, and he knew he was negative, so I walked five blocks down the hill to the clinic and took The Test. Two weeks later, I was told it came back positive for HIV. I immediately made an appointment with a respected HIV doctor who told me I had less than two years to live. I was 26. It would be a few years before I figured out that I had acquired HIV in 1983.\n\nFrom 1981 until 1998, having HIV was considered a \u201cdeath sentence.\u201d I witness my loved one and a huge swath of my community die young\u2014all the while fully expecting to be the next one to die. At the end of the two years, I was still physically healthy, so he said I would be lucky if I lived another two years. It went on like that for a decade. Along the way, I watched my T-cells dwindle and had AIDS-related illnesses, all signs of certain death. I lived at death\u2019s door so long, it was all I knew.\n\nI certainly had no idea then that I\u2019d live long enough to be a long-term survivor, or live to be a 58-year-old man. I\u2019m aging with HIV, and I am not alone. I am in the majority. As of 2015, nearly 50% of all people living with HIV/AIDS in the United States were over 50 years of age. By 2020 that will rise to 70%. It is a paradigm shift in the demographics of HIV. It is also another frontier that no other generation has explored.\n\nWe watched HIV go from a \u201cdeath sentence\u201d and to a \u201cchronic manageable illness\u201d in the late 1990s. Patients were told after 1998 they could expect to \u201cto live a normal lifespan.\u201d That was a vastly different experience than for those of us living who were diagnosed before.\n\nMORE: People With HIV Are Living 10 Years Longer\n\nI spent decades planning to die, not intending to live. In 2005, it came to a head. I was having extreme anxiety and couldn\u2019t sleep. When I did sleep, I was haunted by horrific nightmares. My depression went from mild to severe. I became obsessed with suicide. Most of all, I was terrified by the idea of becoming an old man with HIV. I had no long-term goals, no retirement saved, no safety net.\n\nPhysically, I had developed pain and numbness in my feet and hands, known as neuropathy. I became sick with AIDS-related illnesses, and the treatments for those also exacted a price on my physical wellbeing. It all contributed to my dark, confusing mental state. My life had become unmanageable. I alienated what few long-time friends I had because I was so angry. By then, I had lost a lover and hundreds of friends to AIDS. Why had I survived when so many of my friends and community had died?\n\nI had to seek help. I saw several therapists who tried to treat the individual symptoms. They never said it was a part of something larger. They had never treated anyone with my experience of surviving a historically unique epidemic.\n\nDuring the darkest of those days, I saw a TV show about post-traumatic stress disorder (PTSD) and returning Iraqi War vets. A lightbulb went off. It dawned on me that my mental state was rooted in the trauma of surviving AIDS for decades. It was like PTSD but seemed much more complex, given the duration of the deaths of the AIDS epidemic combined with a crippling fear of aging without any sense of future orientation. I coined a term for what it felt like: AIDS Survivor Syndrome.\n\nWhen I began talking about it with other survivors, I heard that they too were dealing with something similar. In 2012, there were several long-term survivors who chose to end their lives rather than face the uncertainty of aging with a virus that had taken so much from them. I thought I understood why they did it. I realized there is a unique distinction to be made between HIV/AIDS long-term survivors and those who have been recently diagnosed with HIV. The two groups have distinctly different and overlapping psychosocial and clinical needs. Long-term survivors experience issues associated with accelerated aging, and many now die from cardiovascular, renal and liver disease; diabetes; hypertension; lipid abnormalities; non-AIDS related malignancies; frailty; bone loss; and dementia, that are not considered AIDS-related deaths.\n\nIn 2013, I founded Let\u2019s Kick ASS-AIDS Survivor Syndrome, a nonprofit to both raise awareness about AIDS Survivor Syndrome and seek out solutions to overcome it. A small group of other activists and I held a town hall in San Francisco on September 18, 2013. Over 200 people attended.\n\nWhile we had ample anecdotal evidence to support the existence of AIDS Survivors Syndrome and experts who agreed it is real, we did not have research data to back it up. That changed in November 2017, when Let\u2019s Kick ASS held a town hall entitled \u201cResearch on the AIDS Survivor Syndrome: New Data from the Multi-Center AIDS Cohort Study (MACS) and Voices of Survivors Themselves.\u201d\n\nThis World AIDS Day, we honor those we lost and those who survived the worst epidemic of the modern age. It a population that deserves recognition.\n\nTez Anderson is the founder of Let\u2019s Kick ASS-AIDS Survivor Syndrome. Based in San Francisco, there are chapters in Portland, Palm Springs and Austin."},
{"url": "https://www.youtube.com/watch?v=ywiwq9IpDEU", "link_title": "That time I used Ruby to crack my Reddit password \u2013 RubyConf 2017", "sentiment": 0.23409090909090907, "text": "RubyConf 2017: That time I used Ruby to crack my Reddit password by Haseeb Qureshi\n\n\n\nI lost my password. So I used Ruby it crack it, kinda. I will re-enact the story live in front of a group of strangers.\n\n\n\nI'm going to be honest, this is a weird and fairly embarrassing story. You probably shouldn't come see it.\n\n\n\nYou know what, forget I even said anything."},
{"url": "https://www.scientificamerican.com/article/global-powers-strike-deal-to-research-before-fishing-arctic-seas/", "link_title": "Global Powers Strike Deal to Research Before Fishing Arctic Seas\u200b", "sentiment": 0.029537037037037035, "text": "WASHINGTON (Reuters) - Delegations from the United States, Russia, and China and other countries struck a deal on Thursday to refrain from commercial fishing in the high Arctic seas, one of world's fastest-warming places, until scientists can determine what fish are there and whether they can be harvested sustainably.\n\nOnce signed by the governments of all the parties, the agreement will protect an area of the central Arctic Ocean roughly the size of the Mediterranean Sea, for at least 16 years.\n\nWhile commercial fishing has not yet occurred in the area, the world's hunger for fish protein is rising and both Arctic and non-Arctic nations are angling to develop natural resources in the region as global warming opens shipping lanes. Waters in the region were once frozen year round.\n\n\"This is one of the rare times when a group of governments actually solved a problem before it happened,\" David Balton, the U.S. ambassador for oceans and fisheries who has worked the State Department for 32 years, told Reuters.\n\nThe other parties to the legally binding agreement were Canada, Norway, Greenland, Iceland, Japan, South Korea and the European Union.\n\nUnder the agreement, Arctic countries and non-Arctic countries, such as China, will be part of a joint scientific research program determining what fish are in the region.\n\n\"In the future if fish stocks are plentiful enough to support a commercial fishery there, they will be part of the management system and presumably their vessels will have the opportunity to fish for those stocks,\" Balton said.\n\nThe agreement, which came after years of talks and a three-day meeting in Washington, D.C., built on a declaration in 2015 by the U.S., Canada, Norway, Greenland and Russia to voluntarily avoid fishing in the Arctic.\n\nScott Highleyman, an official at the Ocean Conservancy who also served on the U.S. delegation, said scientists have little knowledge of what kind of fish are in the region now and whether commercial stocks will migrate north as the water warms.\n\n\"This precautionary action recognizes both the pace of change in the Arctic due to climate change as well as the tradition of Arctic cooperation across international boundaries,\" he said.\n\nTrevorhi Taylor, a conservationist at the Canadian nonprofit group Oceans North, said the deal would protect Arctic fish and marine mammals, such as walrus and seals, on which many coastal communities in the North rely."},
{"url": "https://www.grants.gov/grantsws/rest/opportunity/att/download/268060", "link_title": "R &D for Next Generation Nuclear Physics Accelerator Facilities [pdf]", "sentiment": 0.0, "text": ""},
{"url": "https://www.youtube.com/watch?v=SmkVv8pcVhc", "link_title": "Large doses of aluminum found in autistic brains", "sentiment": 0.11489898989898989, "text": "We've been hard at work on the new YouTube, and it's better than ever. Try it now"},
{"url": "http://www.bbc.com/news/technology-41469232", "link_title": "Cyber-thieves seek to cash in on Bitcoin boom", "sentiment": 0.09011994949494952, "text": "Bitcoin's booming value has driven a huge rise in crypto-currency themed malware, say security firms.\n\nIn one month, anti-malware software company Malwarebytes said it stopped almost 250 million attempts to place coin-mining malware on to PCs.\n\nSymantec said it had seen a \"tenfold\" increase in the amount of malicious code connected with crypto-cash.\n\nCyber-thieves are using both dedicated software, hacked websites and emails to snare victims.\n\n\"There's been a huge spike,\" said Candid Wuest, a threat researcher at online security firm Symantec, adding that it had been caused by the rapid increase in Bitcoin's value.\n\nOn 29 November, the value of one Bitcoin surpassed $10,000 (\u00a37,943) - a massive increase on the $1,000 each one was worth at the start of 2017, although that figure has now fallen back sharply.\n\n\"With $10,000 being breached, and all the hype, a lot of people are trying to make money with crypto-coins,\" said Mr Wuest.\n\nMost of the activity seen by Symantec and other security firms involves crypto-coins other than Bitcoin. This was because it took a huge amount of computer power to produce or \"mine\" bitcoins.\n\nBy contrast, he said, mining other crypto-coins such as Monero could be done on desktops, laptops and even smartphones.\n\nMany of these alternative coins had risen in value alongside Bitcoin, said Mr Wuest.\n\nMining involves solving complicated mathematical problems and those who take part can be rewarded with coins. The more machines one person can get mining on their behalf - the more coins they are likely to amass, said Mr Wuest.\n\nMalwarebytes told the BBC that its security software was now, on average, stopping about eight million attempts a day by coin-mining code to compromise users' PCs.\n\nMuch of this coin-mining software was found on websites that had been hacked, to give attackers the ability to install their own code. One researcher found almost 2,500 sites hosting mining code.\n\nOther cyber-thieves have hijacked extensions and add-ons for web browsing programs to insert the malicious code. Once on a computer, the malware often runs processors at close to 100% to get as much mining work done as possible. On smartphones, this can mean batteries are depleted very quickly.\n\nMuch of the mining malware seen before now relied on using a victim's browser, said Malwarebytes' security researcher Jerome Segura. Attackers had now adapted malware to ensure it mines coins for as long as possible and did not stop when a browsing program was shut down.\n\n\"The trick is that although the visible browser windows are closed, there is a hidden one that remains opened,\" wrote Mr Segura in a blog detailing how the malware works.\n\nThe tiny window lurks beneath the taskbar on a Windows machine and would not be noticed by a victim, he said. Adverts that run on porn sites had been found harbouring this malware, he added.\n\nIt is not only websites that are being caught up in attempts to cash in on the crypto-cash boom, said Nicole Eagan, chief executive of security firm Darktrace.\n\nMs Eagan said it had found coin-mining programs of one sort or another on the internal networks of 25% of its customers. Many sought to use the significant computer processing power available inside corporate networks to generate coins.\n\n\"Sometimes it's an external intrusion into the network and sometimes its an employee that's looking to do it,\" she said. \"It's rampant at the moment,\""},
{"url": "https://www.quantamagazine.org/secret-link-uncovered-between-pure-math-and-physics-20171201/", "link_title": "Advances in number theory inspired by physics", "sentiment": 0.14870551879985844, "text": "\u201cTo get effective results on rational points, it definitely has the feeling that there\u2019d have to be a new idea,\u201d said Ellenberg.\n\nAt present, there are two main proposals for what that new idea could be. One comes from the Japanese mathematician Shinichi Mochizuki, who in 2012 posted hundreds of pages of elaborate, novel mathematics to his faculty webpage at Kyoto University. Five years later, that work remains largely inscrutable. The other new idea comes from Kim, who has tried to think about rational numbers in an expanded numerical setting where hidden patterns between them start to come into view.\n\nMathematicians often say that the more symmetric an object is, the easier it is to study. Given that, they\u2019d like to situate the study of Diophantine equations in a setting with more symmetry than the one where the problem naturally occurs. If they could do that, they could harness the newly relevant symmetries to track down the rational points they\u2019re looking for.\n\nTo see how symmetry helps a mathematician navigate a problem, picture a circle. Maybe your objective is to identify all the points on that circle. Symmetry is a great aid because it creates a map that lets you navigate from points you do know to points you have yet to discover.\n\nImagine you\u2019ve found all the rational points on the southern half of the circle. Because the circle has reflectional symmetry, you can flip those points over the equator (changing the signs of all the y coordinates), and suddenly you\u2019ve got all the points in the northern half too. In fact, a circle has such rich symmetry that knowing the location of even one single point, combined with knowledge of the circle\u2019s symmetries, is all you need to find all the points on the circle: Just apply the circle\u2019s infinite rotational symmetries to the original point.\n\nYet if the geometric object you\u2019re working with is highly irregular, like a random wandering path, you\u2019re going to have to work hard to identify each point individually \u2014 there are no symmetry relationships that allow you to map known points to unknown points.\n\nSets of numbers can have symmetry, too, and the more symmetry a set has, the easier it is to understand \u2014 you can apply symmetry relationships to discover unknown values. Numbers that have particular kinds of symmetry relationships form a \u201cgroup,\u201d and mathematicians can use the properties of a group to understand all the numbers it contains.\n\nThe set of rational solutions to an equation doesn\u2019t have any symmetry and doesn\u2019t form a group, which leaves mathematicians with the impossible task of trying to discover the solutions one at a time.\n\nBeginning in the 1940s, mathematicians began to explore ways of situating Diophantine equations in settings with more symmetry. The mathematician Claude Chabauty discovered that inside a larger geometric space he constructed (using an expanded universe of numbers called the p-adic numbers), the rational numbers form their own symmetric subspace. He then took this subspace and combined it with the graph of a Diophantine equation. The points where the two intersect reveal rational solutions to the equation.\n\nIn the 1980s the mathematician Robert Coleman refined Chabauty\u2019s work. For a couple of decades after that, the Coleman-Chabauty approach was the best tool mathematicians had for finding rational solutions to Diophantine equations. It only works, though, when the graph of the equation is in a particular proportion to the size of the larger space. When the proportion is off, it becomes hard to spot the exact points where the curve of the equation intersects the rational numbers.\n\n\u201cIf you have a curve inside an ambient space and there are too many rational points, then the rational points kind of cluster and you have trouble distinguishing which ones are on the curve,\u201d said Kiran Kedlaya, a mathematician at the University of California, San Diego.\n\nAnd that\u2019s where Kim came in. To extend Chabauty\u2019s work, he wanted to find an even larger space in which to think about Diophantine equations \u2014 a space where the rational points are more spread out, allowing him to study intersection points for many more kinds of Diophantine equations."},
{"url": "http://transition.fcc.gov/Daily_Releases/Daily_Business/2017/db1128/DOC-347980A1.pdf", "link_title": "Remarks of Chairman Ajit Pai on Restoring Internet Freedom [pdf]", "sentiment": 0.0, "text": ""},
{"url": "https://blog.google/topics/machine-learning/introducing-aiy-vision-kit-make-devices-see/", "link_title": "Google launches AIY Vision Kit: Make devices that see", "sentiment": 0.16469907407407405, "text": "The provided software includes three TensorFlow-based neural network models for different vision applications. One based on MobileNets can recognize a thousand common objects, a second can recognize faces and their expressions and the third is a person, cat and dog detector. We've also included a tool to compile models for Vision Kit, so you can train and retrain models with TensorFlow on your workstation or any cloud service.\n\nWe also provide a Python API that gives you the ability to change the RGB button colors, adjust the piezo element sounds and access the four GPIO pins.\n\nWith all of these features, you can explore many creative builds that use computer vision. For example, you can:\n\nIdentify all kinds of plant and animal species See when your dog is at the back door See when your car left the driveway See that your guests are delighted by your holiday decorations See when your little brother comes into your room (sound the alarm!)\n\nAIY Vision Kit will be available in stores in early December. Pre-order your kit today through Micro Center.\n\n** Please note that full assembly requires Raspberry Pi Zero W, Raspberry Pi Camera and a micro SD card, which must be purchased separately.\n\nPlease let us know how we can improve on future kits and show us what you\u2019re building by using the #AIYProjects hashtag on social media.\n\nWe\u2019re excited to see what you build!"},
{"url": "https://www.seroundtable.com/matt-cutts-disappointed-google-redirects-24854.html", "link_title": "Matt Cutts Dislikes How Google Links to Search Results", "sentiment": 0.07476851851851851, "text": "Matt Cutts, former Google executive and star amongst the SEO community, posted on Google+ how he is not happy with how Google is linking to the \"10 blue links,\" the core Google search results.\n\nMatt showed how Google is not directly linking from the core search results to the site. Instead, they are adding a bunch of parameters to the URLs for tracking purposes. Matt wrote \"I wish the \"10 blue links\" in Google's search results were direct links instead of links like https://www.google.com/url?sa=t&rct= j&q=&esrc=s&source=web&cd=4&cad=rja&uact= 8&ved=0ahUKEwjJpuvXgejXAhURSt8KHRUJDl8QFgg7MAM &url=http%3A%2F%2Fwww.speedtest.net% 2F&usg=AOvVaw0szRo_9l-4_h8tA3oKB8NJ.\" (note I broke up the URL a bit so it wraps in this blog post)\n\nInstead, Matt wants the link to go direct to www.speedtest.net and not pass through all these parameters and redirects. I suspect this is a concern to Matt for a [
{"url": "https://github.com/yangmillstheory/vim-snipe", "link_title": "Show HN: Vim-snipe \u2013 Fast linewise motions and edits", "sentiment": -0.011791383219954639, "text": "There aren't any plugins with the same feature set. The two plugins with the most overlap in functionality are\n\n1 is no longer active, and is a simple fork of 2. While it agrees with this effort in spirit (constraining motions to ), it only provides mappings for , , and . It also hasn't seen any activity in a while.\n\n2 also has a similarly incomplete API at the time of this writing; see this issue. It's also monolithic, sprawling, and (IMHO) painful to extend; see this Reddit thread for more discussion.\n\nHowever, I'd like to give credit to , having borrowed some core functionality and logic:\n\nIf you use a plugin manager this is as simple as\n\nThe above example uses vim-plug; tweak accordingly for your plugin manager.\n\nNote that all motions below (except cutting, swapping, and replacing) work in character, visual and operator-pending modes.\n\nNo, and it does too much.\n\nAfter looking at the code, it's indeed monolithic, large, sprawling, and (in my opinion) painful and unpleasant to extend. However, one of the core algorithms is similar.\n\nPull requests are welcome; no special process is required. Currently there's no optionality for the highlighting format, for example.\n\nI'm sure there's also plenty of bugs which I won't have the time or inclination to always fix (try using the plugin when browsing Vim documentation, e.g.)."},
{"url": "https://www.thetimes.co.uk/magazine/style/polyamory-in-silicon-valley-gk79dm6qs", "link_title": "Polyamory in Silicon Valley", "sentiment": -0.17, "text": "Orgy Ben and Orgy Kate, as they\u2019ve called themselves on their name badges, have taken me under their wing at a sex party in downtown San Francisco. It\u2019s immediately clear that my pleather Zara trousers aren\u2019t going to cut it \u2014 the event\u2019s website wasn\u2019t lying when it promised \u201cleatherfolk, kinksters and perverts\u201d. In one room, half-naked women writhe, suspended from scaffolding, while bumbling boy scouts below wrestle with knots. In another, podgy men are trussed up, tortured and teased by expressionless females. Elsewhere, one poor lady, bound to a pole with industrial quantities of clingfilm, is being whipped. The salubrious venue of this welcome-one-and-all event? A Holiday Inn. A pale, purple-haired man introduces himself as a polyamory expert called Pepper Mint. I flee the building.\u2026"},
{"url": "https://breakthroughprize.org/News/41", "link_title": "2018 Breakthrough Prizes in Physics, Life Sciences, and Mathematics", "sentiment": 0.17792613636363644, "text": "2018 Breakthrough Prizes in Life Sciences Awarded to Joanne Chory, Don W. Cleveland, Kazutoshi Mori, Kim Nasmyth, and Peter Walter.\n\n2018 Breakthrough Prize in Fundamental Physics Awarded to Charles L. Bennett, Gary Hinshaw, Norman Jarosik, Lyman Page Jr., David N. Spergel, and the WMAP Science Team.\n\n2018 Breakthrough Prize in Mathematics Awarded to Christopher Hacon and James McKernan.\n\nNew Horizons in Physics Prizes Awarded to Christopher Hirata, Douglas Stanford, and Andrea Young.\n\nNew Horizons in Mathematics Prizes Awarded to Aaron Naber, Maryna Viazovska, Zhiwei Yun, and Wei Zhang.\n\nLaureates to be honored at glittering awards gala hosted by Morgan Freeman, with live performance by Wiz Khalifa and musician Nana Ou-Yang, and presentations from Mayim Bialik, Lily Collins, Mila Kunis, Ashton Kutcher, Katie Ledecky, Kerry Washington, John Urschel, Miss USA K\u00e1ra McCullough and the founders of the Breakthrough Prize.\n\nDecember 3, 2017 \u2013 (San Francisco) \u2013 The Breakthrough Prize and sponsors Sergey Brin, Yuri and Julia Milner, Mark Zuckerberg and Priscilla Chan, Anne Wojcicki, and Pony Ma, will tonight announce the recipients of the 2018 Breakthrough Prizes, which recognize top achievements in Life Sciences, Fundamental Physics and Mathematics. A combined total of $22 million will be awarded at the gala ceremony in Silicon Valley, to be hosted by Morgan Freeman, which will air live tonight on National Geographic at 10p ET/7p PT. Each Breakthrough Prize award is $3 million, the largest individual monetary prize in science.\n\nThis year, a total of seven $3 million prizes will be awarded. In addition, three $100,000 New Horizons in Physics Prizes will be awarded to three early-career physicists, and three New Horizons in Mathematics Prizes totaling $300,000 will be awarded to four early-career mathematicians. The Breakthrough Junior Challenge will recognize one student with a $250,000 scholarship and provide an additional $150,000 in educational prizes for the winner\u2019s science teacher and school.\n\nSince its inception in 2012, the Breakthrough Prize has awarded close to $200 million to honor paradigm-shifting research in the fields of fundamental physics, life sciences, and mathematics.\n\n\u201cThe Breakthrough Prize was created to celebrate the achievements of scientists, physicists, and mathematicians, whose genius help us understand our world, and whose advances shape our future,\u201d said Breakthrough Prize co-founder, Mark Zuckerberg. \u201cThe world needs their inspiration, and their reminder that even though it doesn\u2019t always feel that way, we are making steady progress toward building a better future for everyone. Priscilla and I want to congratulate all of tonight\u2019s laureates and give our deepest thanks for all that they do.\u201d\n\nThe 2018 Breakthrough Prize in Life Sciences will be awarded to Joanne Chory (Salk Institute for Biological Studies and Howard Hughes Medical Institute), Don W. Cleveland (Ludwig Institute for Cancer Research at University of California, San Diego), Kazutoshi Mori (Kyoto University), Kim Nasmyth (University of Oxford) and Peter Walter (University of California, San Francisco).\n\nThe 2018 Breakthrough Prize in Fundamental Physics will be awarded to Charles L. Bennett (Johns Hopkins University), Gary Hinshaw (University of British Columbia), Norman Jarosik (Princeton University), Lyman Page Jr. (Princeton University), and David N. Spergel (Princeton University).\n\nThe 2018 Breakthrough Prize in Mathematics will be awarded to Christopher Hacon (University of Utah) and James McKernan (University of California, San Diego).\n\nLaureates will take to the stage tonight at an exclusive gala co-hosted by founders Sergey Brin, Yuri and Julia Milner, Mark Zuckerberg and Priscilla Chan, Anne Wojcicki, Pony Ma, and Vanity Fair editor Graydon Carter. Academy Award\u00ae-winning actor Morgan Freeman will host the show, which will feature a performance by multi-platinum selling hip hop artist and entrepreneur Wiz Khalifa with musician Nana Ou-Yang, presentations from actress Mila Kunis, actor and investor Ashton Kutcher, critically acclaimed actress and producer Kerry Washington, actress and neuroscientist Mayim Bialik, actress Lily Collins, U.S. Olympic swimmer Katie Ledecky, former NFL player turned mathematician John Urschel and Miss USA K\u00e1ra McCullough, as well as the founders of the Breakthrough Prize. The theme of the evening will be \u201cSparks of Creation.\u201d The ceremony will be directed and produced, for the fifth time, by Don Mischer alongside executive producers Charlie Haykel and Juliane Hare of Don Mischer Productions.\n\n\u201cIt is always the right time to celebrate great scientists,\u201d said Internet investor and science philanthropist Yuri Milner. \u201cAll of our futures depend on them.\u201d\n\nIn addition, six New Horizons Prizes \u2013 an annual prize of $100,000, recognizing the achievements of early-career physicists and mathematicians \u2013 will be awarded.\n\nThe New Horizons in Physics Prize is awarded to: Christopher Hirata (Ohio State University), Andrea Young (University of California, Santa Barbara), and Douglas Stanford (Institute for Advanced Study and Stanford University).\n\nThe New Horizons in Mathematics Prize is awarded to: Aaron Naber (Northwestern University), Maryna Viazovska (\u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne), Zhiwei Yun (Yale University), and Wei Zhang (Massachusetts Institute of Technology and Columbia University).\n\n\u201cEvery year I am inspired by the Breakthrough Prize laureates and the deep insights that are made possible by pure curiosity-driven research. This year is no exception,\" said Breakthrough Prize co-founder, Anne Wojcicki.\n\nThe Breakthrough Junior Challenge is a global science video competition designed to inspire creative thinking about fundamental concepts in the life sciences, physics, and mathematics. In recognition of her winning submission, Hillary Diane Andales receives up to $400,000 in educational prizes, including a scholarship worth up to $250,000, another $50,000 for the science teacher who inspired her, and a state-of-the-art science lab valued at $100,000 designed by and in partnership with Cold Spring Harbor Laboratory.\n\nThis was Andales\u2019 second time in the competition, and last year, she was the Top Scorer in the Popular Vote, a segment of the contest that allows the public to vote for their favorites online. As the Top Scorer in the Popular Vote, she won a DNA molecular-biology laboratory as her school recovered from damage by Typhoon Haiyan in 2013. This year, her overall victory in the competition will secure for her school a Fabrication/Physics/Design/Innovation Lab.\n\nMore than 11,000 entries from 178 countries were received in the 2017 installment of the global competition, which kicked off on September 1, 2017. The Breakthrough Junior Challenge is funded by Mark Zuckerberg and Priscilla Chan, and Yuri and Julia Milner, through the Breakthrough Prize Foundation, based on a grant from Mark Zuckerberg\u2019s fund at the Silicon Valley Community Foundation and a grant from the Milner Global Foundation.\n\nThe Breakthrough Prize in Life Sciences honors transformative advances toward understanding living systems and extending human life, with one prize dedicated to work that contributes to the understanding of neurological diseases.\n\nEach of the five Life Science winners will receive a $3 million prize.\n\nThe Breakthrough Prize in Fundamental Physics recognizes major insights into the deepest questions of the universe.\n\nThe $3 million physics prize will be shared among the entire 27-member WMAP experimental team, including the following five team leaders:\n\nFor detailed maps of the early universe that greatly improved our knowledge of the evolution of the cosmos and the fluctuations that seeded the formation of galaxies.\n\nThe Breakthrough Prize in Mathematics honors the world\u2019s best mathematicians who have contributed to major advances in the field.\n\nThe joint winners of the $3 million prize, are:\n\nFor transformational contributions to birational algebraic geometry, especially to the minimal model program in all dimensions.\n\nThe New Horizons in Physics Prize is awarded to promising early-career researchers who have already produced important work in fundamental physics.\n\nThe New Horizons in Mathematics Prize is awarded to promising early-career researchers who have already produced important work in mathematics.\n\nThe third annual Breakthrough Junior Challenge will recognize Hillary Diane Andales (18) of the Philippines. She will receive $250,000 in educational prizes; her science teacher will receive $50,000; and her school will receive a new science laboratory valued at $100,000 designed by and in partnership with Cold Spring Harbor Laboratory.\n\nHillary\u2019s video, submitted in the physics category, focused on reference frames in general relativity.\n\nImages and select video from the 2018 Breakthrough Prize Gala \u2013 red carpet and ceremony \u2013 can be downloaded for media use at: http://www.epklink.com/2018breakthroughprize\n\nFor the sixth year, the Breakthrough Prizes will recognize the contributions of the world\u2019s top scientists. Each prize is $3 million and awarded in the fields of Life Sciences (up to five per year), Fundamental Physics (up to one per year) and Mathematics (up to one per year). In addition, up to three New Horizons in Physics and up to three New Horizons in Mathematics Prizes are given out to early-career researchers each year. Laureates attend a televised awards ceremony designed to celebrate their achievements and inspire the next generation of scientists. As part of the ceremony schedule, they also engage in a program of lectures and discussions. The Breakthrough Prizes were founded by Sergey Brin, Yuri and Julia Milner, Mark Zuckerberg and Priscilla Chan, Anne Wojcicki, and Pony Ma. Selection Committees composed of previous Breakthrough Prize laureates choose the winners.\n\nInformation on the Breakthrough Prizes is available at breakthroughprize.org."},
{"url": "https://xamarinhelp.com/flutter-xamarins-next-big-competitor/", "link_title": "Google's Flutter could be Xamarin\u2019s next big competitor", "sentiment": 0.11236418236418239, "text": "Flutter is a new SDK from Google, still in Alpha stage, that lets you build apps for Android and iOS. Flutter is unique in that while it allows access to native APIs, it doesn\u2019t use native UI elements. Everything is drawn on a Skia canvas.\n\nThis is how Flutter works at a high level. Using Dart, you use components that draw on a Skia canvas. What ever platform Skia can run on, theoretically, so can Flutter.\n\nTo delve deeper into how this would play out in the Xamarin.Forms world, I quickly created a proof of concept called Skixam, that takes a Xamarin.Forms app and draws it on a Skia canvas, instead of using the native UI elements. It shows that Xamarin.Forms could have Skia as a platform.\n\nFlutter also has weight behind it, because it is backed by Google, and even recently acquired long term Microsoft employee, Tim Sneath to work on this framework. It\u2019s early stages, and it has such a long way to go, but even I can see it\u2019s potential, provided they execute correctly.\n\nNative Look And Feel. A commonly spoken phrase, that used to be the shining selling point of Xamarin. We can have an app that looks native on each platform, but share significant amounts of code, even the UI.\n\nThis is fast losing relevance, among Xamarin.Forms applications. Today clients are less focussed on making an app look native. They get UX/UI designers to come in and develop how they want the app to look. They don\u2019t make tweaks for each platform, then they want the app to look like this on ALL platforms.\n\nI spend more and more time now, diverting from the native UI look and feel, to match exactly across platforms. Users of the app aren\u2019t complaining, and I see it is becoming more common place. UI designers are starting to push back on platform styling guidelines and say they are only guidelines, and a lot of the time, not the best approach.\n\nIf Xamarin.Forms took the Skia approach, and focussed on a consistent UI across platforms as a platform, it could very well take the advantage away from Flutter.\n\nXamarin isn\u2019t going anywhere, Flutter looks like it could pick up a lot of indie and small dev shop movement, leading the way to larger companies adopting it down the road. If Xamarin.Forms also offered Skia as a platform, along with its existing ones, it could negate the Flutter advantage, and allow it to move to newer platforms, quicker. Xamarin could still continue to work on platform specific UI\u2019s if they desired to, Skia would work along side.\n\nTie this together with the existing SDK Bindings and Tools that Xamarin already offers, it could be the next step Xamarin takes to secure it\u2019s position in cross platform mobile development."},
{"url": "https://www.youtube.com/watch?v=I081OvfZZtc", "link_title": "Japan in the seventies", "sentiment": 0.004166666666666666, "text": "Second and final part of an educational film for American school children forty years ago\n\nSee my other 1000 clips by searching YouTube with 'michael rogge' \n\nWebsite 'Man and the Unknown' http://wichm.home.xs4all.nl/"},
{"url": "https://www.newyorker.com/tech/elements/origin-silicon-valley-dysfunctional-attitude-toward-hate-speech", "link_title": "The origin of Silicon Valley's dysfunctional attitude toward hate speech", "sentiment": 0.09533654582537264, "text": "On January 30, 1989, an article appeared in the student-run Stanford Daily under the headline \u201c Racial slurs cause University to shut down bulletin board .\u201d The bulletin board in question, rec.humor.funny, was one of hundreds of so-called newsgroups\u2014glorified mass e-mails organized around specific interests\u2014that streamed onto the school\u2019s computer terminals via Usenet, an early precursor to today\u2019s Internet forums. Rec.humor.funny was conceived as a place to share jokes, many of them crude and off-color, and one in particular, the Daily explained, had caught the eye of Stanford\u2019s nascent I.T. department. Though decidedly stale and not nearly as offensive as some of the other material in the newsgroup, it relied on ethnic stereotypes: \u201cA Jew and a Scotsman have dinner. At the end of the dinner the Scotsman is heard to say, \u2018I\u2019ll pay.\u2019 The newspaper headline next morning says, \u2018Jewish ventriloquist found dead in alley.\u2019\u00a0\u201d Upon reading those words, a student at M.I.T. had complained, and the attention had led a Canadian university to stop hosting rec.humor.funny. Eventually\u2014most likely thanks to Usenet\u2014word reached Stanford.\n\nI.T. administrators soon decided to block the group. \u201cJokes based on such stereotypes perpetuate racism, sexism, and intolerance,\u201d they wrote in a note that appeared on terminals campus-wide. \u201cThey undermine an important University purpose: our collective search for a better way, for a truly pluralistic community in which every person is acknowledged an individual, not a caricature.\u201d Carefully stressing the value of freedom of expression, the note nevertheless concluded that \u201cour respect for the dignity and rights of every individual\u201d was more important. This was a notably early attempt to clean up the Internet\u2014occurring at Stanford, no less, the epicenter of Silicon Valley\u2014and the reactions to it established a pattern of toxic rhetoric and hypocritical argumentation that, nearly three decades later, remains discouragingly familiar.\n\nEven before the I.T. department announced its decision, the atmosphere at Stanford had been politically fraught. In many ways, it resembled America in 2017. Women and minority students, spurred on by the Reverend Jesse Jackson\u2019s \u201crainbow coalition,\u201d had been demanding new, more inclusive curriculum requirements and greater diversity, while a reactionary movement had sprung up among their conservative peers. One of the leaders of the right-wing insurrection was Peter Thiel , who would go on to co-found PayPal and the software company Palantir and make millions of dollars as an early investor in Facebook. At the time, he was an undergraduate philosophy major and the editor of the Stanford Review , a sort of collegiate Breitbart News for the late eighties, dedicated to bemoaning what it saw as political correctness run amok. The Review , with Thiel at its helm, yearned to make Stanford great again. As he observed in \u201cThe Diversity Myth,\u201d his 1995 polemic co-written with David Sacks, another Review editor who later became a Silicon Valley bigwig, \u201cMulticulturalism caused Stanford to resemble less a great university than a Third World country, with corrupt ideologues and unhappy underlings.\u201d\n\nBanning rec.humor.funny was the Stanford I.T. team\u2019s attempt to calm campus nerves; only a few months earlier, there had been a polarizing case of two white freshmen drawing racist graffiti on a poster of Beethoven. But the backlash was immediate and extreme, and it went well above Thiel. When the team decided to act, they had sought technical advice from a graduate student, who, quite predictably, informed one of the eminences of the computer-science department, John McCarthy , what was going down. Before the ban had taken effect, McCarthy, a pioneer in programming and artificial intelligence, spearheaded a free-speech crusade. He took to the department\u2019s own electronic bulletin board to make the case against what he saw as censorship, strengthened by his conviction that computers were destined to be crucial to how we lived. \u201cNewsgroups are a new communication medium just as printed books were in the 15th century,\u201d McCarthy wrote. \u201cI believe they are one step towards universal access through everyone\u2019s computer terminal to the whole of world literature.\u201d In what must have been one of the first online petitions, McCarthy gathered a hundred digital signatures of support from his colleagues.\n\nThroughout this campaign, McCarthy never acknowledged the racial tensions that had so clearly informed the university\u2019s actions. Rather, he offered an engineer\u2019s systemic analysis of how information ought to be distributed, without regard for cultural or political context\u2014a species of reasoning that, decades later, has become ingrained in Silicon Valley. But context intruded on the bulletin board anyway, through the posts of William Augustus Brown, Jr., an African-American medical student who was participating in the department\u2019s research on using A.I. to treat patients. Brown was the lone voice among Stanford\u2019s computer scientists to support the ban.\n\n\u201cEven if I can\u2019t force the presentation of other cultures\u2014and I DO NOT assume this is impossible\u2014I will ALWAYS protest the stereotyping of my culture,\u201d he wrote. \u201cFor once the University acted with some modicum of maturity. I sincerely hope it maintains this status by refusing to reverse its decision.\u201d Brown framed the debate in terms quite different from McCarthy\u2019s. \u201cWhether disguised as free speech or simply stated as racism or sexism, such humor IS hurtful,\u201d he wrote. \u201cIt is a University\u2019s right and RESPONSIBILITY to minimize such inflammatory correspondence in PUBLIC telecommunications.\u201d\n\nMcCarthy never responded, directly or indirectly, to Brown, but others in his department did. Their rhetoric offers an early glimpse at how alternative opinions would be shouted down or patronized online from that point onward. (Terms such as \u201csocial-justice warrior\u201d and \u201cwhitesplaining\u201d had yet to be coined, but they would have been right at home.) One graduate student replied to Brown, \u201cI am a white male, and I have never been offended by white male jokes. Either they are so off-base that they are meaningless, or, by having some basis in fact (but being highly exaggerated) they are quite funny. I feel that the ability to laugh at oneself is part of being a mature, comfortable human being.\u201d A second grad student patiently explained that Brown didn\u2019t understand his own best interests. \u201cThe problem is that censorship costs more than the disease you\u2019re trying to cure,\u201d the student wrote. \u201cIf you really believe in the conspiracy, I\u2019m surprised that you want to give \u2018them\u2019 tools to implement their goals.\u201d\n\nThe reactions against Brown were so uniformly critical that he chose a different tack, opening up to his fellow-students about the difficulties of being a black man at Stanford. \u201cHaving received most of my pre-professional training in the Black American educational system, I have a different outlook than most students,\u201d Brown wrote. \u201cI certainly didn\u2019t expect the kind of close, warm relationships I developed at Hampton University, but I was not prepared for the antagonism.\u201d He continued, \u201cI don\u2019t really mind the isolation\u2014I can still deal, and it gives me PLENTY of time to study. But I really don\u2019t like the cruel humor. Once you come down from the high-flying ideals, it boils down to someone insisting on his right to be cruel to someone. That is a right he/she has, but NOT in ALL media.\u201d\n\nAgain, no one responded directly. The closest there was to a defense of Brown came from another grad student, who said that, while he was opposed to the rec.humor.funny ban, he worried that many of his peers believed that \u201cminority groups complain so much really because they like the attention they get in the media.\u201d He added that people rarely \u201ctry to understand the complaints from the minority point of view.\u201d Then he ended his post to the bulletin board by asking, \u201cDo people feel that the environment at Stanford has improved for minority students? Worsened? Who cares?\u201d Based on the lack of reply, \u201cWho cares?\u201d carried the day.\n\nMcCarthy wasn\u2019t persuadable on the matter, and certainly not through personal testimony. To his way of thinking, there was no such thing as inappropriate tech or inappropriate speech. Besides, who could be trusted to decide? One post, which McCarthy endorsed, suggested that letting I.T. administrators determine what belonged on the computers at Stanford was like giving janitors at the library the right to pick the books.\n\nMcCarthy\u2019s colleagues innately shared his anti-authoritarian perspective; they voted unanimously to oppose the removal of rec.humor.funny from Stanford\u2019s terminals. The students were nearly as committed; a confidential e-mail poll found a hundred and twenty-eight against the ban and only four in favor. McCarthy was soon able to win over the entire university by enlisting a powerful metaphor for the digital age. Censoring a newsgroup, he explained to those who might not be familiar with Usenet, was like pulling a book from circulation. Since \u201cMein Kampf\u201d was still on the library shelves, it was hard to imagine how anything else merited removal. The terms were clear: either you accepted offensive speech or you were in favor of destroying knowledge. There was no middle ground, and thus no opportunity to introduce reasonable regulations to insure civility online. In other words, here was the outline for exactly our predicament today.\n\nMcCarthy, who died in 2011, considered his successful campaign against Internet censorship the capstone to a distinguished career. As he boasted to a crowd gathered for the fortieth anniversary of the Stanford computer-science department, on March 21, 2006, his great victory had been to make the school understand that \u201ca faculty-member or student Web page was his own property, as it were, and not the property of the university.\u201d At the time, almost as much as in 1989, McCarthy could safely see this victory as untainted; the Internet still appeared to be virgin territory for the public to frolic in. Facebook wouldn\u2019t go public for another six years. The verb \u201cGoogle\u201d had yet to enter the Oxford English Dictionary. The first tweet had just been sent\u2014the very same day , in fact.\n\nToday, of course, hateful, enraging words are routinely foisted on the public by users of all three companies\u2019 products, whether in individual tweets and Facebook posts or in flawed Google News algorithms . Championing freedom of speech has become a business model in itself, a cover for maximizing engagement and attracting ad revenue, with the social damage mostly pushed aside for others to bear. When the Internet was young, the reason to clean it up was basic human empathy\u2014the idea that one\u2019s friends and neighbors, at home or on the other side of the world, were worth respecting. In 2017, the reason is self-preservation: American democracy is struggling to withstand the rampant, profit-based manipulation of the public\u2019s emotions and hatreds.\n\nWilliam Brown, who ended up leaving Stanford for Howard University Medical School and is now the head of vascular surgery at the Naval Medical Center in Portsmouth, Virginia, told me recently that he wishes his fellow computer scientists had heeded his warnings. \u201cCompassion and equity and humanity matters more than your right to say whatever comes out of your mouth,\u201d he said. \u201cThat environment sort of sparked the attitude that yes, if you came from a refined enough background, you could say whatever you wanted. Somehow the First Amendment was unlimited and there was no accountability.\u201d The problem, Brown added, remains all too pervasive. \u201cI see that attitude today,\u201d he said. \u201cIt doesn\u2019t matter whether it\u2019s Stanford or the alt-right.\u201d\n\nParts of this essay were adapted from Noam Cohen\u2019s book \u201c The Know-It-Alls ,\u201d which was released earlier this month by the New Press."},
{"url": "https://www.npmjs.com/package/nm8", "link_title": "Show HN: Nm8, a tiny JavaScript animation lib under 260 bytes", "sentiment": -0.05952380952380952, "text": "Ridiculously small animation library. Less than 260 bytes. Fits in a tweet.\n\nCreates an animation that calls with the current:\n\nStarts playing the animation, because the animation doesn't just fire off immediately. That's irresponsible.\n\nPauses the animation. The handler won't be called again until or is called.\n\nStops the animation. The handler will be called with the end value (either if is specified or otherwise). Calling on a stopped animation will restart it.\n\nHow do I actually make stuff move?\n\nNo. Use https://github.com/tweenrex/tweenrex if you want a small tweening library with more features.\n\nWhat is the browser support?\n\nWhy is it so small?\n\nSo you can copy-paste it:\n\nHave examples? Check out the examples directory: https://github.com/davidkpiano/nm8/blob/master/examples"},
{"url": "https://ourworldindata.org/a-history-of-global-living-conditions-in-5-charts/", "link_title": "The short history of global living conditions and why it matters that we know it", "sentiment": 0.08481705747955746, "text": "OWID presents work from many different people and organizations. When citing this entry, please also cite the original data source. This entry can be cited as: Max Roser (2017) \u2013 \u2018The short history of global living conditions and why it matters that we know it\u2019. Published online at OurWorldInData.org. Retrieved from: https://ourworldindata.org/a-history-of-global-living-conditions-in-5-charts/ [Online Resource]\n\nThis is the introduction to Our World in Data \u2013 the web publication that shows how global living conditions are changing. This text was previously titled \u201cA history of global living conditions in 5 charts\u201d.\n\nA recent survey asked \u201cAll things considered, do you think the world is getting better or worse, or neither getting better nor worse?\u201d. In Sweden 10% thought things are getting better, in the US they were only 6%, and in Germany only 4%. Very few people think that the world is getting better.\n\nWhat is the evidence that we need to consider when answering this question? The question is about how the world has changed and so we must take a historical perspective. And the question is about the world as a whole and the answer must therefore consider everybody. The answer must consider the history of global living conditions \u2013 a history of everyone.\n\nTo see where we are coming from we must go far back in time. 30 or even 50 years are not enough. When you only consider what the world looked during our life time it is easy to make the mistake of thinking of the world as relatively static\u00a0\u2013 the rich, healthy and educated parts of the world here and the poor, uneducated, sick regions there \u2013 and to falsely conclude that it always was like that and that it always will be like that.\n\nTake a longer perspective and it becomes very clear that the world is not static at all. The countries that are rich today were very poor just very recently and were in fact worse off than the poor countries today.\n\nTo avoid portraying the world in a static way \u2013 the North always much richer than the South \u2013 we have to start 200 years ago before the\u00a0time when\u00a0living conditions really changed dramatically.\n\nResearchers measure extreme poverty as living with less than 1.90$ per day. These poverty figures take into account non-monetary forms of income \u2013 for poor families today and in the past this is important, particularly because of subsistence farming. The poverty measure is also corrected for different price levels in different countries and adjusted for price changes over time (inflation) \u2013 poverty is measured in so-called international dollar that accounts for these adjustments.\n\nThe first chart shows the estimates for the share of the world population living in extreme poverty. In 1820 only a tiny elite enjoyed higher standards of living, while the vast majority of people lived in conditions that we would call extreme poverty today. Since then the share of extremely poor people fell continuously. More and more world regions industrialised and thereby increased productivity which made it possible to lift more people out of poverty: In 1950 three-quarters of the world were living in extreme poverty; in 1981 it was still 44%. For last year research suggests that the share in extreme poverty has fallen below 10%.\n\nThat is a huge achievement, for me as a researcher who focusses on growth and inequality maybe the biggest achievement of all in the last two centuries. It is particularly remarkable if we consider that the world population has increased 7-fold over the last two centuries \u2013 switch to the \u2018Absolute\u2019 view in the visualisation below to see the number of people in and out of poverty. In a world without economic growth, such an increase in the population would have resulted in less and less income for everyone; A 7-fold increase in the world population would have been enough to drive everyone into extreme poverty. Yet, the exact opposite happened. In a time of unprecedented population growth our world managed to give more prosperity to more people and to continuously lift more people out of poverty.\n\nIncreasing productivity was important because it made vital goods and services less scarce: more food, better clothing, and less cramped housing. Productivity is the ratio between the output of our work and the input that we put in our work; as productivity increased we benefitted from more output, but also from less input \u2013 weekly working hours fell very substantially.\n\nEconomic growth was also important because it changed the relationship between people. In the long time in which the world lived in a non-growth world the only way to become better off is if someone else got\u00a0worse off. Your own good luck is your neighbours bad luck. Economic growth changed that, growth made it possible that you are better off when others become better off. The ingenuity of those that built the technology that increased productivity \u2013 the car, the machinery, and communication technology \u2013 made some of them very rich and at the same time it increased the productivity and the incomes of others. It is hard to overstate how different life in zero-sum and a positive-sum economy are.\n\nUnfortunately the media is overly obsessed with reporting single events and with things that go wrong\u00a0and does not nearly pay enough attention to the slow developments that reshape our world. With this empirical data on the reduction of poverty we can make it concrete what a\u00a0media that would report global\u00a0development would look like. The headline could be\u00a0\u201cThe number of people in extreme poverty fell by 130,000 since yesterday\u201d and they wouldn\u2019t have this headline once, but every single day since 1990, since, on average, there were 130,000 people fewer in extreme poverty every day.\n\nHow did the education of the world population change over this period? The chart below shows the share of the world population that is literate over the last 2 centuries. In the past only a tiny elite was able to read and write. Today\u2019s education \u2013 including in today\u2019s richest countries \u2013 is again a very recent achievement. It was in the last two centuries that literacy became the norm for the entire population.\n\nIn 1820 only every 10th person older than 15 years was literate; in 1930 it was every third and now we are at 85% globally. Put differently, if you were alive in 1800 there was a chance of 9 in 10 that you weren\u2019t able to read \u2013 today more than 8 out of 10 people are able to read. And if you are young chances are much higher since many of today\u2019s illiterate population are old.\n\nIf you think science, technology, political freedom are important to solve the world\u2019s problems and you think that it helps to read and write to do this then look at the figures in absolute numbers. Today there are 5.4 billion people older than 15 years of which, as the chart shows, 85% are literate \u2013 these are 4.6 billion people. In 1800 there were fewer than 100 million people with the same skill.\n\nOne reason why we do not see progress is that we are unaware of how bad the past was.\n\nIn 1800 the health conditions of our ancestors were such that around 43% of the world\u2019s newborns died before their 5th birthday. The historical estimates suggest that the entire world lived in poor conditions; there was relatively little variation between different regions, in all countries of the world more than every third child died before it was 5 years old.\n\nIt would be wrong to believe that modern medicine was the only reason for improved health. Initially rising prosperity and the changing nature of social life mattered more than medicine. It were improvements in housing and sanitation that improved our chances in the age old war against infectious disease. Healthier diet \u2013 made possible through higher productivity in the agricultural sector and overseas trade \u2013 made us more resilient against disease. Surprisingly improving nutrition and health also made us smarter\u00a0and taller.\n\nBut surely science and medicine mattered as well. A more educated population achieved a series of scientific breakthroughs that made it possible to reduce mortality and disease further. Particularly important was the discovery of the germ theory of disease in the second half of the 19th century.\u00a0In retrospect it is hard to understand why a new theory can possibly be so important. But at a time when doctors did not wash their hands when switching from post-mortem to midwifery the theory finally convinced our ancestors that hygiene and public sanitation are crucial for health.\n\nThe germ theory of disease laid\u00a0the foundation for the development of antibiotics and vaccines, and it helped the world to see why public health is so very important. Public health mattered hugely: Everybody benefits from everybody else being vaccinated, and everybody benefits from everybody else obeying the rules of hygiene.\n\nWith these changes global health improved in a way that was unimaginable to our ancestors. In 2015 child mortality was down to 4.3% \u2013 10-fold lower than 2 centuries ago. You have to take this long perspective to see the progress that we have achieved.\n\nPolitical freedom and civil liberties are at the very heart of development \u2013 as they are both a means for development and an end of development. Journalism and public discourse are the pillars on which this freedom rests, but\u00a0qualitative assessments of these aspects\u00a0bears the risk that we are mistakingly\u00a0perceiving a decline of liberties over time when in fact we are raising the bar by which we judge our liberty. Quantitative assessments can therefore be useful when they help us to measure freedom against the same yardstick across countries and over time.\n\nThere are various attempts to measure the types of political regimes that govern the world\u2019s countries and to capture something as complex as a political system is necessarily controversial. There is just no way around that. In this analysis I will rely on the Polity IV index as it is the least problematic\u00a0of the measures that present a long term perspective. The index measures political regimes on a spectrum from +10 for full democracies to -10 for full autocracies; regimes that fall somewhere in the middle of this spectrum are called anocracies. To this I added information about the world\u2019s countries that were ruled by other countries as part of a colonial empire.\n\nAgain I want to give a time perspective to get an idea of how political freedom has changed over the last 200 years.\n\nThe chart shows the share of people living under different types of political regimes over the last 2 centuries. Throughout the 19th century more than a third of the population lived in colonial regimes and almost everyone else lived in autocratically ruled countries. The first expansion of political freedom from the late 19th century onward was crushed by the rise of authoritarian regimes that in many countries took their place in the time leading up to the Second World War.\n\n In the second half of the 20th century the world has changed significantly: Colonial empires ended, and more and more countries turned democratic: The share of the world population living in democracies increased continuously \u2013 particularly important was the breakdown of the Soviet Union which allowed more countries to democratise. Now more than every second person in the world lives in a democracy.\n\nThe huge majority of those living in an autocracy \u2013 4 out of 5 \u2013 live in one autocratic country: China.\n\nHuman rights are similarly difficult to measure consistently over time and across time. The best\u00a0empirical data show that after a time of stagnation human right protection improved globally over the last 3 decades.\n\n\n\nIf you click on \u2018Absolute\u2019 in any of the previous charts you see the increase of the world population over the last 2 centuries. The world population was around 1 billion in the year 1800 and increased 7-fold since then.\n\nPopulation growth increased humanity\u2019s demand for resources and amplified humanity\u2019s impact on the environment. But this increase of the world population should evoke more than doom and gloom. First of all, this increase shows a tremendous achievement. It shows that humans stopped dying at the rate at which our ancestors died for the many millennia before.\n\nIn pre-modern times fertility was high \u2013 5 or 6 children per woman were the norm. What kept the population growth low was the very high rate with which people died\u00a0and that meant that many children\u00a0were dead before they reached their reproductive age. The increase of the world population followed when humanity started to win the fight against death. Global life expectancy doubled just over the last hundred years.\n\nPopulation growth is a consequence of fertility and mortality not declining simultaneously. The fast population growth happened when fertility was still as high as it was in the unhealthy environment of the past, but mortality has already declined to the low levels of our time.\n\nWhat we have seen in country after country over the last 200 years is that once women realise that the chances of their children dying has declined substantially they adapt and chose to have fewer children. Population growth then comes to an end. This transition from high mortality and fertility to low mortality and fertility is called the demographic transition. In those countries that industrialised first it lasted at least from the mid 19th century to the mid 20th century \u2013 it took 95 years for fertility to decline from above 6 children to less than 3 children per woman in the UK. Countries that followed later sometimes achieved this transition much faster: South Korea went from more than 6 children per woman to less than 3 in just 18 years, Iran even achieved it in just 10 years.\n\nJust as countries went through this transition so is the world going through this transition. Global fertility has more than halved in the last 50 years, from more than 5 children per woman in the early 1960s to below 2.5 today. This means that the world is well into the demographic transition and global population growth has in fact peaked half a century ago.\n\nNow that we see fertility declining everywhere we come to an end of population growth: The global population has quadrupled over the course of the 20th century, over the course of this century it will not double. And at the end of the century the UN expects a slow annual population growth of 0.1% whereas the demographers from IIASA expect an end of global population growth around the year 2075.\n\nNone of the achievements over the last 2 centuries could have been made without the expansion of knowledge and education. The revolution in how we live was not only driven by education it also made education more important than ever.\n\nAnd we know that education is on track to improve globally. Contrary to many other social aspects where forecasts are of limited use, I think education is an aspect where we can make some useful projections into the future. The simple reason is that the educational composition today tells us something about the education of tomorrow\u00a0\u2013 a literate young woman today will be a literate old woman in 2070 and a student with secondary education now\u00a0will be a graduate with secondary education in the future.\n\nThe younger cohort today is\u00a0much better educated than the older cohorts. And as the cohort size is decreasing schools that are already in place can provide better for the next generation.\n\nThe visualisation below shows the projection of the IIASA institute\u00a0for the size and the educational composition of the world population until 2100. It is an interesting look into the future: With today\u2019s lower global fertility the researchers expect that the number of children will decline from now \u2013 there will never be more children on the planet than today. And as mentioned before the IIASA researchers expect the world population to peak in 2070 and to decline thereafter.\n\nFocusing on the educational breakdown the projection suggests that by 2100, there will be almost no one without formal education and there will be more than 7 billion minds who will have received at least secondary education.\n\nWith the great importance of education for improving health, increasing political freedom, and ending poverty this projection is very encouraging.\n\nThe motivation for this history of global living conditions was the survey result that documented the very negative perspective of global development that most of us have. More than 9 out of 10 people do not think that the world is getting better. How does that fit with the empirical evidence?\n\nI do not think that the media are the only ones to blame, but I do think that they are to blame for some part of this.\u00a0This is because the\u00a0media does not tell us how the world is changing, it tells us what in the world goes wrong.\n\nOne reason why the media focusses on things that go wrong is that the media focusses on single events and single events are often bad \u2013 look at the news: plane crashes, terrorism attacks, natural disasters, election outcomes that we are not happy with.\n\n Positive developments on the other hand often happen very slowly and never make the headlines in the event-obsessed media.\n\nThe result of a media \u2013\u00a0and education system \u2013 that fails to present quantitative information on long-run developments is that the huge majority of people is completely ignorant about global development. Even the decline of global extreme poverty \u2013 by any standard one of the most important developments in our lifetime \u2013 is only known by a small fraction of the population of the UK (10%) or the US (5%). In both countries the majority of people think that the share of people living in extreme poverty has increased! Two thirds in the US even think the share in extreme poverty has \u2018almost doubled\u2019. When we are ignorant about global development it is not\u00a0surprising\u00a0that few think that the world is getting better.\n\nThe only way to tell a history of everyone is to use statistics, only then can we hope to get an overview over the lives of the 22 billion people that lived in the last 200 years. The\u00a0developments that these statistics reveal transform our global living conditions \u2013 slowly but steadily. They are reported in\u00a0this online publication \u2013 Our World in Data \u2013 that my team and I have been building over the last years. We see it as a resource to show these long-term developments and thereby complement the information in the news that focus on events.\n\nThe difficulty for telling the history of how everyone\u2019s lives changed over the last 200 years is that you cannot pick single stories. Stories about individual people are much more engaging \u2013 our minds like these stories \u2013 but they cannot be representative for how the world has changed. To\u00a0achieve a representation of how the world has changed at large you have to tell many, many stories all at once; and that is statistics.\n\nTo make it easier for myself and for you to understand the transformation in living conditions that we have achieved I made a summarizing visualisation in which I imagine this 200 year history as the history of a group of 100 people to see how the lives of them would have changed if they lived through this transformative period of the modern world.\n\nhere you can download the 200 year chart\u00a0in high resolution to print it out.\n\nThe successful transformation of our living conditions was possible only because of collaboration. Such a transformation would be impossible for a single person to accomplish. It is our collective brains and our collaborative effort that are needed for such an improvement.\n\nThere are big problems that remain. None of the above\u00a0should give us reason to become complacent. On the contrary, it shows us that a lot of work still needs to be done \u2013 accomplishing the fastest reduction of poverty is a tremendous achievement, but the fact that 1 out of 10 people lives in extreme poverty today is unacceptable. We also must not\u00a0accept the restrictions of our liberty that remain and that are put in place. And it is also clear that humanity\u2019s impact on the environment is at a level that is not sustainable and is endangering the biosphere and climate on which we depend. We urgently need to reduce our impact.\n\nIt is far from certain that we will make progress against these problems \u2013 there is no iron law that would ensure that the world continues this trend of improving living conditions. But what is clear from the long-term perspective is that the last 200 years brought us to a better position than ever before to solve these problems. Solving problems \u2013 big problems \u2013 is always a collaborative undertaking. And the group of people that is able to work together today is a much, much stronger group than there ever was on this planet. We have just seen the change over time; the world today is healthier, richer, and better educated.\n\nFor our history to be a source of encouragement we have to know our history. The story that we tell ourselves about our history and our time matters. Because our hopes and efforts for building a better future are inextricably linked to our perception of the past it is important to understand and communicate the global development up to now. A positive lookout on the efforts of ourselves and our fellow humans is a vital condition to the fruitfulness of our endeavors. Knowing that we have come a long way in improving living conditions and the notion that our work is worthwhile is to us all what self-respect is to individuals. It is a necessary condition for self-improvement.\n\nFreedom is impossible without faith in free people. And if we are not aware of our history and falsely believe the opposite of what is true we risk losing faith in each other."},
{"url": "https://www.djangoproject.com/weblog/2017/dec/02/django-20-released/", "link_title": "Django 2.0 released", "sentiment": 0.02476465841850458, "text": "The Django team is happy to announce the release of Django 2.0.\n\nThis release starts Django\u2019s use of a loose form of semantic versioning, but there aren\u2019t any major backwards incompatible changes (except that support for Python 2.7 is removed) that might be expected of a 2.0 release. Upgrading should be a similar amount of effort as past feature releases.\n\nThe release notes cover the assortment of new features in detail, but a few highlights are:\n\nYou can get Django 2.0 from our downloads page or from the Python Package Index. The PGP k